{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcce5ce",
   "metadata": {},
   "source": [
    "This notebook contains the necessary scripts for making the base case model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac91e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\po7517\\Anaconda3\\envs\\new_env\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\po7517\\Anaconda3\\envs\\new_env\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\po7517\\Anaconda3\\envs\\new_env\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "### Starting with the import of the necessary libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.stats import linregress\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0e2186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### either CPU or GPU:\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37edf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the dummy data\n",
    "all_data = pd.read_csv('data/all_data_dummy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db56d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_NN(all_data, input_features, target_variables, weight_decay=1e-3, patience=100):\n",
    "    '''\n",
    "    This function reads the data and based on the interest of the user, different \n",
    "    input features and target variables can be selected from the existing measured\n",
    "    parameters.\n",
    "    weight_decay is a regularization technique used to prevent overfitting by penalizing \n",
    "    large weights in the model. More details at \n",
    "    https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    "    patience refers to the number of training epochs to wait after the last improvement \n",
    "    in the monitored metric (e.g., validation loss, accuracy) before stopping the training process.\n",
    "    More details at https://pytorch.org/ignite/generated/ignite.handlers.early_stopping.EarlyStopping.html\n",
    "    '''\n",
    "    ### The next block of code prepares the data\n",
    "    X = all_data[input_features].to_numpy()\n",
    "    y = all_data[target_variables].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    scaler_x = RobustScaler()\n",
    "    scaler_y = RobustScaler()\n",
    "    X_train_norm = scaler_x.fit_transform(X_train)\n",
    "    X_test_norm = scaler_x.transform(X_test)\n",
    "    y_train_norm = scaler_y.fit_transform(y_train)\n",
    "    y_test_norm = scaler_y.transform(y_test)\n",
    "    XX = torch.from_numpy(X_train_norm.astype(np.float32)).to(device)\n",
    "    yy = torch.from_numpy(y_train_norm.astype(np.float32)).to(device)\n",
    "    n_samples, n_features = XX.shape\n",
    "    input_size = n_features\n",
    "    output_size = yy.shape[1]\n",
    "    \n",
    "    class NN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc1 = nn.Linear(n_features, 32) # Input layer to hidden layer\n",
    "            self.norm1 = nn.BatchNorm1d(32) # Batch normalization\n",
    "            self.fc2 = nn.Linear(32, 16) # Hidden layer to hidden layer\n",
    "            self.norm2 = nn.BatchNorm1d(16) # Batch normalization\n",
    "            self.fc3 = nn.Linear(16, output_size) # Hidden layer to output layer\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x)) # applying relu activation\n",
    "            x = self.norm1(x) # applying the batch normalization\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.norm2(x)\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    " \n",
    "    model = NN().to(device) # contruction of the model\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience, verbose=True)\n",
    "    # Training loop with early stopping\n",
    "    num_epochs = 2000\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    loss_values = []\n",
    "    loss_train = []\n",
    "    for epoch in range(num_epochs):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(XX)\n",
    "            loss = criterion(outputs, yy)\n",
    "            loss.backward()\n",
    "            loss_train.append(loss.item())\n",
    "            return loss\n",
    "\n",
    "        # Perform optimization step\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(torch.from_numpy(X_test_norm.astype(np.float32)).to(device))\n",
    "            val_loss = criterion(val_outputs, torch.from_numpy(y_test_norm.astype(np.float32)).to(device))\n",
    "            \n",
    "        scheduler.step(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience: # looking for the improve of the loss\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "\n",
    "        if (epoch+1) % 100 == 0: # printg out each 100th epoch\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "        loss_values.append(val_loss.item())\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    # using the trained model to predict for the test data\n",
    "    predicted = model(torch.from_numpy(X_test_norm.astype(np.float32)).to(device)).detach().cpu().numpy()\n",
    "    predicted_original_scale = scaler_y.inverse_transform(predicted)\n",
    "    y_test_original_scale = scaler_y.inverse_transform(y_test_norm)\n",
    "    \n",
    "    # using the trained model to predict for the train data\n",
    "    predicted_tr = model(torch.from_numpy(X_train_norm.astype(np.float32)).to(device)).detach().cpu().numpy()\n",
    "    predicted_original_scale_tr = scaler_y.inverse_transform(predicted_tr)\n",
    "    y_train_original_scale = scaler_y.inverse_transform(y_train_norm)\n",
    "\n",
    "    r_values = [] # collects the r value between the measured test and predicted test cases\n",
    "    for i in range(len(target_variables)):\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(y_test_original_scale[:, i], predicted_original_scale[:, i])\n",
    "        r_values.append(r_value)\n",
    "    \n",
    "    return r_values, y_test_original_scale, predicted_original_scale, y_train_original_scale, predicted_original_scale_tr, loss_train, loss_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224fa4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Round 0\n",
      "Epoch [100/2000], Loss: 0.2505, Val Loss: 0.2505\n",
      "Epoch [200/2000], Loss: 0.2555, Val Loss: 0.2555\n",
      "Early stopping at epoch 211\n",
      "Training complete.\n",
      "Starting Round 1\n",
      "Epoch [100/2000], Loss: 0.2425, Val Loss: 0.2425\n",
      "Epoch [200/2000], Loss: 0.2434, Val Loss: 0.2434\n",
      "Early stopping at epoch 220\n",
      "Training complete.\n",
      "Starting Round 2\n",
      "Epoch [100/2000], Loss: 0.2330, Val Loss: 0.2330\n",
      "Early stopping at epoch 160\n",
      "Training complete.\n",
      "Starting Round 3\n",
      "Epoch [100/2000], Loss: 0.2676, Val Loss: 0.2676\n",
      "Early stopping at epoch 151\n",
      "Training complete.\n",
      "Starting Round 4\n",
      "Epoch [100/2000], Loss: 0.2395, Val Loss: 0.2395\n",
      "Epoch [200/2000], Loss: 0.2517, Val Loss: 0.2517\n",
      "Early stopping at epoch 273\n",
      "Training complete.\n",
      "Starting Round 5\n",
      "Epoch [100/2000], Loss: 0.3095, Val Loss: 0.3095\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 6\n",
      "Epoch [100/2000], Loss: 0.2550, Val Loss: 0.2550\n",
      "Early stopping at epoch 158\n",
      "Training complete.\n",
      "Starting Round 7\n",
      "Epoch [100/2000], Loss: 0.2684, Val Loss: 0.2684\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 8\n",
      "Epoch [100/2000], Loss: 0.2624, Val Loss: 0.2624\n",
      "Epoch [200/2000], Loss: 0.3067, Val Loss: 0.3067\n",
      "Early stopping at epoch 226\n",
      "Training complete.\n",
      "Starting Round 9\n",
      "Epoch [100/2000], Loss: 0.2671, Val Loss: 0.2671\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 10\n",
      "Epoch [100/2000], Loss: 0.2776, Val Loss: 0.2776\n",
      "Early stopping at epoch 172\n",
      "Training complete.\n",
      "Starting Round 11\n",
      "Epoch [100/2000], Loss: 0.2465, Val Loss: 0.2465\n",
      "Early stopping at epoch 170\n",
      "Training complete.\n",
      "Starting Round 12\n",
      "Epoch [100/2000], Loss: 0.2630, Val Loss: 0.2630\n",
      "Early stopping at epoch 164\n",
      "Training complete.\n",
      "Starting Round 13\n",
      "Epoch [100/2000], Loss: 0.2497, Val Loss: 0.2497\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 14\n",
      "Epoch [100/2000], Loss: 0.2774, Val Loss: 0.2774\n",
      "Epoch [200/2000], Loss: 0.2694, Val Loss: 0.2694\n",
      "Epoch [300/2000], Loss: 0.2576, Val Loss: 0.2576\n",
      "Early stopping at epoch 329\n",
      "Training complete.\n",
      "Starting Round 15\n",
      "Epoch [100/2000], Loss: 0.2269, Val Loss: 0.2269\n",
      "Epoch [200/2000], Loss: 0.2501, Val Loss: 0.2501\n",
      "Early stopping at epoch 219\n",
      "Training complete.\n",
      "Starting Round 16\n",
      "Epoch [100/2000], Loss: 0.2458, Val Loss: 0.2458\n",
      "Early stopping at epoch 179\n",
      "Training complete.\n",
      "Starting Round 17\n",
      "Epoch [100/2000], Loss: 0.2434, Val Loss: 0.2434\n",
      "Epoch [200/2000], Loss: 0.2563, Val Loss: 0.2563\n",
      "Early stopping at epoch 209\n",
      "Training complete.\n",
      "Starting Round 18\n",
      "Epoch [100/2000], Loss: 0.2927, Val Loss: 0.2927\n",
      "Epoch [200/2000], Loss: 0.2811, Val Loss: 0.2811\n",
      "Early stopping at epoch 255\n",
      "Training complete.\n",
      "Starting Round 19\n",
      "Epoch [100/2000], Loss: 0.2924, Val Loss: 0.2924\n",
      "Epoch [200/2000], Loss: 0.2873, Val Loss: 0.2873\n",
      "Early stopping at epoch 258\n",
      "Training complete.\n",
      "Starting Round 20\n",
      "Epoch [100/2000], Loss: 0.2827, Val Loss: 0.2827\n",
      "Epoch [200/2000], Loss: 0.2838, Val Loss: 0.2838\n",
      "Epoch [300/2000], Loss: 0.2763, Val Loss: 0.2763\n",
      "Early stopping at epoch 327\n",
      "Training complete.\n",
      "Starting Round 21\n",
      "Epoch [100/2000], Loss: 0.2802, Val Loss: 0.2802\n",
      "Early stopping at epoch 198\n",
      "Training complete.\n",
      "Starting Round 22\n",
      "Epoch [100/2000], Loss: 0.2351, Val Loss: 0.2351\n",
      "Early stopping at epoch 198\n",
      "Training complete.\n",
      "Starting Round 23\n",
      "Epoch [100/2000], Loss: 0.2825, Val Loss: 0.2825\n",
      "Early stopping at epoch 175\n",
      "Training complete.\n",
      "Starting Round 24\n",
      "Epoch [100/2000], Loss: 0.2442, Val Loss: 0.2442\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 25\n",
      "Epoch [100/2000], Loss: 0.2699, Val Loss: 0.2699\n",
      "Epoch [200/2000], Loss: 0.2864, Val Loss: 0.2864\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 26\n",
      "Epoch [100/2000], Loss: 0.3048, Val Loss: 0.3048\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 27\n",
      "Epoch [100/2000], Loss: 0.2262, Val Loss: 0.2262\n",
      "Epoch [200/2000], Loss: 0.2145, Val Loss: 0.2145\n",
      "Early stopping at epoch 287\n",
      "Training complete.\n",
      "Starting Round 28\n",
      "Epoch [100/2000], Loss: 0.2297, Val Loss: 0.2297\n",
      "Epoch [200/2000], Loss: 0.2200, Val Loss: 0.2200\n",
      "Epoch [300/2000], Loss: 0.2233, Val Loss: 0.2233\n",
      "Early stopping at epoch 330\n",
      "Training complete.\n",
      "Starting Round 29\n",
      "Epoch [100/2000], Loss: 0.2471, Val Loss: 0.2471\n",
      "Epoch [200/2000], Loss: 0.2328, Val Loss: 0.2328\n",
      "Early stopping at epoch 278\n",
      "Training complete.\n",
      "Starting Round 30\n",
      "Epoch [100/2000], Loss: 0.2462, Val Loss: 0.2462\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 31\n",
      "Epoch [100/2000], Loss: 0.2969, Val Loss: 0.2969\n",
      "Epoch [200/2000], Loss: 0.2783, Val Loss: 0.2783\n",
      "Early stopping at epoch 261\n",
      "Training complete.\n",
      "Starting Round 32\n",
      "Epoch [100/2000], Loss: 0.2875, Val Loss: 0.2875\n",
      "Epoch [200/2000], Loss: 0.2675, Val Loss: 0.2675\n",
      "Early stopping at epoch 292\n",
      "Training complete.\n",
      "Starting Round 33\n",
      "Epoch [100/2000], Loss: 0.2878, Val Loss: 0.2878\n",
      "Epoch [200/2000], Loss: 0.2610, Val Loss: 0.2610\n",
      "Epoch [300/2000], Loss: 0.2464, Val Loss: 0.2464\n",
      "Epoch [400/2000], Loss: 0.2483, Val Loss: 0.2483\n",
      "Epoch [500/2000], Loss: 0.2549, Val Loss: 0.2549\n",
      "Early stopping at epoch 517\n",
      "Training complete.\n",
      "Starting Round 34\n",
      "Epoch [100/2000], Loss: 0.2301, Val Loss: 0.2301\n",
      "Early stopping at epoch 166\n",
      "Training complete.\n",
      "Starting Round 35\n",
      "Epoch [100/2000], Loss: 0.2448, Val Loss: 0.2448\n",
      "Epoch [200/2000], Loss: 0.2358, Val Loss: 0.2358\n",
      "Early stopping at epoch 274\n",
      "Training complete.\n",
      "Starting Round 36\n",
      "Epoch [100/2000], Loss: 0.2718, Val Loss: 0.2718\n",
      "Epoch [200/2000], Loss: 0.2350, Val Loss: 0.2350\n",
      "Epoch [300/2000], Loss: 0.2403, Val Loss: 0.2403\n",
      "Early stopping at epoch 319\n",
      "Training complete.\n",
      "Starting Round 37\n",
      "Epoch [100/2000], Loss: 0.3119, Val Loss: 0.3119\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 38\n",
      "Epoch [100/2000], Loss: 0.2381, Val Loss: 0.2381\n",
      "Epoch [200/2000], Loss: 0.2542, Val Loss: 0.2542\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 39\n",
      "Epoch [100/2000], Loss: 0.2708, Val Loss: 0.2708\n",
      "Epoch [200/2000], Loss: 0.2941, Val Loss: 0.2941\n",
      "Early stopping at epoch 211\n",
      "Training complete.\n",
      "Starting Round 40\n",
      "Epoch [100/2000], Loss: 0.3115, Val Loss: 0.3115\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 41\n",
      "Epoch [100/2000], Loss: 0.2709, Val Loss: 0.2709\n",
      "Epoch [200/2000], Loss: 0.2644, Val Loss: 0.2644\n",
      "Early stopping at epoch 214\n",
      "Training complete.\n",
      "Starting Round 42\n",
      "Epoch [100/2000], Loss: 0.2751, Val Loss: 0.2751\n",
      "Epoch [200/2000], Loss: 0.2637, Val Loss: 0.2637\n",
      "Early stopping at epoch 281\n",
      "Training complete.\n",
      "Starting Round 43\n",
      "Epoch [100/2000], Loss: 0.2888, Val Loss: 0.2888\n",
      "Epoch [200/2000], Loss: 0.2898, Val Loss: 0.2898\n",
      "Epoch [300/2000], Loss: 0.2924, Val Loss: 0.2924\n",
      "Epoch [400/2000], Loss: 0.2681, Val Loss: 0.2681\n",
      "Epoch [500/2000], Loss: 0.2836, Val Loss: 0.2836\n",
      "Early stopping at epoch 534\n",
      "Training complete.\n",
      "Starting Round 44\n",
      "Epoch [100/2000], Loss: 0.2395, Val Loss: 0.2395\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 45\n",
      "Epoch [100/2000], Loss: 0.2278, Val Loss: 0.2278\n",
      "Epoch [200/2000], Loss: 0.2325, Val Loss: 0.2325\n",
      "Epoch [300/2000], Loss: 0.2443, Val Loss: 0.2443\n",
      "Early stopping at epoch 325\n",
      "Training complete.\n",
      "Starting Round 46\n",
      "Epoch [100/2000], Loss: 0.2681, Val Loss: 0.2681\n",
      "Epoch [200/2000], Loss: 0.2510, Val Loss: 0.2510\n",
      "Epoch [300/2000], Loss: 0.2496, Val Loss: 0.2496\n",
      "Epoch [400/2000], Loss: 0.2450, Val Loss: 0.2450\n",
      "Early stopping at epoch 481\n",
      "Training complete.\n",
      "Starting Round 47\n",
      "Epoch [100/2000], Loss: 0.2590, Val Loss: 0.2590\n",
      "Epoch [200/2000], Loss: 0.2646, Val Loss: 0.2646\n",
      "Epoch [300/2000], Loss: 0.2652, Val Loss: 0.2652\n",
      "Early stopping at epoch 305\n",
      "Training complete.\n",
      "Starting Round 48\n",
      "Epoch [100/2000], Loss: 0.2835, Val Loss: 0.2835\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 49\n",
      "Epoch [100/2000], Loss: 0.2863, Val Loss: 0.2863\n",
      "Epoch [200/2000], Loss: 0.3004, Val Loss: 0.3004\n",
      "Early stopping at epoch 275\n",
      "Training complete.\n",
      "Starting Round 50\n",
      "Epoch [100/2000], Loss: 0.2762, Val Loss: 0.2762\n",
      "Epoch [200/2000], Loss: 0.2803, Val Loss: 0.2803\n",
      "Early stopping at epoch 220\n",
      "Training complete.\n",
      "Starting Round 51\n",
      "Epoch [100/2000], Loss: 0.2276, Val Loss: 0.2276\n",
      "Early stopping at epoch 195\n",
      "Training complete.\n",
      "Starting Round 52\n",
      "Epoch [100/2000], Loss: 0.2816, Val Loss: 0.2816\n",
      "Epoch [200/2000], Loss: 0.2815, Val Loss: 0.2815\n",
      "Early stopping at epoch 242\n",
      "Training complete.\n",
      "Starting Round 53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.2232, Val Loss: 0.2232\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 54\n",
      "Epoch [100/2000], Loss: 0.2541, Val Loss: 0.2541\n",
      "Epoch [200/2000], Loss: 0.2791, Val Loss: 0.2791\n",
      "Early stopping at epoch 225\n",
      "Training complete.\n",
      "Starting Round 55\n",
      "Epoch [100/2000], Loss: 0.2955, Val Loss: 0.2955\n",
      "Epoch [200/2000], Loss: 0.2806, Val Loss: 0.2806\n",
      "Epoch [300/2000], Loss: 0.2794, Val Loss: 0.2794\n",
      "Epoch [400/2000], Loss: 0.2677, Val Loss: 0.2677\n",
      "Early stopping at epoch 420\n",
      "Training complete.\n",
      "Starting Round 56\n",
      "Epoch [100/2000], Loss: 0.2908, Val Loss: 0.2908\n",
      "Epoch [200/2000], Loss: 0.2882, Val Loss: 0.2882\n",
      "Early stopping at epoch 279\n",
      "Training complete.\n",
      "Starting Round 57\n",
      "Epoch [100/2000], Loss: 0.2732, Val Loss: 0.2732\n",
      "Epoch [200/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Early stopping at epoch 277\n",
      "Training complete.\n",
      "Starting Round 58\n",
      "Epoch [100/2000], Loss: 0.2515, Val Loss: 0.2515\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 59\n",
      "Epoch [100/2000], Loss: 0.3148, Val Loss: 0.3148\n",
      "Epoch [200/2000], Loss: 0.3062, Val Loss: 0.3062\n",
      "Early stopping at epoch 288\n",
      "Training complete.\n",
      "Starting Round 60\n",
      "Epoch [100/2000], Loss: 0.2826, Val Loss: 0.2826\n",
      "Epoch [200/2000], Loss: 0.2603, Val Loss: 0.2603\n",
      "Epoch [300/2000], Loss: 0.2715, Val Loss: 0.2715\n",
      "Epoch [400/2000], Loss: 0.2823, Val Loss: 0.2823\n",
      "Early stopping at epoch 432\n",
      "Training complete.\n",
      "Starting Round 61\n",
      "Epoch [100/2000], Loss: 0.2614, Val Loss: 0.2614\n",
      "Early stopping at epoch 171\n",
      "Training complete.\n",
      "Starting Round 62\n",
      "Epoch [100/2000], Loss: 0.2556, Val Loss: 0.2556\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 63\n",
      "Epoch [100/2000], Loss: 0.2485, Val Loss: 0.2485\n",
      "Epoch [200/2000], Loss: 0.2328, Val Loss: 0.2328\n",
      "Early stopping at epoch 211\n",
      "Training complete.\n",
      "Starting Round 64\n",
      "Epoch [100/2000], Loss: 0.2374, Val Loss: 0.2374\n",
      "Epoch [200/2000], Loss: 0.2634, Val Loss: 0.2634\n",
      "Epoch [300/2000], Loss: 0.2513, Val Loss: 0.2513\n",
      "Early stopping at epoch 327\n",
      "Training complete.\n",
      "Starting Round 65\n",
      "Epoch [100/2000], Loss: 0.2761, Val Loss: 0.2761\n",
      "Early stopping at epoch 199\n",
      "Training complete.\n",
      "Starting Round 66\n",
      "Epoch [100/2000], Loss: 0.2284, Val Loss: 0.2284\n",
      "Epoch [200/2000], Loss: 0.2362, Val Loss: 0.2362\n",
      "Early stopping at epoch 201\n",
      "Training complete.\n",
      "Starting Round 67\n",
      "Epoch [100/2000], Loss: 0.2853, Val Loss: 0.2853\n",
      "Early stopping at epoch 194\n",
      "Training complete.\n",
      "Starting Round 68\n",
      "Epoch [100/2000], Loss: 0.2781, Val Loss: 0.2781\n",
      "Early stopping at epoch 175\n",
      "Training complete.\n",
      "Starting Round 69\n",
      "Epoch [100/2000], Loss: 0.2843, Val Loss: 0.2843\n",
      "Epoch [200/2000], Loss: 0.2909, Val Loss: 0.2909\n",
      "Epoch [300/2000], Loss: 0.2894, Val Loss: 0.2894\n",
      "Early stopping at epoch 316\n",
      "Training complete.\n",
      "Starting Round 70\n",
      "Epoch [100/2000], Loss: 0.2700, Val Loss: 0.2700\n",
      "Epoch [200/2000], Loss: 0.2709, Val Loss: 0.2709\n",
      "Early stopping at epoch 223\n",
      "Training complete.\n",
      "Starting Round 71\n",
      "Epoch [100/2000], Loss: 0.2314, Val Loss: 0.2314\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 72\n",
      "Epoch [100/2000], Loss: 0.2114, Val Loss: 0.2114\n",
      "Early stopping at epoch 164\n",
      "Training complete.\n",
      "Starting Round 73\n",
      "Epoch [100/2000], Loss: 0.2479, Val Loss: 0.2479\n",
      "Epoch [200/2000], Loss: 0.2402, Val Loss: 0.2402\n",
      "Early stopping at epoch 272\n",
      "Training complete.\n",
      "Starting Round 74\n",
      "Epoch [100/2000], Loss: 0.2596, Val Loss: 0.2596\n",
      "Early stopping at epoch 173\n",
      "Training complete.\n",
      "Starting Round 75\n",
      "Epoch [100/2000], Loss: 0.2555, Val Loss: 0.2555\n",
      "Epoch [200/2000], Loss: 0.2362, Val Loss: 0.2362\n",
      "Epoch [300/2000], Loss: 0.2381, Val Loss: 0.2381\n",
      "Epoch [400/2000], Loss: 0.2431, Val Loss: 0.2431\n",
      "Early stopping at epoch 460\n",
      "Training complete.\n",
      "Starting Round 76\n",
      "Epoch [100/2000], Loss: 0.2562, Val Loss: 0.2562\n",
      "Epoch [200/2000], Loss: 0.2581, Val Loss: 0.2581\n",
      "Epoch [300/2000], Loss: 0.2268, Val Loss: 0.2268\n",
      "Early stopping at epoch 400\n",
      "Training complete.\n",
      "Starting Round 77\n",
      "Epoch [100/2000], Loss: 0.2484, Val Loss: 0.2484\n",
      "Epoch [200/2000], Loss: 0.2370, Val Loss: 0.2370\n",
      "Epoch [300/2000], Loss: 0.2387, Val Loss: 0.2387\n",
      "Early stopping at epoch 333\n",
      "Training complete.\n",
      "Starting Round 78\n",
      "Epoch [100/2000], Loss: 0.2900, Val Loss: 0.2900\n",
      "Early stopping at epoch 164\n",
      "Training complete.\n",
      "Starting Round 79\n",
      "Epoch [100/2000], Loss: 0.2670, Val Loss: 0.2670\n",
      "Early stopping at epoch 189\n",
      "Training complete.\n",
      "Starting Round 80\n",
      "Epoch [100/2000], Loss: 0.2538, Val Loss: 0.2538\n",
      "Epoch [200/2000], Loss: 0.2312, Val Loss: 0.2312\n",
      "Epoch [300/2000], Loss: 0.2336, Val Loss: 0.2336\n",
      "Early stopping at epoch 320\n",
      "Training complete.\n",
      "Starting Round 81\n",
      "Epoch [100/2000], Loss: 0.2620, Val Loss: 0.2620\n",
      "Epoch [200/2000], Loss: 0.2580, Val Loss: 0.2580\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 82\n",
      "Epoch [100/2000], Loss: 0.2551, Val Loss: 0.2551\n",
      "Epoch [200/2000], Loss: 0.2464, Val Loss: 0.2464\n",
      "Epoch [300/2000], Loss: 0.2679, Val Loss: 0.2679\n",
      "Early stopping at epoch 366\n",
      "Training complete.\n",
      "Starting Round 83\n",
      "Epoch [100/2000], Loss: 0.2872, Val Loss: 0.2872\n",
      "Epoch [200/2000], Loss: 0.2839, Val Loss: 0.2839\n",
      "Epoch [300/2000], Loss: 0.2749, Val Loss: 0.2749\n",
      "Epoch [400/2000], Loss: 0.2903, Val Loss: 0.2903\n",
      "Early stopping at epoch 463\n",
      "Training complete.\n",
      "Starting Round 84\n",
      "Epoch [100/2000], Loss: 0.2754, Val Loss: 0.2754\n",
      "Early stopping at epoch 156\n",
      "Training complete.\n",
      "Starting Round 85\n",
      "Epoch [100/2000], Loss: 0.2273, Val Loss: 0.2273\n",
      "Epoch [200/2000], Loss: 0.2318, Val Loss: 0.2318\n",
      "Epoch [300/2000], Loss: 0.2301, Val Loss: 0.2301\n",
      "Early stopping at epoch 341\n",
      "Training complete.\n",
      "Starting Round 86\n",
      "Epoch [100/2000], Loss: 0.2494, Val Loss: 0.2494\n",
      "Early stopping at epoch 171\n",
      "Training complete.\n",
      "Starting Round 87\n",
      "Epoch [100/2000], Loss: 0.2512, Val Loss: 0.2512\n",
      "Epoch [200/2000], Loss: 0.2569, Val Loss: 0.2569\n",
      "Early stopping at epoch 288\n",
      "Training complete.\n",
      "Starting Round 88\n",
      "Epoch [100/2000], Loss: 0.2817, Val Loss: 0.2817\n",
      "Epoch [200/2000], Loss: 0.2707, Val Loss: 0.2707\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 89\n",
      "Epoch [100/2000], Loss: 0.2639, Val Loss: 0.2639\n",
      "Epoch [200/2000], Loss: 0.2530, Val Loss: 0.2530\n",
      "Early stopping at epoch 245\n",
      "Training complete.\n",
      "Starting Round 90\n",
      "Epoch [100/2000], Loss: 0.2399, Val Loss: 0.2399\n",
      "Epoch [200/2000], Loss: 0.2580, Val Loss: 0.2580\n",
      "Early stopping at epoch 219\n",
      "Training complete.\n",
      "Starting Round 91\n",
      "Epoch [100/2000], Loss: 0.2501, Val Loss: 0.2501\n",
      "Epoch [200/2000], Loss: 0.2341, Val Loss: 0.2341\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 92\n",
      "Epoch [100/2000], Loss: 0.2638, Val Loss: 0.2638\n",
      "Early stopping at epoch 158\n",
      "Training complete.\n",
      "Starting Round 93\n",
      "Epoch [100/2000], Loss: 0.2516, Val Loss: 0.2516\n",
      "Epoch [200/2000], Loss: 0.2579, Val Loss: 0.2579\n",
      "Early stopping at epoch 240\n",
      "Training complete.\n",
      "Starting Round 94\n",
      "Epoch [100/2000], Loss: 0.2731, Val Loss: 0.2731\n",
      "Epoch [200/2000], Loss: 0.2834, Val Loss: 0.2834\n",
      "Epoch [300/2000], Loss: 0.2746, Val Loss: 0.2746\n",
      "Early stopping at epoch 327\n",
      "Training complete.\n",
      "Starting Round 95\n",
      "Epoch [100/2000], Loss: 0.2486, Val Loss: 0.2486\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 96\n",
      "Epoch [100/2000], Loss: 0.2680, Val Loss: 0.2680\n",
      "Epoch [200/2000], Loss: 0.2648, Val Loss: 0.2648\n",
      "Epoch [300/2000], Loss: 0.2578, Val Loss: 0.2578\n",
      "Epoch [400/2000], Loss: 0.2546, Val Loss: 0.2546\n",
      "Epoch [500/2000], Loss: 0.2540, Val Loss: 0.2540\n",
      "Epoch [600/2000], Loss: 0.2545, Val Loss: 0.2545\n",
      "Early stopping at epoch 635\n",
      "Training complete.\n",
      "Starting Round 97\n",
      "Epoch [100/2000], Loss: 0.2808, Val Loss: 0.2808\n",
      "Epoch [200/2000], Loss: 0.2796, Val Loss: 0.2796\n",
      "Epoch [300/2000], Loss: 0.2786, Val Loss: 0.2786\n",
      "Early stopping at epoch 398\n",
      "Training complete.\n",
      "Starting Round 98\n",
      "Epoch [100/2000], Loss: 0.2503, Val Loss: 0.2503\n",
      "Epoch [200/2000], Loss: 0.2545, Val Loss: 0.2545\n",
      "Early stopping at epoch 243\n",
      "Training complete.\n",
      "Starting Round 99\n",
      "Epoch [100/2000], Loss: 0.2482, Val Loss: 0.2482\n",
      "Epoch [200/2000], Loss: 0.2468, Val Loss: 0.2468\n",
      "Early stopping at epoch 249\n",
      "Training complete.\n",
      "Starting Round 100\n",
      "Epoch [100/2000], Loss: 0.2863, Val Loss: 0.2863\n",
      "Epoch [200/2000], Loss: 0.2684, Val Loss: 0.2684\n",
      "Early stopping at epoch 280\n",
      "Training complete.\n",
      "Starting Round 101\n",
      "Epoch [100/2000], Loss: 0.2980, Val Loss: 0.2980\n",
      "Epoch [200/2000], Loss: 0.2806, Val Loss: 0.2806\n",
      "Epoch [300/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Early stopping at epoch 382\n",
      "Training complete.\n",
      "Starting Round 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.2583, Val Loss: 0.2583\n",
      "Epoch [200/2000], Loss: 0.2625, Val Loss: 0.2625\n",
      "Early stopping at epoch 227\n",
      "Training complete.\n",
      "Starting Round 103\n",
      "Epoch [100/2000], Loss: 0.2962, Val Loss: 0.2962\n",
      "Epoch [200/2000], Loss: 0.3003, Val Loss: 0.3003\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 104\n",
      "Epoch [100/2000], Loss: 0.2813, Val Loss: 0.2813\n",
      "Epoch [200/2000], Loss: 0.2824, Val Loss: 0.2824\n",
      "Epoch [300/2000], Loss: 0.2920, Val Loss: 0.2920\n",
      "Early stopping at epoch 317\n",
      "Training complete.\n",
      "Starting Round 105\n",
      "Epoch [100/2000], Loss: 0.2897, Val Loss: 0.2897\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 106\n",
      "Epoch [100/2000], Loss: 0.2861, Val Loss: 0.2861\n",
      "Epoch [200/2000], Loss: 0.2744, Val Loss: 0.2744\n",
      "Early stopping at epoch 295\n",
      "Training complete.\n",
      "Starting Round 107\n",
      "Epoch [100/2000], Loss: 0.2724, Val Loss: 0.2724\n",
      "Epoch [200/2000], Loss: 0.2642, Val Loss: 0.2642\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 108\n",
      "Epoch [100/2000], Loss: 0.2743, Val Loss: 0.2743\n",
      "Epoch [200/2000], Loss: 0.2742, Val Loss: 0.2742\n",
      "Early stopping at epoch 267\n",
      "Training complete.\n",
      "Starting Round 109\n",
      "Epoch [100/2000], Loss: 0.2764, Val Loss: 0.2764\n",
      "Epoch [200/2000], Loss: 0.2718, Val Loss: 0.2718\n",
      "Early stopping at epoch 208\n",
      "Training complete.\n",
      "Starting Round 110\n",
      "Epoch [100/2000], Loss: 0.2257, Val Loss: 0.2257\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 111\n",
      "Epoch [100/2000], Loss: 0.2017, Val Loss: 0.2017\n",
      "Epoch [200/2000], Loss: 0.2019, Val Loss: 0.2019\n",
      "Early stopping at epoch 291\n",
      "Training complete.\n",
      "Starting Round 112\n",
      "Epoch [100/2000], Loss: 0.2906, Val Loss: 0.2906\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 113\n",
      "Epoch [100/2000], Loss: 0.3026, Val Loss: 0.3026\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 114\n",
      "Epoch [100/2000], Loss: 0.2786, Val Loss: 0.2786\n",
      "Epoch [200/2000], Loss: 0.2704, Val Loss: 0.2704\n",
      "Epoch [300/2000], Loss: 0.2696, Val Loss: 0.2696\n",
      "Epoch [400/2000], Loss: 0.2639, Val Loss: 0.2639\n",
      "Early stopping at epoch 401\n",
      "Training complete.\n",
      "Starting Round 115\n",
      "Epoch [100/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Epoch [200/2000], Loss: 0.2480, Val Loss: 0.2480\n",
      "Early stopping at epoch 247\n",
      "Training complete.\n",
      "Starting Round 116\n",
      "Epoch [100/2000], Loss: 0.2795, Val Loss: 0.2795\n",
      "Epoch [200/2000], Loss: 0.2741, Val Loss: 0.2741\n",
      "Early stopping at epoch 207\n",
      "Training complete.\n",
      "Starting Round 117\n",
      "Epoch [100/2000], Loss: 0.2799, Val Loss: 0.2799\n",
      "Early stopping at epoch 169\n",
      "Training complete.\n",
      "Starting Round 118\n",
      "Epoch [100/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Epoch [200/2000], Loss: 0.2492, Val Loss: 0.2492\n",
      "Epoch [300/2000], Loss: 0.2555, Val Loss: 0.2555\n",
      "Epoch [400/2000], Loss: 0.2675, Val Loss: 0.2675\n",
      "Early stopping at epoch 454\n",
      "Training complete.\n",
      "Starting Round 119\n",
      "Epoch [100/2000], Loss: 0.2560, Val Loss: 0.2560\n",
      "Epoch [200/2000], Loss: 0.2623, Val Loss: 0.2623\n",
      "Early stopping at epoch 277\n",
      "Training complete.\n",
      "Starting Round 120\n",
      "Epoch [100/2000], Loss: 0.3269, Val Loss: 0.3269\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 121\n",
      "Epoch [100/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Epoch [200/2000], Loss: 0.2386, Val Loss: 0.2386\n",
      "Early stopping at epoch 206\n",
      "Training complete.\n",
      "Starting Round 122\n",
      "Epoch [100/2000], Loss: 0.2287, Val Loss: 0.2287\n",
      "Epoch [200/2000], Loss: 0.2439, Val Loss: 0.2439\n",
      "Early stopping at epoch 261\n",
      "Training complete.\n",
      "Starting Round 123\n",
      "Epoch [100/2000], Loss: 0.2810, Val Loss: 0.2810\n",
      "Epoch [200/2000], Loss: 0.2840, Val Loss: 0.2840\n",
      "Early stopping at epoch 216\n",
      "Training complete.\n",
      "Starting Round 124\n",
      "Epoch [100/2000], Loss: 0.2818, Val Loss: 0.2818\n",
      "Epoch [200/2000], Loss: 0.2964, Val Loss: 0.2964\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 125\n",
      "Epoch [100/2000], Loss: 0.2582, Val Loss: 0.2582\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 126\n",
      "Epoch [100/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 127\n",
      "Epoch [100/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Early stopping at epoch 170\n",
      "Training complete.\n",
      "Starting Round 128\n",
      "Epoch [100/2000], Loss: 0.2725, Val Loss: 0.2725\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 129\n",
      "Epoch [100/2000], Loss: 0.2971, Val Loss: 0.2971\n",
      "Epoch [200/2000], Loss: 0.3004, Val Loss: 0.3004\n",
      "Early stopping at epoch 268\n",
      "Training complete.\n",
      "Starting Round 130\n",
      "Epoch [100/2000], Loss: 0.2811, Val Loss: 0.2811\n",
      "Epoch [200/2000], Loss: 0.2710, Val Loss: 0.2710\n",
      "Early stopping at epoch 278\n",
      "Training complete.\n",
      "Starting Round 131\n",
      "Epoch [100/2000], Loss: 0.2582, Val Loss: 0.2582\n",
      "Epoch [200/2000], Loss: 0.2698, Val Loss: 0.2698\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 132\n",
      "Epoch [100/2000], Loss: 0.2832, Val Loss: 0.2832\n",
      "Epoch [200/2000], Loss: 0.2846, Val Loss: 0.2846\n",
      "Early stopping at epoch 265\n",
      "Training complete.\n",
      "Starting Round 133\n",
      "Epoch [100/2000], Loss: 0.2662, Val Loss: 0.2662\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 134\n",
      "Epoch [100/2000], Loss: 0.2145, Val Loss: 0.2145\n",
      "Epoch [200/2000], Loss: 0.2186, Val Loss: 0.2186\n",
      "Early stopping at epoch 210\n",
      "Training complete.\n",
      "Starting Round 135\n",
      "Epoch [100/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Epoch [200/2000], Loss: 0.2487, Val Loss: 0.2487\n",
      "Epoch [300/2000], Loss: 0.2496, Val Loss: 0.2496\n",
      "Early stopping at epoch 307\n",
      "Training complete.\n",
      "Starting Round 136\n",
      "Epoch [100/2000], Loss: 0.2839, Val Loss: 0.2839\n",
      "Epoch [200/2000], Loss: 0.2686, Val Loss: 0.2686\n",
      "Early stopping at epoch 236\n",
      "Training complete.\n",
      "Starting Round 137\n",
      "Epoch [100/2000], Loss: 0.2694, Val Loss: 0.2694\n",
      "Epoch [200/2000], Loss: 0.2485, Val Loss: 0.2485\n",
      "Epoch [300/2000], Loss: 0.2606, Val Loss: 0.2606\n",
      "Epoch [400/2000], Loss: 0.2498, Val Loss: 0.2498\n",
      "Early stopping at epoch 482\n",
      "Training complete.\n",
      "Starting Round 138\n",
      "Epoch [100/2000], Loss: 0.2914, Val Loss: 0.2914\n",
      "Epoch [200/2000], Loss: 0.2835, Val Loss: 0.2835\n",
      "Early stopping at epoch 214\n",
      "Training complete.\n",
      "Starting Round 139\n",
      "Epoch [100/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Epoch [200/2000], Loss: 0.2554, Val Loss: 0.2554\n",
      "Epoch [300/2000], Loss: 0.2477, Val Loss: 0.2477\n",
      "Early stopping at epoch 366\n",
      "Training complete.\n",
      "Starting Round 140\n",
      "Epoch [100/2000], Loss: 0.2547, Val Loss: 0.2547\n",
      "Epoch [200/2000], Loss: 0.2348, Val Loss: 0.2348\n",
      "Early stopping at epoch 300\n",
      "Training complete.\n",
      "Starting Round 141\n",
      "Epoch [100/2000], Loss: 0.2621, Val Loss: 0.2621\n",
      "Epoch [200/2000], Loss: 0.2647, Val Loss: 0.2647\n",
      "Epoch [300/2000], Loss: 0.2681, Val Loss: 0.2681\n",
      "Early stopping at epoch 356\n",
      "Training complete.\n",
      "Starting Round 142\n",
      "Epoch [100/2000], Loss: 0.2876, Val Loss: 0.2876\n",
      "Epoch [200/2000], Loss: 0.3013, Val Loss: 0.3013\n",
      "Early stopping at epoch 203\n",
      "Training complete.\n",
      "Starting Round 143\n",
      "Epoch [100/2000], Loss: 0.2740, Val Loss: 0.2740\n",
      "Early stopping at epoch 200\n",
      "Training complete.\n",
      "Starting Round 144\n",
      "Epoch [100/2000], Loss: 0.2794, Val Loss: 0.2794\n",
      "Epoch [200/2000], Loss: 0.2601, Val Loss: 0.2601\n",
      "Early stopping at epoch 218\n",
      "Training complete.\n",
      "Starting Round 145\n",
      "Epoch [100/2000], Loss: 0.2397, Val Loss: 0.2397\n",
      "Early stopping at epoch 153\n",
      "Training complete.\n",
      "Starting Round 146\n",
      "Epoch [100/2000], Loss: 0.2962, Val Loss: 0.2962\n",
      "Epoch [200/2000], Loss: 0.2855, Val Loss: 0.2855\n",
      "Epoch [300/2000], Loss: 0.2835, Val Loss: 0.2835\n",
      "Epoch [400/2000], Loss: 0.2953, Val Loss: 0.2953\n",
      "Early stopping at epoch 439\n",
      "Training complete.\n",
      "Starting Round 147\n",
      "Epoch [100/2000], Loss: 0.2871, Val Loss: 0.2871\n",
      "Epoch [200/2000], Loss: 0.2724, Val Loss: 0.2724\n",
      "Early stopping at epoch 268\n",
      "Training complete.\n",
      "Starting Round 148\n",
      "Epoch [100/2000], Loss: 0.2113, Val Loss: 0.2113\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 149\n",
      "Epoch [100/2000], Loss: 0.2227, Val Loss: 0.2227\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 150\n",
      "Epoch [100/2000], Loss: 0.2545, Val Loss: 0.2545\n",
      "Early stopping at epoch 195\n",
      "Training complete.\n",
      "Starting Round 151\n",
      "Epoch [100/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Epoch [200/2000], Loss: 0.2350, Val Loss: 0.2350\n",
      "Epoch [300/2000], Loss: 0.2324, Val Loss: 0.2324\n",
      "Early stopping at epoch 356\n",
      "Training complete.\n",
      "Starting Round 152\n",
      "Epoch [100/2000], Loss: 0.3001, Val Loss: 0.3001\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 153\n",
      "Epoch [100/2000], Loss: 0.2647, Val Loss: 0.2647\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.2815, Val Loss: 0.2815\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 155\n",
      "Epoch [100/2000], Loss: 0.2677, Val Loss: 0.2677\n",
      "Epoch [200/2000], Loss: 0.2507, Val Loss: 0.2507\n",
      "Epoch [300/2000], Loss: 0.2485, Val Loss: 0.2485\n",
      "Epoch [400/2000], Loss: 0.2444, Val Loss: 0.2444\n",
      "Epoch [500/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Early stopping at epoch 501\n",
      "Training complete.\n",
      "Starting Round 156\n",
      "Epoch [100/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Epoch [200/2000], Loss: 0.2244, Val Loss: 0.2244\n",
      "Early stopping at epoch 238\n",
      "Training complete.\n",
      "Starting Round 157\n",
      "Epoch [100/2000], Loss: 0.2456, Val Loss: 0.2456\n",
      "Epoch [200/2000], Loss: 0.2466, Val Loss: 0.2466\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 158\n",
      "Epoch [100/2000], Loss: 0.2426, Val Loss: 0.2426\n",
      "Epoch [200/2000], Loss: 0.2295, Val Loss: 0.2295\n",
      "Epoch [300/2000], Loss: 0.2260, Val Loss: 0.2260\n",
      "Epoch [400/2000], Loss: 0.2206, Val Loss: 0.2206\n",
      "Early stopping at epoch 492\n",
      "Training complete.\n",
      "Starting Round 159\n",
      "Epoch [100/2000], Loss: 0.2117, Val Loss: 0.2117\n",
      "Epoch [200/2000], Loss: 0.2150, Val Loss: 0.2150\n",
      "Early stopping at epoch 250\n",
      "Training complete.\n",
      "Starting Round 160\n",
      "Epoch [100/2000], Loss: 0.2560, Val Loss: 0.2560\n",
      "Epoch [200/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Epoch [300/2000], Loss: 0.2484, Val Loss: 0.2484\n",
      "Early stopping at epoch 346\n",
      "Training complete.\n",
      "Starting Round 161\n",
      "Epoch [100/2000], Loss: 0.2485, Val Loss: 0.2485\n",
      "Epoch [200/2000], Loss: 0.2470, Val Loss: 0.2470\n",
      "Epoch [300/2000], Loss: 0.2364, Val Loss: 0.2364\n",
      "Epoch [400/2000], Loss: 0.2493, Val Loss: 0.2493\n",
      "Early stopping at epoch 409\n",
      "Training complete.\n",
      "Starting Round 162\n",
      "Epoch [100/2000], Loss: 0.2375, Val Loss: 0.2375\n",
      "Early stopping at epoch 138\n",
      "Training complete.\n",
      "Starting Round 163\n",
      "Epoch [100/2000], Loss: 0.2712, Val Loss: 0.2712\n",
      "Epoch [200/2000], Loss: 0.2738, Val Loss: 0.2738\n",
      "Epoch [300/2000], Loss: 0.2780, Val Loss: 0.2780\n",
      "Early stopping at epoch 355\n",
      "Training complete.\n",
      "Starting Round 164\n",
      "Epoch [100/2000], Loss: 0.2591, Val Loss: 0.2591\n",
      "Epoch [200/2000], Loss: 0.2468, Val Loss: 0.2468\n",
      "Early stopping at epoch 213\n",
      "Training complete.\n",
      "Starting Round 165\n",
      "Epoch [100/2000], Loss: 0.2491, Val Loss: 0.2491\n",
      "Epoch [200/2000], Loss: 0.2453, Val Loss: 0.2453\n",
      "Early stopping at epoch 287\n",
      "Training complete.\n",
      "Starting Round 166\n",
      "Epoch [100/2000], Loss: 0.2648, Val Loss: 0.2648\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 167\n",
      "Epoch [100/2000], Loss: 0.2680, Val Loss: 0.2680\n",
      "Epoch [200/2000], Loss: 0.2661, Val Loss: 0.2661\n",
      "Early stopping at epoch 268\n",
      "Training complete.\n",
      "Starting Round 168\n",
      "Epoch [100/2000], Loss: 0.2470, Val Loss: 0.2470\n",
      "Epoch [200/2000], Loss: 0.2505, Val Loss: 0.2505\n",
      "Early stopping at epoch 225\n",
      "Training complete.\n",
      "Starting Round 169\n",
      "Epoch [100/2000], Loss: 0.2721, Val Loss: 0.2721\n",
      "Epoch [200/2000], Loss: 0.2574, Val Loss: 0.2574\n",
      "Epoch [300/2000], Loss: 0.2502, Val Loss: 0.2502\n",
      "Early stopping at epoch 337\n",
      "Training complete.\n",
      "Starting Round 170\n",
      "Epoch [100/2000], Loss: 0.2600, Val Loss: 0.2600\n",
      "Epoch [200/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Epoch [300/2000], Loss: 0.2414, Val Loss: 0.2414\n",
      "Epoch [400/2000], Loss: 0.2356, Val Loss: 0.2356\n",
      "Epoch [500/2000], Loss: 0.2342, Val Loss: 0.2342\n",
      "Early stopping at epoch 570\n",
      "Training complete.\n",
      "Starting Round 171\n",
      "Epoch [100/2000], Loss: 0.2544, Val Loss: 0.2544\n",
      "Epoch [200/2000], Loss: 0.2495, Val Loss: 0.2495\n",
      "Early stopping at epoch 206\n",
      "Training complete.\n",
      "Starting Round 172\n",
      "Epoch [100/2000], Loss: 0.2940, Val Loss: 0.2940\n",
      "Epoch [200/2000], Loss: 0.2885, Val Loss: 0.2885\n",
      "Early stopping at epoch 218\n",
      "Training complete.\n",
      "Starting Round 173\n",
      "Epoch [100/2000], Loss: 0.2199, Val Loss: 0.2199\n",
      "Epoch [200/2000], Loss: 0.2289, Val Loss: 0.2289\n",
      "Early stopping at epoch 217\n",
      "Training complete.\n",
      "Starting Round 174\n",
      "Epoch [100/2000], Loss: 0.2394, Val Loss: 0.2394\n",
      "Epoch [200/2000], Loss: 0.2396, Val Loss: 0.2396\n",
      "Early stopping at epoch 291\n",
      "Training complete.\n",
      "Starting Round 175\n",
      "Epoch [100/2000], Loss: 0.2312, Val Loss: 0.2312\n",
      "Early stopping at epoch 187\n",
      "Training complete.\n",
      "Starting Round 176\n",
      "Epoch [100/2000], Loss: 0.2296, Val Loss: 0.2296\n",
      "Epoch [200/2000], Loss: 0.2297, Val Loss: 0.2297\n",
      "Early stopping at epoch 261\n",
      "Training complete.\n",
      "Starting Round 177\n",
      "Epoch [100/2000], Loss: 0.2525, Val Loss: 0.2525\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 178\n",
      "Epoch [100/2000], Loss: 0.2308, Val Loss: 0.2308\n",
      "Epoch [200/2000], Loss: 0.2265, Val Loss: 0.2265\n",
      "Epoch [300/2000], Loss: 0.2268, Val Loss: 0.2268\n",
      "Early stopping at epoch 301\n",
      "Training complete.\n",
      "Starting Round 179\n",
      "Epoch [100/2000], Loss: 0.2623, Val Loss: 0.2623\n",
      "Epoch [200/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Early stopping at epoch 213\n",
      "Training complete.\n",
      "Starting Round 180\n",
      "Epoch [100/2000], Loss: 0.2169, Val Loss: 0.2169\n",
      "Epoch [200/2000], Loss: 0.2124, Val Loss: 0.2124\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 181\n",
      "Epoch [100/2000], Loss: 0.2571, Val Loss: 0.2571\n",
      "Epoch [200/2000], Loss: 0.2692, Val Loss: 0.2692\n",
      "Epoch [300/2000], Loss: 0.2650, Val Loss: 0.2650\n",
      "Early stopping at epoch 303\n",
      "Training complete.\n",
      "Starting Round 182\n",
      "Epoch [100/2000], Loss: 0.3014, Val Loss: 0.3014\n",
      "Epoch [200/2000], Loss: 0.2933, Val Loss: 0.2933\n",
      "Epoch [300/2000], Loss: 0.2993, Val Loss: 0.2993\n",
      "Early stopping at epoch 390\n",
      "Training complete.\n",
      "Starting Round 183\n",
      "Epoch [100/2000], Loss: 0.2515, Val Loss: 0.2515\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 184\n",
      "Epoch [100/2000], Loss: 0.2024, Val Loss: 0.2024\n",
      "Epoch [200/2000], Loss: 0.1899, Val Loss: 0.1899\n",
      "Early stopping at epoch 249\n",
      "Training complete.\n",
      "Starting Round 185\n",
      "Epoch [100/2000], Loss: 0.2334, Val Loss: 0.2334\n",
      "Epoch [200/2000], Loss: 0.2495, Val Loss: 0.2495\n",
      "Early stopping at epoch 252\n",
      "Training complete.\n",
      "Starting Round 186\n",
      "Epoch [100/2000], Loss: 0.2602, Val Loss: 0.2602\n",
      "Epoch [200/2000], Loss: 0.2433, Val Loss: 0.2433\n",
      "Early stopping at epoch 286\n",
      "Training complete.\n",
      "Starting Round 187\n",
      "Epoch [100/2000], Loss: 0.2108, Val Loss: 0.2108\n",
      "Epoch [200/2000], Loss: 0.2044, Val Loss: 0.2044\n",
      "Early stopping at epoch 244\n",
      "Training complete.\n",
      "Starting Round 188\n",
      "Epoch [100/2000], Loss: 0.2833, Val Loss: 0.2833\n",
      "Epoch [200/2000], Loss: 0.2879, Val Loss: 0.2879\n",
      "Early stopping at epoch 221\n",
      "Training complete.\n",
      "Starting Round 189\n",
      "Epoch [100/2000], Loss: 0.2259, Val Loss: 0.2259\n",
      "Epoch [200/2000], Loss: 0.2302, Val Loss: 0.2302\n",
      "Epoch [300/2000], Loss: 0.2234, Val Loss: 0.2234\n",
      "Early stopping at epoch 329\n",
      "Training complete.\n",
      "Starting Round 190\n",
      "Epoch [100/2000], Loss: 0.2322, Val Loss: 0.2322\n",
      "Epoch [200/2000], Loss: 0.2382, Val Loss: 0.2382\n",
      "Early stopping at epoch 290\n",
      "Training complete.\n",
      "Starting Round 191\n",
      "Epoch [100/2000], Loss: 0.2878, Val Loss: 0.2878\n",
      "Epoch [200/2000], Loss: 0.2721, Val Loss: 0.2721\n",
      "Early stopping at epoch 239\n",
      "Training complete.\n",
      "Starting Round 192\n",
      "Epoch [100/2000], Loss: 0.2516, Val Loss: 0.2516\n",
      "Epoch [200/2000], Loss: 0.2461, Val Loss: 0.2461\n",
      "Epoch [300/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Early stopping at epoch 345\n",
      "Training complete.\n",
      "Starting Round 193\n",
      "Epoch [100/2000], Loss: 0.2364, Val Loss: 0.2364\n",
      "Epoch [200/2000], Loss: 0.2251, Val Loss: 0.2251\n",
      "Early stopping at epoch 266\n",
      "Training complete.\n",
      "Starting Round 194\n",
      "Epoch [100/2000], Loss: 0.2468, Val Loss: 0.2468\n",
      "Epoch [200/2000], Loss: 0.2578, Val Loss: 0.2578\n",
      "Epoch [300/2000], Loss: 0.2643, Val Loss: 0.2643\n",
      "Epoch [400/2000], Loss: 0.2428, Val Loss: 0.2428\n",
      "Early stopping at epoch 448\n",
      "Training complete.\n",
      "Starting Round 195\n",
      "Epoch [100/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 196\n",
      "Epoch [100/2000], Loss: 0.2457, Val Loss: 0.2457\n",
      "Epoch [200/2000], Loss: 0.2718, Val Loss: 0.2718\n",
      "Early stopping at epoch 219\n",
      "Training complete.\n",
      "Starting Round 197\n",
      "Epoch [100/2000], Loss: 0.2330, Val Loss: 0.2330\n",
      "Epoch [200/2000], Loss: 0.2137, Val Loss: 0.2137\n",
      "Early stopping at epoch 279\n",
      "Training complete.\n",
      "Starting Round 198\n",
      "Epoch [100/2000], Loss: 0.2774, Val Loss: 0.2774\n",
      "Early stopping at epoch 160\n",
      "Training complete.\n",
      "Starting Round 199\n",
      "Epoch [100/2000], Loss: 0.3130, Val Loss: 0.3130\n",
      "Epoch [200/2000], Loss: 0.2829, Val Loss: 0.2829\n",
      "Early stopping at epoch 257\n",
      "Training complete.\n",
      "Starting Round 200\n",
      "Epoch [100/2000], Loss: 0.2942, Val Loss: 0.2942\n",
      "Epoch [200/2000], Loss: 0.3013, Val Loss: 0.3013\n",
      "Early stopping at epoch 234\n",
      "Training complete.\n",
      "Starting Round 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.2014, Val Loss: 0.2014\n",
      "Epoch [200/2000], Loss: 0.2011, Val Loss: 0.2011\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 202\n",
      "Epoch [100/2000], Loss: 0.2730, Val Loss: 0.2730\n",
      "Early stopping at epoch 194\n",
      "Training complete.\n",
      "Starting Round 203\n",
      "Epoch [100/2000], Loss: 0.2645, Val Loss: 0.2645\n",
      "Epoch [200/2000], Loss: 0.2538, Val Loss: 0.2538\n",
      "Early stopping at epoch 245\n",
      "Training complete.\n",
      "Starting Round 204\n",
      "Epoch [100/2000], Loss: 0.2812, Val Loss: 0.2812\n",
      "Epoch [200/2000], Loss: 0.2655, Val Loss: 0.2655\n",
      "Epoch [300/2000], Loss: 0.2632, Val Loss: 0.2632\n",
      "Early stopping at epoch 309\n",
      "Training complete.\n",
      "Starting Round 205\n",
      "Epoch [100/2000], Loss: 0.2558, Val Loss: 0.2558\n",
      "Epoch [200/2000], Loss: 0.2479, Val Loss: 0.2479\n",
      "Epoch [300/2000], Loss: 0.2427, Val Loss: 0.2427\n",
      "Early stopping at epoch 367\n",
      "Training complete.\n",
      "Starting Round 206\n",
      "Epoch [100/2000], Loss: 0.2385, Val Loss: 0.2385\n",
      "Epoch [200/2000], Loss: 0.2386, Val Loss: 0.2386\n",
      "Early stopping at epoch 201\n",
      "Training complete.\n",
      "Starting Round 207\n",
      "Epoch [100/2000], Loss: 0.2654, Val Loss: 0.2654\n",
      "Epoch [200/2000], Loss: 0.2631, Val Loss: 0.2631\n",
      "Epoch [300/2000], Loss: 0.2534, Val Loss: 0.2534\n",
      "Early stopping at epoch 342\n",
      "Training complete.\n",
      "Starting Round 208\n",
      "Epoch [100/2000], Loss: 0.2617, Val Loss: 0.2617\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 209\n",
      "Epoch [100/2000], Loss: 0.2350, Val Loss: 0.2350\n",
      "Epoch [200/2000], Loss: 0.2305, Val Loss: 0.2305\n",
      "Early stopping at epoch 219\n",
      "Training complete.\n",
      "Starting Round 210\n",
      "Epoch [100/2000], Loss: 0.2371, Val Loss: 0.2371\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 211\n",
      "Epoch [100/2000], Loss: 0.2477, Val Loss: 0.2477\n",
      "Epoch [200/2000], Loss: 0.2397, Val Loss: 0.2397\n",
      "Epoch [300/2000], Loss: 0.2502, Val Loss: 0.2502\n",
      "Early stopping at epoch 370\n",
      "Training complete.\n",
      "Starting Round 212\n",
      "Epoch [100/2000], Loss: 0.2674, Val Loss: 0.2674\n",
      "Epoch [200/2000], Loss: 0.2508, Val Loss: 0.2508\n",
      "Epoch [300/2000], Loss: 0.2530, Val Loss: 0.2530\n",
      "Early stopping at epoch 350\n",
      "Training complete.\n",
      "Starting Round 213\n",
      "Epoch [100/2000], Loss: 0.2692, Val Loss: 0.2692\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 214\n",
      "Epoch [100/2000], Loss: 0.2309, Val Loss: 0.2309\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 215\n",
      "Epoch [100/2000], Loss: 0.2606, Val Loss: 0.2606\n",
      "Epoch [200/2000], Loss: 0.2552, Val Loss: 0.2552\n",
      "Early stopping at epoch 221\n",
      "Training complete.\n",
      "Starting Round 216\n",
      "Epoch [100/2000], Loss: 0.2916, Val Loss: 0.2916\n",
      "Early stopping at epoch 168\n",
      "Training complete.\n",
      "Starting Round 217\n",
      "Epoch [100/2000], Loss: 0.2731, Val Loss: 0.2731\n",
      "Epoch [200/2000], Loss: 0.2536, Val Loss: 0.2536\n",
      "Epoch [300/2000], Loss: 0.2387, Val Loss: 0.2387\n",
      "Epoch [400/2000], Loss: 0.2640, Val Loss: 0.2640\n",
      "Early stopping at epoch 449\n",
      "Training complete.\n",
      "Starting Round 218\n",
      "Epoch [100/2000], Loss: 0.2544, Val Loss: 0.2544\n",
      "Epoch [200/2000], Loss: 0.2437, Val Loss: 0.2437\n",
      "Early stopping at epoch 295\n",
      "Training complete.\n",
      "Starting Round 219\n",
      "Epoch [100/2000], Loss: 0.2709, Val Loss: 0.2709\n",
      "Epoch [200/2000], Loss: 0.2435, Val Loss: 0.2435\n",
      "Epoch [300/2000], Loss: 0.2332, Val Loss: 0.2332\n",
      "Epoch [400/2000], Loss: 0.2511, Val Loss: 0.2511\n",
      "Early stopping at epoch 468\n",
      "Training complete.\n",
      "Starting Round 220\n",
      "Epoch [100/2000], Loss: 0.2822, Val Loss: 0.2822\n",
      "Early stopping at epoch 138\n",
      "Training complete.\n",
      "Starting Round 221\n",
      "Epoch [100/2000], Loss: 0.2663, Val Loss: 0.2663\n",
      "Epoch [200/2000], Loss: 0.2747, Val Loss: 0.2747\n",
      "Early stopping at epoch 233\n",
      "Training complete.\n",
      "Starting Round 222\n",
      "Epoch [100/2000], Loss: 0.2476, Val Loss: 0.2476\n",
      "Epoch [200/2000], Loss: 0.2273, Val Loss: 0.2273\n",
      "Epoch [300/2000], Loss: 0.2384, Val Loss: 0.2384\n",
      "Early stopping at epoch 377\n",
      "Training complete.\n",
      "Starting Round 223\n",
      "Epoch [100/2000], Loss: 0.2720, Val Loss: 0.2720\n",
      "Epoch [200/2000], Loss: 0.2743, Val Loss: 0.2743\n",
      "Early stopping at epoch 238\n",
      "Training complete.\n",
      "Starting Round 224\n",
      "Epoch [100/2000], Loss: 0.3050, Val Loss: 0.3050\n",
      "Epoch [200/2000], Loss: 0.2783, Val Loss: 0.2783\n",
      "Epoch [300/2000], Loss: 0.2775, Val Loss: 0.2775\n",
      "Epoch [400/2000], Loss: 0.2899, Val Loss: 0.2899\n",
      "Early stopping at epoch 489\n",
      "Training complete.\n",
      "Starting Round 225\n",
      "Epoch [100/2000], Loss: 0.2250, Val Loss: 0.2250\n",
      "Epoch [200/2000], Loss: 0.2399, Val Loss: 0.2399\n",
      "Epoch [300/2000], Loss: 0.2461, Val Loss: 0.2461\n",
      "Early stopping at epoch 354\n",
      "Training complete.\n",
      "Starting Round 226\n",
      "Epoch [100/2000], Loss: 0.2483, Val Loss: 0.2483\n",
      "Epoch [200/2000], Loss: 0.2437, Val Loss: 0.2437\n",
      "Epoch [300/2000], Loss: 0.2351, Val Loss: 0.2351\n",
      "Epoch [400/2000], Loss: 0.2312, Val Loss: 0.2312\n",
      "Early stopping at epoch 482\n",
      "Training complete.\n",
      "Starting Round 227\n",
      "Epoch [100/2000], Loss: 0.2828, Val Loss: 0.2828\n",
      "Epoch [200/2000], Loss: 0.2731, Val Loss: 0.2731\n",
      "Epoch [300/2000], Loss: 0.2678, Val Loss: 0.2678\n",
      "Early stopping at epoch 323\n",
      "Training complete.\n",
      "Starting Round 228\n",
      "Epoch [100/2000], Loss: 0.2176, Val Loss: 0.2176\n",
      "Epoch [200/2000], Loss: 0.2208, Val Loss: 0.2208\n",
      "Early stopping at epoch 278\n",
      "Training complete.\n",
      "Starting Round 229\n",
      "Epoch [100/2000], Loss: 0.2713, Val Loss: 0.2713\n",
      "Epoch [200/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Early stopping at epoch 255\n",
      "Training complete.\n",
      "Starting Round 230\n",
      "Epoch [100/2000], Loss: 0.2789, Val Loss: 0.2789\n",
      "Epoch [200/2000], Loss: 0.2870, Val Loss: 0.2870\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 231\n",
      "Epoch [100/2000], Loss: 0.2357, Val Loss: 0.2357\n",
      "Epoch [200/2000], Loss: 0.2223, Val Loss: 0.2223\n",
      "Epoch [300/2000], Loss: 0.2248, Val Loss: 0.2248\n",
      "Epoch [400/2000], Loss: 0.2275, Val Loss: 0.2275\n",
      "Early stopping at epoch 489\n",
      "Training complete.\n",
      "Starting Round 232\n",
      "Epoch [100/2000], Loss: 0.2595, Val Loss: 0.2595\n",
      "Epoch [200/2000], Loss: 0.2444, Val Loss: 0.2444\n",
      "Epoch [300/2000], Loss: 0.2427, Val Loss: 0.2427\n",
      "Early stopping at epoch 385\n",
      "Training complete.\n",
      "Starting Round 233\n",
      "Epoch [100/2000], Loss: 0.2979, Val Loss: 0.2979\n",
      "Epoch [200/2000], Loss: 0.3001, Val Loss: 0.3001\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 234\n",
      "Epoch [100/2000], Loss: 0.2738, Val Loss: 0.2738\n",
      "Epoch [200/2000], Loss: 0.2890, Val Loss: 0.2890\n",
      "Early stopping at epoch 241\n",
      "Training complete.\n",
      "Starting Round 235\n",
      "Epoch [100/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Epoch [200/2000], Loss: 0.2502, Val Loss: 0.2502\n",
      "Epoch [300/2000], Loss: 0.2656, Val Loss: 0.2656\n",
      "Early stopping at epoch 303\n",
      "Training complete.\n",
      "Starting Round 236\n",
      "Epoch [100/2000], Loss: 0.2568, Val Loss: 0.2568\n",
      "Epoch [200/2000], Loss: 0.2497, Val Loss: 0.2497\n",
      "Epoch [300/2000], Loss: 0.2379, Val Loss: 0.2379\n",
      "Early stopping at epoch 397\n",
      "Training complete.\n",
      "Starting Round 237\n",
      "Epoch [100/2000], Loss: 0.2603, Val Loss: 0.2603\n",
      "Early stopping at epoch 158\n",
      "Training complete.\n",
      "Starting Round 238\n",
      "Epoch [100/2000], Loss: 0.2514, Val Loss: 0.2514\n",
      "Early stopping at epoch 182\n",
      "Training complete.\n",
      "Starting Round 239\n",
      "Epoch [100/2000], Loss: 0.2626, Val Loss: 0.2626\n",
      "Epoch [200/2000], Loss: 0.2404, Val Loss: 0.2404\n",
      "Epoch [300/2000], Loss: 0.2494, Val Loss: 0.2494\n",
      "Early stopping at epoch 304\n",
      "Training complete.\n",
      "Starting Round 240\n",
      "Epoch [100/2000], Loss: 0.2584, Val Loss: 0.2584\n",
      "Epoch [200/2000], Loss: 0.2453, Val Loss: 0.2453\n",
      "Epoch [300/2000], Loss: 0.2705, Val Loss: 0.2705\n",
      "Early stopping at epoch 332\n",
      "Training complete.\n",
      "Starting Round 241\n",
      "Epoch [100/2000], Loss: 0.2411, Val Loss: 0.2411\n",
      "Epoch [200/2000], Loss: 0.2239, Val Loss: 0.2239\n",
      "Epoch [300/2000], Loss: 0.2159, Val Loss: 0.2159\n",
      "Epoch [400/2000], Loss: 0.2302, Val Loss: 0.2302\n",
      "Early stopping at epoch 494\n",
      "Training complete.\n",
      "Starting Round 242\n",
      "Epoch [100/2000], Loss: 0.2779, Val Loss: 0.2779\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 243\n",
      "Epoch [100/2000], Loss: 0.2693, Val Loss: 0.2693\n",
      "Epoch [200/2000], Loss: 0.2761, Val Loss: 0.2761\n",
      "Early stopping at epoch 207\n",
      "Training complete.\n",
      "Starting Round 244\n",
      "Epoch [100/2000], Loss: 0.2384, Val Loss: 0.2384\n",
      "Epoch [200/2000], Loss: 0.2387, Val Loss: 0.2387\n",
      "Epoch [300/2000], Loss: 0.2368, Val Loss: 0.2368\n",
      "Early stopping at epoch 317\n",
      "Training complete.\n",
      "Starting Round 245\n",
      "Epoch [100/2000], Loss: 0.2813, Val Loss: 0.2813\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 246\n",
      "Epoch [100/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Epoch [200/2000], Loss: 0.2305, Val Loss: 0.2305\n",
      "Epoch [300/2000], Loss: 0.2302, Val Loss: 0.2302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 354\n",
      "Training complete.\n",
      "Starting Round 247\n",
      "Epoch [100/2000], Loss: 0.2322, Val Loss: 0.2322\n",
      "Epoch [200/2000], Loss: 0.2564, Val Loss: 0.2564\n",
      "Early stopping at epoch 238\n",
      "Training complete.\n",
      "Starting Round 248\n",
      "Epoch [100/2000], Loss: 0.2407, Val Loss: 0.2407\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 249\n",
      "Epoch [100/2000], Loss: 0.2556, Val Loss: 0.2556\n",
      "Epoch [200/2000], Loss: 0.2692, Val Loss: 0.2692\n",
      "Epoch [300/2000], Loss: 0.2448, Val Loss: 0.2448\n",
      "Epoch [400/2000], Loss: 0.2372, Val Loss: 0.2372\n",
      "Early stopping at epoch 408\n",
      "Training complete.\n",
      "Starting Round 250\n",
      "Epoch [100/2000], Loss: 0.2607, Val Loss: 0.2607\n",
      "Epoch [200/2000], Loss: 0.2655, Val Loss: 0.2655\n",
      "Early stopping at epoch 206\n",
      "Training complete.\n",
      "Starting Round 251\n",
      "Epoch [100/2000], Loss: 0.2530, Val Loss: 0.2530\n",
      "Early stopping at epoch 162\n",
      "Training complete.\n",
      "Starting Round 252\n",
      "Epoch [100/2000], Loss: 0.2632, Val Loss: 0.2632\n",
      "Epoch [200/2000], Loss: 0.2639, Val Loss: 0.2639\n",
      "Early stopping at epoch 223\n",
      "Training complete.\n",
      "Starting Round 253\n",
      "Epoch [100/2000], Loss: 0.2746, Val Loss: 0.2746\n",
      "Epoch [200/2000], Loss: 0.2808, Val Loss: 0.2808\n",
      "Epoch [300/2000], Loss: 0.2685, Val Loss: 0.2685\n",
      "Epoch [400/2000], Loss: 0.2710, Val Loss: 0.2710\n",
      "Early stopping at epoch 409\n",
      "Training complete.\n",
      "Starting Round 254\n",
      "Epoch [100/2000], Loss: 0.2186, Val Loss: 0.2186\n",
      "Epoch [200/2000], Loss: 0.2203, Val Loss: 0.2203\n",
      "Epoch [300/2000], Loss: 0.2058, Val Loss: 0.2058\n",
      "Epoch [400/2000], Loss: 0.2189, Val Loss: 0.2189\n",
      "Epoch [500/2000], Loss: 0.2077, Val Loss: 0.2077\n",
      "Epoch [600/2000], Loss: 0.2141, Val Loss: 0.2141\n",
      "Early stopping at epoch 634\n",
      "Training complete.\n",
      "Starting Round 255\n",
      "Epoch [100/2000], Loss: 0.2928, Val Loss: 0.2928\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 256\n",
      "Epoch [100/2000], Loss: 0.2819, Val Loss: 0.2819\n",
      "Early stopping at epoch 159\n",
      "Training complete.\n",
      "Starting Round 257\n",
      "Epoch [100/2000], Loss: 0.2905, Val Loss: 0.2905\n",
      "Early stopping at epoch 139\n",
      "Training complete.\n",
      "Starting Round 258\n",
      "Epoch [100/2000], Loss: 0.2212, Val Loss: 0.2212\n",
      "Epoch [200/2000], Loss: 0.2196, Val Loss: 0.2196\n",
      "Early stopping at epoch 271\n",
      "Training complete.\n",
      "Starting Round 259\n",
      "Epoch [100/2000], Loss: 0.2651, Val Loss: 0.2651\n",
      "Epoch [200/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Early stopping at epoch 229\n",
      "Training complete.\n",
      "Starting Round 260\n",
      "Epoch [100/2000], Loss: 0.2508, Val Loss: 0.2508\n",
      "Early stopping at epoch 154\n",
      "Training complete.\n",
      "Starting Round 261\n",
      "Epoch [100/2000], Loss: 0.2865, Val Loss: 0.2865\n",
      "Epoch [200/2000], Loss: 0.2718, Val Loss: 0.2718\n",
      "Epoch [300/2000], Loss: 0.2599, Val Loss: 0.2599\n",
      "Early stopping at epoch 370\n",
      "Training complete.\n",
      "Starting Round 262\n",
      "Epoch [100/2000], Loss: 0.2597, Val Loss: 0.2597\n",
      "Epoch [200/2000], Loss: 0.2435, Val Loss: 0.2435\n",
      "Early stopping at epoch 298\n",
      "Training complete.\n",
      "Starting Round 263\n",
      "Epoch [100/2000], Loss: 0.2185, Val Loss: 0.2185\n",
      "Epoch [200/2000], Loss: 0.2214, Val Loss: 0.2214\n",
      "Epoch [300/2000], Loss: 0.2261, Val Loss: 0.2261\n",
      "Epoch [400/2000], Loss: 0.2128, Val Loss: 0.2128\n",
      "Early stopping at epoch 445\n",
      "Training complete.\n",
      "Starting Round 264\n",
      "Epoch [100/2000], Loss: 0.2508, Val Loss: 0.2508\n",
      "Epoch [200/2000], Loss: 0.2570, Val Loss: 0.2570\n",
      "Early stopping at epoch 220\n",
      "Training complete.\n",
      "Starting Round 265\n",
      "Epoch [100/2000], Loss: 0.2885, Val Loss: 0.2885\n",
      "Epoch [200/2000], Loss: 0.2812, Val Loss: 0.2812\n",
      "Epoch [300/2000], Loss: 0.2745, Val Loss: 0.2745\n",
      "Early stopping at epoch 351\n",
      "Training complete.\n",
      "Starting Round 266\n",
      "Epoch [100/2000], Loss: 0.2682, Val Loss: 0.2682\n",
      "Early stopping at epoch 154\n",
      "Training complete.\n",
      "Starting Round 267\n",
      "Epoch [100/2000], Loss: 0.2543, Val Loss: 0.2543\n",
      "Epoch [200/2000], Loss: 0.2489, Val Loss: 0.2489\n",
      "Epoch [300/2000], Loss: 0.2704, Val Loss: 0.2704\n",
      "Early stopping at epoch 358\n",
      "Training complete.\n",
      "Starting Round 268\n",
      "Epoch [100/2000], Loss: 0.2221, Val Loss: 0.2221\n",
      "Epoch [200/2000], Loss: 0.2211, Val Loss: 0.2211\n",
      "Early stopping at epoch 246\n",
      "Training complete.\n",
      "Starting Round 269\n",
      "Epoch [100/2000], Loss: 0.2205, Val Loss: 0.2205\n",
      "Early stopping at epoch 189\n",
      "Training complete.\n",
      "Starting Round 270\n",
      "Epoch [100/2000], Loss: 0.2353, Val Loss: 0.2353\n",
      "Early stopping at epoch 187\n",
      "Training complete.\n",
      "Starting Round 271\n",
      "Epoch [100/2000], Loss: 0.2450, Val Loss: 0.2450\n",
      "Epoch [200/2000], Loss: 0.2448, Val Loss: 0.2448\n",
      "Early stopping at epoch 208\n",
      "Training complete.\n",
      "Starting Round 272\n",
      "Epoch [100/2000], Loss: 0.3280, Val Loss: 0.3280\n",
      "Epoch [200/2000], Loss: 0.3022, Val Loss: 0.3022\n",
      "Epoch [300/2000], Loss: 0.2965, Val Loss: 0.2965\n",
      "Epoch [400/2000], Loss: 0.2900, Val Loss: 0.2900\n",
      "Early stopping at epoch 441\n",
      "Training complete.\n",
      "Starting Round 273\n",
      "Epoch [100/2000], Loss: 0.2418, Val Loss: 0.2418\n",
      "Epoch [200/2000], Loss: 0.2444, Val Loss: 0.2444\n",
      "Early stopping at epoch 247\n",
      "Training complete.\n",
      "Starting Round 274\n",
      "Epoch [100/2000], Loss: 0.2849, Val Loss: 0.2849\n",
      "Epoch [200/2000], Loss: 0.2659, Val Loss: 0.2659\n",
      "Epoch [300/2000], Loss: 0.2803, Val Loss: 0.2803\n",
      "Early stopping at epoch 342\n",
      "Training complete.\n",
      "Starting Round 275\n",
      "Epoch [100/2000], Loss: 0.2122, Val Loss: 0.2122\n",
      "Epoch [200/2000], Loss: 0.2019, Val Loss: 0.2019\n",
      "Early stopping at epoch 216\n",
      "Training complete.\n",
      "Starting Round 276\n",
      "Epoch [100/2000], Loss: 0.2435, Val Loss: 0.2435\n",
      "Epoch [200/2000], Loss: 0.2462, Val Loss: 0.2462\n",
      "Early stopping at epoch 247\n",
      "Training complete.\n",
      "Starting Round 277\n",
      "Epoch [100/2000], Loss: 0.2751, Val Loss: 0.2751\n",
      "Epoch [200/2000], Loss: 0.2749, Val Loss: 0.2749\n",
      "Early stopping at epoch 239\n",
      "Training complete.\n",
      "Starting Round 278\n",
      "Epoch [100/2000], Loss: 0.2611, Val Loss: 0.2611\n",
      "Early stopping at epoch 144\n",
      "Training complete.\n",
      "Starting Round 279\n",
      "Epoch [100/2000], Loss: 0.2679, Val Loss: 0.2679\n",
      "Epoch [200/2000], Loss: 0.2698, Val Loss: 0.2698\n",
      "Early stopping at epoch 237\n",
      "Training complete.\n",
      "Starting Round 280\n",
      "Epoch [100/2000], Loss: 0.2726, Val Loss: 0.2726\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 281\n",
      "Epoch [100/2000], Loss: 0.2532, Val Loss: 0.2532\n",
      "Epoch [200/2000], Loss: 0.2714, Val Loss: 0.2714\n",
      "Epoch [300/2000], Loss: 0.2394, Val Loss: 0.2394\n",
      "Epoch [400/2000], Loss: 0.2557, Val Loss: 0.2557\n",
      "Early stopping at epoch 439\n",
      "Training complete.\n",
      "Starting Round 282\n",
      "Epoch [100/2000], Loss: 0.3027, Val Loss: 0.3027\n",
      "Early stopping at epoch 187\n",
      "Training complete.\n",
      "Starting Round 283\n",
      "Epoch [100/2000], Loss: 0.2583, Val Loss: 0.2583\n",
      "Epoch [200/2000], Loss: 0.2737, Val Loss: 0.2737\n",
      "Early stopping at epoch 201\n",
      "Training complete.\n",
      "Starting Round 284\n",
      "Epoch [100/2000], Loss: 0.3210, Val Loss: 0.3210\n",
      "Epoch [200/2000], Loss: 0.3037, Val Loss: 0.3037\n",
      "Epoch [300/2000], Loss: 0.3027, Val Loss: 0.3027\n",
      "Early stopping at epoch 339\n",
      "Training complete.\n",
      "Starting Round 285\n",
      "Epoch [100/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Epoch [200/2000], Loss: 0.2751, Val Loss: 0.2751\n",
      "Early stopping at epoch 223\n",
      "Training complete.\n",
      "Starting Round 286\n",
      "Epoch [100/2000], Loss: 0.2458, Val Loss: 0.2458\n",
      "Epoch [200/2000], Loss: 0.2449, Val Loss: 0.2449\n",
      "Early stopping at epoch 241\n",
      "Training complete.\n",
      "Starting Round 287\n",
      "Epoch [100/2000], Loss: 0.2867, Val Loss: 0.2867\n",
      "Epoch [200/2000], Loss: 0.2935, Val Loss: 0.2935\n",
      "Early stopping at epoch 272\n",
      "Training complete.\n",
      "Starting Round 288\n",
      "Epoch [100/2000], Loss: 0.2377, Val Loss: 0.2377\n",
      "Early stopping at epoch 200\n",
      "Training complete.\n",
      "Starting Round 289\n",
      "Epoch [100/2000], Loss: 0.2825, Val Loss: 0.2825\n",
      "Early stopping at epoch 179\n",
      "Training complete.\n",
      "Starting Round 290\n",
      "Epoch [100/2000], Loss: 0.2725, Val Loss: 0.2725\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 291\n",
      "Epoch [100/2000], Loss: 0.2799, Val Loss: 0.2799\n",
      "Early stopping at epoch 194\n",
      "Training complete.\n",
      "Starting Round 292\n",
      "Epoch [100/2000], Loss: 0.2919, Val Loss: 0.2919\n",
      "Epoch [200/2000], Loss: 0.2742, Val Loss: 0.2742\n",
      "Epoch [300/2000], Loss: 0.2616, Val Loss: 0.2616\n",
      "Early stopping at epoch 341\n",
      "Training complete.\n",
      "Starting Round 293\n",
      "Epoch [100/2000], Loss: 0.2723, Val Loss: 0.2723\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 294\n",
      "Epoch [100/2000], Loss: 0.2459, Val Loss: 0.2459\n",
      "Epoch [200/2000], Loss: 0.2305, Val Loss: 0.2305\n",
      "Early stopping at epoch 297\n",
      "Training complete.\n",
      "Starting Round 295\n",
      "Epoch [100/2000], Loss: 0.2600, Val Loss: 0.2600\n",
      "Epoch [200/2000], Loss: 0.2488, Val Loss: 0.2488\n",
      "Epoch [300/2000], Loss: 0.2355, Val Loss: 0.2355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 348\n",
      "Training complete.\n",
      "Starting Round 296\n",
      "Epoch [100/2000], Loss: 0.2482, Val Loss: 0.2482\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 297\n",
      "Epoch [100/2000], Loss: 0.2712, Val Loss: 0.2712\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 298\n",
      "Epoch [100/2000], Loss: 0.2678, Val Loss: 0.2678\n",
      "Epoch [200/2000], Loss: 0.2738, Val Loss: 0.2738\n",
      "Early stopping at epoch 213\n",
      "Training complete.\n",
      "Starting Round 299\n",
      "Epoch [100/2000], Loss: 0.2719, Val Loss: 0.2719\n",
      "Epoch [200/2000], Loss: 0.2543, Val Loss: 0.2543\n",
      "Epoch [300/2000], Loss: 0.2636, Val Loss: 0.2636\n",
      "Early stopping at epoch 346\n",
      "Training complete.\n",
      "Starting Round 300\n",
      "Epoch [100/2000], Loss: 0.2505, Val Loss: 0.2505\n",
      "Epoch [200/2000], Loss: 0.2437, Val Loss: 0.2437\n",
      "Early stopping at epoch 297\n",
      "Training complete.\n",
      "Starting Round 301\n",
      "Epoch [100/2000], Loss: 0.2742, Val Loss: 0.2742\n",
      "Epoch [200/2000], Loss: 0.2469, Val Loss: 0.2469\n",
      "Epoch [300/2000], Loss: 0.2554, Val Loss: 0.2554\n",
      "Early stopping at epoch 342\n",
      "Training complete.\n",
      "Starting Round 302\n",
      "Epoch [100/2000], Loss: 0.2617, Val Loss: 0.2617\n",
      "Epoch [200/2000], Loss: 0.2374, Val Loss: 0.2374\n",
      "Epoch [300/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Epoch [400/2000], Loss: 0.2275, Val Loss: 0.2275\n",
      "Epoch [500/2000], Loss: 0.2245, Val Loss: 0.2245\n",
      "Epoch [600/2000], Loss: 0.2364, Val Loss: 0.2364\n",
      "Epoch [700/2000], Loss: 0.2372, Val Loss: 0.2372\n",
      "Early stopping at epoch 717\n",
      "Training complete.\n",
      "Starting Round 303\n",
      "Epoch [100/2000], Loss: 0.2573, Val Loss: 0.2573\n",
      "Epoch [200/2000], Loss: 0.2791, Val Loss: 0.2791\n",
      "Early stopping at epoch 249\n",
      "Training complete.\n",
      "Starting Round 304\n",
      "Epoch [100/2000], Loss: 0.2896, Val Loss: 0.2896\n",
      "Early stopping at epoch 195\n",
      "Training complete.\n",
      "Starting Round 305\n",
      "Epoch [100/2000], Loss: 0.3135, Val Loss: 0.3135\n",
      "Early stopping at epoch 149\n",
      "Training complete.\n",
      "Starting Round 306\n",
      "Epoch [100/2000], Loss: 0.2652, Val Loss: 0.2652\n",
      "Epoch [200/2000], Loss: 0.2584, Val Loss: 0.2584\n",
      "Epoch [300/2000], Loss: 0.2751, Val Loss: 0.2751\n",
      "Epoch [400/2000], Loss: 0.2663, Val Loss: 0.2663\n",
      "Epoch [500/2000], Loss: 0.2618, Val Loss: 0.2618\n",
      "Early stopping at epoch 535\n",
      "Training complete.\n",
      "Starting Round 307\n",
      "Epoch [100/2000], Loss: 0.2505, Val Loss: 0.2505\n",
      "Epoch [200/2000], Loss: 0.2454, Val Loss: 0.2454\n",
      "Epoch [300/2000], Loss: 0.2317, Val Loss: 0.2317\n",
      "Epoch [400/2000], Loss: 0.2401, Val Loss: 0.2401\n",
      "Early stopping at epoch 476\n",
      "Training complete.\n",
      "Starting Round 308\n",
      "Epoch [100/2000], Loss: 0.2436, Val Loss: 0.2436\n",
      "Epoch [200/2000], Loss: 0.2324, Val Loss: 0.2324\n",
      "Epoch [300/2000], Loss: 0.2220, Val Loss: 0.2220\n",
      "Epoch [400/2000], Loss: 0.2373, Val Loss: 0.2373\n",
      "Early stopping at epoch 408\n",
      "Training complete.\n",
      "Starting Round 309\n",
      "Epoch [100/2000], Loss: 0.2492, Val Loss: 0.2492\n",
      "Epoch [200/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Early stopping at epoch 297\n",
      "Training complete.\n",
      "Starting Round 310\n",
      "Epoch [100/2000], Loss: 0.2893, Val Loss: 0.2893\n",
      "Epoch [200/2000], Loss: 0.2752, Val Loss: 0.2752\n",
      "Epoch [300/2000], Loss: 0.2698, Val Loss: 0.2698\n",
      "Early stopping at epoch 303\n",
      "Training complete.\n",
      "Starting Round 311\n",
      "Epoch [100/2000], Loss: 0.2052, Val Loss: 0.2052\n",
      "Epoch [200/2000], Loss: 0.2431, Val Loss: 0.2431\n",
      "Early stopping at epoch 204\n",
      "Training complete.\n",
      "Starting Round 312\n",
      "Epoch [100/2000], Loss: 0.2503, Val Loss: 0.2503\n",
      "Epoch [200/2000], Loss: 0.2591, Val Loss: 0.2591\n",
      "Epoch [300/2000], Loss: 0.2598, Val Loss: 0.2598\n",
      "Epoch [400/2000], Loss: 0.2711, Val Loss: 0.2711\n",
      "Early stopping at epoch 430\n",
      "Training complete.\n",
      "Starting Round 313\n",
      "Epoch [100/2000], Loss: 0.2553, Val Loss: 0.2553\n",
      "Epoch [200/2000], Loss: 0.2456, Val Loss: 0.2456\n",
      "Epoch [300/2000], Loss: 0.2686, Val Loss: 0.2686\n",
      "Early stopping at epoch 308\n",
      "Training complete.\n",
      "Starting Round 314\n",
      "Epoch [100/2000], Loss: 0.2952, Val Loss: 0.2952\n",
      "Epoch [200/2000], Loss: 0.2910, Val Loss: 0.2910\n",
      "Epoch [300/2000], Loss: 0.2723, Val Loss: 0.2723\n",
      "Early stopping at epoch 345\n",
      "Training complete.\n",
      "Starting Round 315\n",
      "Epoch [100/2000], Loss: 0.2947, Val Loss: 0.2947\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 316\n",
      "Epoch [100/2000], Loss: 0.2664, Val Loss: 0.2664\n",
      "Epoch [200/2000], Loss: 0.2629, Val Loss: 0.2629\n",
      "Epoch [300/2000], Loss: 0.2600, Val Loss: 0.2600\n",
      "Early stopping at epoch 383\n",
      "Training complete.\n",
      "Starting Round 317\n",
      "Epoch [100/2000], Loss: 0.2871, Val Loss: 0.2871\n",
      "Epoch [200/2000], Loss: 0.2741, Val Loss: 0.2741\n",
      "Epoch [300/2000], Loss: 0.3068, Val Loss: 0.3068\n",
      "Early stopping at epoch 312\n",
      "Training complete.\n",
      "Starting Round 318\n",
      "Epoch [100/2000], Loss: 0.3133, Val Loss: 0.3133\n",
      "Early stopping at epoch 178\n",
      "Training complete.\n",
      "Starting Round 319\n",
      "Epoch [100/2000], Loss: 0.2649, Val Loss: 0.2649\n",
      "Epoch [200/2000], Loss: 0.2714, Val Loss: 0.2714\n",
      "Early stopping at epoch 280\n",
      "Training complete.\n",
      "Starting Round 320\n",
      "Epoch [100/2000], Loss: 0.2575, Val Loss: 0.2575\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 321\n",
      "Epoch [100/2000], Loss: 0.2521, Val Loss: 0.2521\n",
      "Epoch [200/2000], Loss: 0.2315, Val Loss: 0.2315\n",
      "Early stopping at epoch 231\n",
      "Training complete.\n",
      "Starting Round 322\n",
      "Epoch [100/2000], Loss: 0.2732, Val Loss: 0.2732\n",
      "Epoch [200/2000], Loss: 0.2611, Val Loss: 0.2611\n",
      "Early stopping at epoch 214\n",
      "Training complete.\n",
      "Starting Round 323\n",
      "Epoch [100/2000], Loss: 0.3262, Val Loss: 0.3262\n",
      "Epoch [200/2000], Loss: 0.3181, Val Loss: 0.3181\n",
      "Early stopping at epoch 207\n",
      "Training complete.\n",
      "Starting Round 324\n",
      "Epoch [100/2000], Loss: 0.2514, Val Loss: 0.2514\n",
      "Epoch [200/2000], Loss: 0.2290, Val Loss: 0.2290\n",
      "Epoch [300/2000], Loss: 0.2176, Val Loss: 0.2176\n",
      "Early stopping at epoch 400\n",
      "Training complete.\n",
      "Starting Round 325\n",
      "Epoch [100/2000], Loss: 0.2365, Val Loss: 0.2365\n",
      "Epoch [200/2000], Loss: 0.2321, Val Loss: 0.2321\n",
      "Epoch [300/2000], Loss: 0.2351, Val Loss: 0.2351\n",
      "Epoch 00360: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Early stopping at epoch 362\n",
      "Training complete.\n",
      "Starting Round 326\n",
      "Epoch [100/2000], Loss: 0.2452, Val Loss: 0.2452\n",
      "Epoch [200/2000], Loss: 0.2544, Val Loss: 0.2544\n",
      "Epoch [300/2000], Loss: 0.2390, Val Loss: 0.2390\n",
      "Epoch [400/2000], Loss: 0.2464, Val Loss: 0.2464\n",
      "Early stopping at epoch 438\n",
      "Training complete.\n",
      "Starting Round 327\n",
      "Epoch [100/2000], Loss: 0.1974, Val Loss: 0.1974\n",
      "Epoch [200/2000], Loss: 0.1910, Val Loss: 0.1910\n",
      "Epoch [300/2000], Loss: 0.1962, Val Loss: 0.1962\n",
      "Epoch [400/2000], Loss: 0.1858, Val Loss: 0.1858\n",
      "Epoch [500/2000], Loss: 0.1880, Val Loss: 0.1880\n",
      "Epoch [600/2000], Loss: 0.1877, Val Loss: 0.1877\n",
      "Epoch [700/2000], Loss: 0.1818, Val Loss: 0.1818\n",
      "Early stopping at epoch 722\n",
      "Training complete.\n",
      "Starting Round 328\n",
      "Epoch [100/2000], Loss: 0.3023, Val Loss: 0.3023\n",
      "Epoch [200/2000], Loss: 0.3076, Val Loss: 0.3076\n",
      "Early stopping at epoch 236\n",
      "Training complete.\n",
      "Starting Round 329\n",
      "Epoch [100/2000], Loss: 0.2539, Val Loss: 0.2539\n",
      "Early stopping at epoch 187\n",
      "Training complete.\n",
      "Starting Round 330\n",
      "Epoch [100/2000], Loss: 0.2706, Val Loss: 0.2706\n",
      "Epoch [200/2000], Loss: 0.2476, Val Loss: 0.2476\n",
      "Early stopping at epoch 295\n",
      "Training complete.\n",
      "Starting Round 331\n",
      "Epoch [100/2000], Loss: 0.2537, Val Loss: 0.2537\n",
      "Epoch [200/2000], Loss: 0.2348, Val Loss: 0.2348\n",
      "Epoch [300/2000], Loss: 0.2343, Val Loss: 0.2343\n",
      "Early stopping at epoch 369\n",
      "Training complete.\n",
      "Starting Round 332\n",
      "Epoch [100/2000], Loss: 0.2766, Val Loss: 0.2766\n",
      "Epoch [200/2000], Loss: 0.2580, Val Loss: 0.2580\n",
      "Epoch [300/2000], Loss: 0.2622, Val Loss: 0.2622\n",
      "Epoch [400/2000], Loss: 0.2527, Val Loss: 0.2527\n",
      "Epoch [500/2000], Loss: 0.2711, Val Loss: 0.2711\n",
      "Early stopping at epoch 513\n",
      "Training complete.\n",
      "Starting Round 333\n",
      "Epoch [100/2000], Loss: 0.2814, Val Loss: 0.2814\n",
      "Epoch [200/2000], Loss: 0.2878, Val Loss: 0.2878\n",
      "Epoch [300/2000], Loss: 0.2821, Val Loss: 0.2821\n",
      "Early stopping at epoch 378\n",
      "Training complete.\n",
      "Starting Round 334\n",
      "Epoch [100/2000], Loss: 0.2578, Val Loss: 0.2578\n",
      "Epoch [200/2000], Loss: 0.2457, Val Loss: 0.2457\n",
      "Epoch [300/2000], Loss: 0.2541, Val Loss: 0.2541\n",
      "Early stopping at epoch 328\n",
      "Training complete.\n",
      "Starting Round 335\n",
      "Epoch [100/2000], Loss: 0.2931, Val Loss: 0.2931\n",
      "Epoch [200/2000], Loss: 0.3094, Val Loss: 0.3094\n",
      "Early stopping at epoch 220\n",
      "Training complete.\n",
      "Starting Round 336\n",
      "Epoch [100/2000], Loss: 0.2287, Val Loss: 0.2287\n",
      "Epoch [200/2000], Loss: 0.2265, Val Loss: 0.2265\n",
      "Early stopping at epoch 279\n",
      "Training complete.\n",
      "Starting Round 337\n",
      "Epoch [100/2000], Loss: 0.2880, Val Loss: 0.2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/2000], Loss: 0.2961, Val Loss: 0.2961\n",
      "Early stopping at epoch 272\n",
      "Training complete.\n",
      "Starting Round 338\n",
      "Epoch [100/2000], Loss: 0.2947, Val Loss: 0.2947\n",
      "Early stopping at epoch 172\n",
      "Training complete.\n",
      "Starting Round 339\n",
      "Epoch [100/2000], Loss: 0.2306, Val Loss: 0.2306\n",
      "Epoch [200/2000], Loss: 0.2259, Val Loss: 0.2259\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 340\n",
      "Epoch [100/2000], Loss: 0.3313, Val Loss: 0.3313\n",
      "Epoch [200/2000], Loss: 0.3426, Val Loss: 0.3426\n",
      "Early stopping at epoch 205\n",
      "Training complete.\n",
      "Starting Round 341\n",
      "Epoch [100/2000], Loss: 0.3013, Val Loss: 0.3013\n",
      "Epoch [200/2000], Loss: 0.2879, Val Loss: 0.2879\n",
      "Epoch [300/2000], Loss: 0.2905, Val Loss: 0.2905\n",
      "Epoch [400/2000], Loss: 0.2879, Val Loss: 0.2879\n",
      "Early stopping at epoch 482\n",
      "Training complete.\n",
      "Starting Round 342\n",
      "Epoch [100/2000], Loss: 0.2660, Val Loss: 0.2660\n",
      "Epoch [200/2000], Loss: 0.2392, Val Loss: 0.2392\n",
      "Early stopping at epoch 297\n",
      "Training complete.\n",
      "Starting Round 343\n",
      "Epoch [100/2000], Loss: 0.2462, Val Loss: 0.2462\n",
      "Epoch [200/2000], Loss: 0.2739, Val Loss: 0.2739\n",
      "Early stopping at epoch 214\n",
      "Training complete.\n",
      "Starting Round 344\n",
      "Epoch [100/2000], Loss: 0.2665, Val Loss: 0.2665\n",
      "Epoch [200/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Epoch [300/2000], Loss: 0.2594, Val Loss: 0.2594\n",
      "Epoch [400/2000], Loss: 0.2596, Val Loss: 0.2596\n",
      "Epoch [500/2000], Loss: 0.2552, Val Loss: 0.2552\n",
      "Early stopping at epoch 517\n",
      "Training complete.\n",
      "Starting Round 345\n",
      "Epoch [100/2000], Loss: 0.2674, Val Loss: 0.2674\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 346\n",
      "Epoch [100/2000], Loss: 0.2468, Val Loss: 0.2468\n",
      "Epoch [200/2000], Loss: 0.2345, Val Loss: 0.2345\n",
      "Epoch [300/2000], Loss: 0.2330, Val Loss: 0.2330\n",
      "Epoch [400/2000], Loss: 0.2382, Val Loss: 0.2382\n",
      "Early stopping at epoch 418\n",
      "Training complete.\n",
      "Starting Round 347\n",
      "Epoch [100/2000], Loss: 0.2995, Val Loss: 0.2995\n",
      "Epoch [200/2000], Loss: 0.2894, Val Loss: 0.2894\n",
      "Early stopping at epoch 276\n",
      "Training complete.\n",
      "Starting Round 348\n",
      "Epoch [100/2000], Loss: 0.2517, Val Loss: 0.2517\n",
      "Early stopping at epoch 188\n",
      "Training complete.\n",
      "Starting Round 349\n",
      "Epoch [100/2000], Loss: 0.3218, Val Loss: 0.3218\n",
      "Epoch [200/2000], Loss: 0.3072, Val Loss: 0.3072\n",
      "Epoch [300/2000], Loss: 0.3223, Val Loss: 0.3223\n",
      "Early stopping at epoch 361\n",
      "Training complete.\n",
      "Starting Round 350\n",
      "Epoch [100/2000], Loss: 0.2396, Val Loss: 0.2396\n",
      "Epoch [200/2000], Loss: 0.2277, Val Loss: 0.2277\n",
      "Epoch [300/2000], Loss: 0.2267, Val Loss: 0.2267\n",
      "Epoch [400/2000], Loss: 0.2233, Val Loss: 0.2233\n",
      "Early stopping at epoch 402\n",
      "Training complete.\n",
      "Starting Round 351\n",
      "Epoch [100/2000], Loss: 0.2406, Val Loss: 0.2406\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 352\n",
      "Epoch [100/2000], Loss: 0.2741, Val Loss: 0.2741\n",
      "Early stopping at epoch 175\n",
      "Training complete.\n",
      "Starting Round 353\n",
      "Epoch [100/2000], Loss: 0.2354, Val Loss: 0.2354\n",
      "Epoch [200/2000], Loss: 0.2515, Val Loss: 0.2515\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 354\n",
      "Epoch [100/2000], Loss: 0.2810, Val Loss: 0.2810\n",
      "Epoch [200/2000], Loss: 0.2677, Val Loss: 0.2677\n",
      "Epoch [300/2000], Loss: 0.2599, Val Loss: 0.2599\n",
      "Epoch [400/2000], Loss: 0.2626, Val Loss: 0.2626\n",
      "Early stopping at epoch 445\n",
      "Training complete.\n",
      "Starting Round 355\n",
      "Epoch [100/2000], Loss: 0.2465, Val Loss: 0.2465\n",
      "Epoch [200/2000], Loss: 0.2524, Val Loss: 0.2524\n",
      "Early stopping at epoch 218\n",
      "Training complete.\n",
      "Starting Round 356\n",
      "Epoch [100/2000], Loss: 0.2488, Val Loss: 0.2488\n",
      "Epoch [200/2000], Loss: 0.2354, Val Loss: 0.2354\n",
      "Epoch [300/2000], Loss: 0.2319, Val Loss: 0.2319\n",
      "Epoch [400/2000], Loss: 0.2300, Val Loss: 0.2300\n",
      "Epoch [500/2000], Loss: 0.2341, Val Loss: 0.2341\n",
      "Early stopping at epoch 561\n",
      "Training complete.\n",
      "Starting Round 357\n",
      "Epoch [100/2000], Loss: 0.2630, Val Loss: 0.2630\n",
      "Epoch [200/2000], Loss: 0.2556, Val Loss: 0.2556\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 358\n",
      "Epoch [100/2000], Loss: 0.2525, Val Loss: 0.2525\n",
      "Epoch [200/2000], Loss: 0.2595, Val Loss: 0.2595\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 359\n",
      "Epoch [100/2000], Loss: 0.2561, Val Loss: 0.2561\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 360\n",
      "Epoch [100/2000], Loss: 0.2551, Val Loss: 0.2551\n",
      "Epoch [200/2000], Loss: 0.2726, Val Loss: 0.2726\n",
      "Epoch [300/2000], Loss: 0.2570, Val Loss: 0.2570\n",
      "Epoch [400/2000], Loss: 0.2410, Val Loss: 0.2410\n",
      "Early stopping at epoch 500\n",
      "Training complete.\n",
      "Starting Round 361\n",
      "Epoch [100/2000], Loss: 0.2763, Val Loss: 0.2763\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 362\n",
      "Epoch [100/2000], Loss: 0.2852, Val Loss: 0.2852\n",
      "Epoch [200/2000], Loss: 0.2721, Val Loss: 0.2721\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 363\n",
      "Epoch [100/2000], Loss: 0.2665, Val Loss: 0.2665\n",
      "Early stopping at epoch 176\n",
      "Training complete.\n",
      "Starting Round 364\n",
      "Epoch [100/2000], Loss: 0.2357, Val Loss: 0.2357\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 365\n",
      "Epoch [100/2000], Loss: 0.2872, Val Loss: 0.2872\n",
      "Epoch [200/2000], Loss: 0.2743, Val Loss: 0.2743\n",
      "Early stopping at epoch 280\n",
      "Training complete.\n",
      "Starting Round 366\n",
      "Epoch [100/2000], Loss: 0.2402, Val Loss: 0.2402\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 367\n",
      "Epoch [100/2000], Loss: 0.2110, Val Loss: 0.2110\n",
      "Epoch [200/2000], Loss: 0.2212, Val Loss: 0.2212\n",
      "Early stopping at epoch 202\n",
      "Training complete.\n",
      "Starting Round 368\n",
      "Epoch [100/2000], Loss: 0.2749, Val Loss: 0.2749\n",
      "Early stopping at epoch 178\n",
      "Training complete.\n",
      "Starting Round 369\n",
      "Epoch [100/2000], Loss: 0.2458, Val Loss: 0.2458\n",
      "Epoch [200/2000], Loss: 0.2438, Val Loss: 0.2438\n",
      "Early stopping at epoch 210\n",
      "Training complete.\n",
      "Starting Round 370\n",
      "Epoch [100/2000], Loss: 0.2671, Val Loss: 0.2671\n",
      "Epoch [200/2000], Loss: 0.2815, Val Loss: 0.2815\n",
      "Epoch [300/2000], Loss: 0.2700, Val Loss: 0.2700\n",
      "Early stopping at epoch 366\n",
      "Training complete.\n",
      "Starting Round 371\n",
      "Epoch [100/2000], Loss: 0.2690, Val Loss: 0.2690\n",
      "Early stopping at epoch 144\n",
      "Training complete.\n",
      "Starting Round 372\n",
      "Epoch [100/2000], Loss: 0.2561, Val Loss: 0.2561\n",
      "Early stopping at epoch 188\n",
      "Training complete.\n",
      "Starting Round 373\n",
      "Epoch [100/2000], Loss: 0.2607, Val Loss: 0.2607\n",
      "Early stopping at epoch 173\n",
      "Training complete.\n",
      "Starting Round 374\n",
      "Epoch [100/2000], Loss: 0.2697, Val Loss: 0.2697\n",
      "Epoch [200/2000], Loss: 0.2655, Val Loss: 0.2655\n",
      "Epoch [300/2000], Loss: 0.2724, Val Loss: 0.2724\n",
      "Early stopping at epoch 319\n",
      "Training complete.\n",
      "Starting Round 375\n",
      "Epoch [100/2000], Loss: 0.2218, Val Loss: 0.2218\n",
      "Epoch [200/2000], Loss: 0.2066, Val Loss: 0.2066\n",
      "Early stopping at epoch 248\n",
      "Training complete.\n",
      "Starting Round 376\n",
      "Epoch [100/2000], Loss: 0.2808, Val Loss: 0.2808\n",
      "Epoch [200/2000], Loss: 0.2589, Val Loss: 0.2589\n",
      "Early stopping at epoch 246\n",
      "Training complete.\n",
      "Starting Round 377\n",
      "Epoch [100/2000], Loss: 0.2616, Val Loss: 0.2616\n",
      "Epoch [200/2000], Loss: 0.2683, Val Loss: 0.2683\n",
      "Epoch [300/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Epoch [400/2000], Loss: 0.2551, Val Loss: 0.2551\n",
      "Early stopping at epoch 489\n",
      "Training complete.\n",
      "Starting Round 378\n",
      "Epoch [100/2000], Loss: 0.2102, Val Loss: 0.2102\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 379\n",
      "Epoch [100/2000], Loss: 0.2826, Val Loss: 0.2826\n",
      "Epoch [200/2000], Loss: 0.2681, Val Loss: 0.2681\n",
      "Epoch [300/2000], Loss: 0.2751, Val Loss: 0.2751\n",
      "Early stopping at epoch 371\n",
      "Training complete.\n",
      "Starting Round 380\n",
      "Epoch [100/2000], Loss: 0.2800, Val Loss: 0.2800\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 381\n",
      "Epoch [100/2000], Loss: 0.2399, Val Loss: 0.2399\n",
      "Epoch [200/2000], Loss: 0.2636, Val Loss: 0.2636\n",
      "Early stopping at epoch 206\n",
      "Training complete.\n",
      "Starting Round 382\n",
      "Epoch [100/2000], Loss: 0.2659, Val Loss: 0.2659\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 383\n",
      "Epoch [100/2000], Loss: 0.2688, Val Loss: 0.2688\n",
      "Early stopping at epoch 192\n",
      "Training complete.\n",
      "Starting Round 384\n",
      "Epoch [100/2000], Loss: 0.2645, Val Loss: 0.2645\n",
      "Early stopping at epoch 192\n",
      "Training complete.\n",
      "Starting Round 385\n",
      "Epoch [100/2000], Loss: 0.2385, Val Loss: 0.2385\n",
      "Epoch [200/2000], Loss: 0.2353, Val Loss: 0.2353\n",
      "Epoch [300/2000], Loss: 0.2427, Val Loss: 0.2427\n",
      "Early stopping at epoch 306\n",
      "Training complete.\n",
      "Starting Round 386\n",
      "Epoch [100/2000], Loss: 0.2563, Val Loss: 0.2563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/2000], Loss: 0.2247, Val Loss: 0.2247\n",
      "Early stopping at epoch 282\n",
      "Training complete.\n",
      "Starting Round 387\n",
      "Epoch [100/2000], Loss: 0.2356, Val Loss: 0.2356\n",
      "Epoch [200/2000], Loss: 0.2349, Val Loss: 0.2349\n",
      "Early stopping at epoch 204\n",
      "Training complete.\n",
      "Starting Round 388\n",
      "Epoch [100/2000], Loss: 0.2769, Val Loss: 0.2769\n",
      "Epoch 00154: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Early stopping at epoch 175\n",
      "Training complete.\n",
      "Starting Round 389\n",
      "Epoch [100/2000], Loss: 0.3113, Val Loss: 0.3113\n",
      "Early stopping at epoch 137\n",
      "Training complete.\n",
      "Starting Round 390\n",
      "Epoch [100/2000], Loss: 0.2573, Val Loss: 0.2573\n",
      "Early stopping at epoch 200\n",
      "Training complete.\n",
      "Starting Round 391\n",
      "Epoch [100/2000], Loss: 0.2422, Val Loss: 0.2422\n",
      "Epoch [200/2000], Loss: 0.2352, Val Loss: 0.2352\n",
      "Early stopping at epoch 257\n",
      "Training complete.\n",
      "Starting Round 392\n",
      "Epoch [100/2000], Loss: 0.2459, Val Loss: 0.2459\n",
      "Epoch [200/2000], Loss: 0.2805, Val Loss: 0.2805\n",
      "Early stopping at epoch 236\n",
      "Training complete.\n",
      "Starting Round 393\n",
      "Epoch [100/2000], Loss: 0.2697, Val Loss: 0.2697\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 394\n",
      "Epoch [100/2000], Loss: 0.2631, Val Loss: 0.2631\n",
      "Epoch [200/2000], Loss: 0.2773, Val Loss: 0.2773\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 395\n",
      "Epoch [100/2000], Loss: 0.2482, Val Loss: 0.2482\n",
      "Epoch [200/2000], Loss: 0.2259, Val Loss: 0.2259\n",
      "Early stopping at epoch 287\n",
      "Training complete.\n",
      "Starting Round 396\n",
      "Epoch [100/2000], Loss: 0.2809, Val Loss: 0.2809\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 397\n",
      "Epoch [100/2000], Loss: 0.2406, Val Loss: 0.2406\n",
      "Epoch [200/2000], Loss: 0.2359, Val Loss: 0.2359\n",
      "Early stopping at epoch 254\n",
      "Training complete.\n",
      "Starting Round 398\n",
      "Epoch [100/2000], Loss: 0.2256, Val Loss: 0.2256\n",
      "Epoch [200/2000], Loss: 0.2377, Val Loss: 0.2377\n",
      "Early stopping at epoch 218\n",
      "Training complete.\n",
      "Starting Round 399\n",
      "Epoch [100/2000], Loss: 0.2458, Val Loss: 0.2458\n",
      "Epoch [200/2000], Loss: 0.2561, Val Loss: 0.2561\n",
      "Early stopping at epoch 295\n",
      "Training complete.\n",
      "Starting Round 400\n",
      "Epoch [100/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 401\n",
      "Epoch [100/2000], Loss: 0.2206, Val Loss: 0.2206\n",
      "Epoch [200/2000], Loss: 0.2116, Val Loss: 0.2116\n",
      "Epoch [300/2000], Loss: 0.2092, Val Loss: 0.2092\n",
      "Early stopping at epoch 339\n",
      "Training complete.\n",
      "Starting Round 402\n",
      "Epoch [100/2000], Loss: 0.2784, Val Loss: 0.2784\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 403\n",
      "Epoch [100/2000], Loss: 0.3147, Val Loss: 0.3147\n",
      "Epoch [200/2000], Loss: 0.2554, Val Loss: 0.2554\n",
      "Epoch [300/2000], Loss: 0.2767, Val Loss: 0.2767\n",
      "Early stopping at epoch 334\n",
      "Training complete.\n",
      "Starting Round 404\n",
      "Epoch [100/2000], Loss: 0.2673, Val Loss: 0.2673\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 405\n",
      "Epoch [100/2000], Loss: 0.2581, Val Loss: 0.2581\n",
      "Epoch [200/2000], Loss: 0.2545, Val Loss: 0.2545\n",
      "Epoch [300/2000], Loss: 0.2387, Val Loss: 0.2387\n",
      "Early stopping at epoch 400\n",
      "Training complete.\n",
      "Starting Round 406\n",
      "Epoch [100/2000], Loss: 0.2543, Val Loss: 0.2543\n",
      "Epoch [200/2000], Loss: 0.2499, Val Loss: 0.2499\n",
      "Early stopping at epoch 247\n",
      "Training complete.\n",
      "Starting Round 407\n",
      "Epoch [100/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Epoch [200/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Early stopping at epoch 220\n",
      "Training complete.\n",
      "Starting Round 408\n",
      "Epoch [100/2000], Loss: 0.2870, Val Loss: 0.2870\n",
      "Epoch [200/2000], Loss: 0.2818, Val Loss: 0.2818\n",
      "Early stopping at epoch 248\n",
      "Training complete.\n",
      "Starting Round 409\n",
      "Epoch [100/2000], Loss: 0.2989, Val Loss: 0.2989\n",
      "Early stopping at epoch 195\n",
      "Training complete.\n",
      "Starting Round 410\n",
      "Epoch [100/2000], Loss: 0.2295, Val Loss: 0.2295\n",
      "Epoch [200/2000], Loss: 0.2488, Val Loss: 0.2488\n",
      "Early stopping at epoch 270\n",
      "Training complete.\n",
      "Starting Round 411\n",
      "Epoch [100/2000], Loss: 0.2858, Val Loss: 0.2858\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 412\n",
      "Epoch [100/2000], Loss: 0.2290, Val Loss: 0.2290\n",
      "Early stopping at epoch 200\n",
      "Training complete.\n",
      "Starting Round 413\n",
      "Epoch [100/2000], Loss: 0.2383, Val Loss: 0.2383\n",
      "Epoch [200/2000], Loss: 0.2405, Val Loss: 0.2405\n",
      "Epoch [300/2000], Loss: 0.2401, Val Loss: 0.2401\n",
      "Epoch [400/2000], Loss: 0.2350, Val Loss: 0.2350\n",
      "Early stopping at epoch 481\n",
      "Training complete.\n",
      "Starting Round 414\n",
      "Epoch [100/2000], Loss: 0.2279, Val Loss: 0.2279\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 415\n",
      "Epoch [100/2000], Loss: 0.2766, Val Loss: 0.2766\n",
      "Epoch [200/2000], Loss: 0.2666, Val Loss: 0.2666\n",
      "Early stopping at epoch 257\n",
      "Training complete.\n",
      "Starting Round 416\n",
      "Epoch [100/2000], Loss: 0.2779, Val Loss: 0.2779\n",
      "Early stopping at epoch 153\n",
      "Training complete.\n",
      "Starting Round 417\n",
      "Epoch [100/2000], Loss: 0.2704, Val Loss: 0.2704\n",
      "Epoch [200/2000], Loss: 0.2748, Val Loss: 0.2748\n",
      "Early stopping at epoch 239\n",
      "Training complete.\n",
      "Starting Round 418\n",
      "Epoch [100/2000], Loss: 0.2639, Val Loss: 0.2639\n",
      "Epoch [200/2000], Loss: 0.2607, Val Loss: 0.2607\n",
      "Epoch [300/2000], Loss: 0.2507, Val Loss: 0.2507\n",
      "Early stopping at epoch 348\n",
      "Training complete.\n",
      "Starting Round 419\n",
      "Epoch [100/2000], Loss: 0.2526, Val Loss: 0.2526\n",
      "Epoch [200/2000], Loss: 0.2545, Val Loss: 0.2545\n",
      "Early stopping at epoch 264\n",
      "Training complete.\n",
      "Starting Round 420\n",
      "Epoch [100/2000], Loss: 0.3014, Val Loss: 0.3014\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 421\n",
      "Epoch [100/2000], Loss: 0.2465, Val Loss: 0.2465\n",
      "Early stopping at epoch 172\n",
      "Training complete.\n",
      "Starting Round 422\n",
      "Epoch [100/2000], Loss: 0.2905, Val Loss: 0.2905\n",
      "Epoch [200/2000], Loss: 0.2780, Val Loss: 0.2780\n",
      "Epoch [300/2000], Loss: 0.2611, Val Loss: 0.2611\n",
      "Epoch [400/2000], Loss: 0.2829, Val Loss: 0.2829\n",
      "Early stopping at epoch 467\n",
      "Training complete.\n",
      "Starting Round 423\n",
      "Epoch [100/2000], Loss: 0.2378, Val Loss: 0.2378\n",
      "Epoch [200/2000], Loss: 0.2520, Val Loss: 0.2520\n",
      "Epoch [300/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Early stopping at epoch 307\n",
      "Training complete.\n",
      "Starting Round 424\n",
      "Epoch [100/2000], Loss: 0.2621, Val Loss: 0.2621\n",
      "Epoch [200/2000], Loss: 0.2656, Val Loss: 0.2656\n",
      "Epoch [300/2000], Loss: 0.2467, Val Loss: 0.2467\n",
      "Early stopping at epoch 379\n",
      "Training complete.\n",
      "Starting Round 425\n",
      "Epoch [100/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Epoch [200/2000], Loss: 0.2517, Val Loss: 0.2517\n",
      "Epoch [300/2000], Loss: 0.2554, Val Loss: 0.2554\n",
      "Epoch [400/2000], Loss: 0.2562, Val Loss: 0.2562\n",
      "Early stopping at epoch 451\n",
      "Training complete.\n",
      "Starting Round 426\n",
      "Epoch [100/2000], Loss: 0.2720, Val Loss: 0.2720\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 427\n",
      "Epoch [100/2000], Loss: 0.2810, Val Loss: 0.2810\n",
      "Epoch [200/2000], Loss: 0.2525, Val Loss: 0.2525\n",
      "Epoch [300/2000], Loss: 0.2625, Val Loss: 0.2625\n",
      "Early stopping at epoch 330\n",
      "Training complete.\n",
      "Starting Round 428\n",
      "Epoch [100/2000], Loss: 0.3251, Val Loss: 0.3251\n",
      "Epoch [200/2000], Loss: 0.2951, Val Loss: 0.2951\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 429\n",
      "Epoch [100/2000], Loss: 0.2459, Val Loss: 0.2459\n",
      "Epoch [200/2000], Loss: 0.2398, Val Loss: 0.2398\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 430\n",
      "Epoch [100/2000], Loss: 0.2663, Val Loss: 0.2663\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 431\n",
      "Epoch [100/2000], Loss: 0.2633, Val Loss: 0.2633\n",
      "Epoch [200/2000], Loss: 0.2602, Val Loss: 0.2602\n",
      "Early stopping at epoch 233\n",
      "Training complete.\n",
      "Starting Round 432\n",
      "Epoch [100/2000], Loss: 0.2493, Val Loss: 0.2493\n",
      "Epoch [200/2000], Loss: 0.2345, Val Loss: 0.2345\n",
      "Early stopping at epoch 265\n",
      "Training complete.\n",
      "Starting Round 433\n",
      "Epoch [100/2000], Loss: 0.2578, Val Loss: 0.2578\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 434\n",
      "Epoch [100/2000], Loss: 0.2867, Val Loss: 0.2867\n",
      "Early stopping at epoch 170\n",
      "Training complete.\n",
      "Starting Round 435\n",
      "Epoch [100/2000], Loss: 0.2660, Val Loss: 0.2660\n",
      "Early stopping at epoch 148\n",
      "Training complete.\n",
      "Starting Round 436\n",
      "Epoch [100/2000], Loss: 0.2723, Val Loss: 0.2723\n",
      "Epoch [200/2000], Loss: 0.2700, Val Loss: 0.2700\n",
      "Early stopping at epoch 246\n",
      "Training complete.\n",
      "Starting Round 437\n",
      "Epoch [100/2000], Loss: 0.2478, Val Loss: 0.2478\n",
      "Epoch [200/2000], Loss: 0.2389, Val Loss: 0.2389\n",
      "Epoch [300/2000], Loss: 0.2306, Val Loss: 0.2306\n",
      "Early stopping at epoch 318\n",
      "Training complete.\n",
      "Starting Round 438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.2346, Val Loss: 0.2346\n",
      "Epoch [200/2000], Loss: 0.2442, Val Loss: 0.2442\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 439\n",
      "Epoch [100/2000], Loss: 0.2393, Val Loss: 0.2393\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 440\n",
      "Epoch [100/2000], Loss: 0.2807, Val Loss: 0.2807\n",
      "Epoch [200/2000], Loss: 0.2697, Val Loss: 0.2697\n",
      "Epoch [300/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Early stopping at epoch 325\n",
      "Training complete.\n",
      "Starting Round 441\n",
      "Epoch [100/2000], Loss: 0.3002, Val Loss: 0.3002\n",
      "Epoch [200/2000], Loss: 0.2880, Val Loss: 0.2880\n",
      "Epoch [300/2000], Loss: 0.2884, Val Loss: 0.2884\n",
      "Early stopping at epoch 363\n",
      "Training complete.\n",
      "Starting Round 442\n",
      "Epoch [100/2000], Loss: 0.2264, Val Loss: 0.2264\n",
      "Early stopping at epoch 189\n",
      "Training complete.\n",
      "Starting Round 443\n",
      "Epoch [100/2000], Loss: 0.2889, Val Loss: 0.2889\n",
      "Epoch [200/2000], Loss: 0.2804, Val Loss: 0.2804\n",
      "Early stopping at epoch 218\n",
      "Training complete.\n",
      "Starting Round 444\n",
      "Epoch [100/2000], Loss: 0.2648, Val Loss: 0.2648\n",
      "Early stopping at epoch 182\n",
      "Training complete.\n",
      "Starting Round 445\n",
      "Epoch [100/2000], Loss: 0.2371, Val Loss: 0.2371\n",
      "Early stopping at epoch 189\n",
      "Training complete.\n",
      "Starting Round 446\n",
      "Epoch [100/2000], Loss: 0.2948, Val Loss: 0.2948\n",
      "Epoch 00146: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 447\n",
      "Epoch [100/2000], Loss: 0.2461, Val Loss: 0.2461\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 448\n",
      "Epoch [100/2000], Loss: 0.2620, Val Loss: 0.2620\n",
      "Epoch [200/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Early stopping at epoch 268\n",
      "Training complete.\n",
      "Starting Round 449\n",
      "Epoch [100/2000], Loss: 0.2479, Val Loss: 0.2479\n",
      "Epoch [200/2000], Loss: 0.2450, Val Loss: 0.2450\n",
      "Epoch [300/2000], Loss: 0.2470, Val Loss: 0.2470\n",
      "Epoch [400/2000], Loss: 0.2417, Val Loss: 0.2417\n",
      "Early stopping at epoch 416\n",
      "Training complete.\n",
      "Starting Round 450\n",
      "Epoch [100/2000], Loss: 0.2784, Val Loss: 0.2784\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 451\n",
      "Epoch [100/2000], Loss: 0.2482, Val Loss: 0.2482\n",
      "Epoch [200/2000], Loss: 0.2449, Val Loss: 0.2449\n",
      "Early stopping at epoch 221\n",
      "Training complete.\n",
      "Starting Round 452\n",
      "Epoch [100/2000], Loss: 0.2456, Val Loss: 0.2456\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 453\n",
      "Epoch [100/2000], Loss: 0.2313, Val Loss: 0.2313\n",
      "Early stopping at epoch 195\n",
      "Training complete.\n",
      "Starting Round 454\n",
      "Epoch [100/2000], Loss: 0.2621, Val Loss: 0.2621\n",
      "Epoch [200/2000], Loss: 0.2618, Val Loss: 0.2618\n",
      "Early stopping at epoch 258\n",
      "Training complete.\n",
      "Starting Round 455\n",
      "Epoch [100/2000], Loss: 0.3128, Val Loss: 0.3128\n",
      "Early stopping at epoch 188\n",
      "Training complete.\n",
      "Starting Round 456\n",
      "Epoch [100/2000], Loss: 0.2296, Val Loss: 0.2296\n",
      "Epoch [200/2000], Loss: 0.2348, Val Loss: 0.2348\n",
      "Early stopping at epoch 257\n",
      "Training complete.\n",
      "Starting Round 457\n",
      "Epoch [100/2000], Loss: 0.2655, Val Loss: 0.2655\n",
      "Epoch [200/2000], Loss: 0.2781, Val Loss: 0.2781\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 458\n",
      "Epoch [100/2000], Loss: 0.2810, Val Loss: 0.2810\n",
      "Epoch [200/2000], Loss: 0.2612, Val Loss: 0.2612\n",
      "Early stopping at epoch 271\n",
      "Training complete.\n",
      "Starting Round 459\n",
      "Epoch [100/2000], Loss: 0.2777, Val Loss: 0.2777\n",
      "Epoch [200/2000], Loss: 0.2461, Val Loss: 0.2461\n",
      "Epoch [300/2000], Loss: 0.2668, Val Loss: 0.2668\n",
      "Early stopping at epoch 324\n",
      "Training complete.\n",
      "Starting Round 460\n",
      "Epoch [100/2000], Loss: 0.2291, Val Loss: 0.2291\n",
      "Epoch [200/2000], Loss: 0.2195, Val Loss: 0.2195\n",
      "Epoch [300/2000], Loss: 0.2212, Val Loss: 0.2212\n",
      "Epoch [400/2000], Loss: 0.2163, Val Loss: 0.2163\n",
      "Early stopping at epoch 453\n",
      "Training complete.\n",
      "Starting Round 461\n",
      "Epoch [100/2000], Loss: 0.2309, Val Loss: 0.2309\n",
      "Epoch [200/2000], Loss: 0.2306, Val Loss: 0.2306\n",
      "Early stopping at epoch 218\n",
      "Training complete.\n",
      "Starting Round 462\n",
      "Epoch [100/2000], Loss: 0.2654, Val Loss: 0.2654\n",
      "Epoch [200/2000], Loss: 0.2580, Val Loss: 0.2580\n",
      "Early stopping at epoch 286\n",
      "Training complete.\n",
      "Starting Round 463\n",
      "Epoch [100/2000], Loss: 0.2646, Val Loss: 0.2646\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 464\n",
      "Epoch [100/2000], Loss: 0.2721, Val Loss: 0.2721\n",
      "Early stopping at epoch 170\n",
      "Training complete.\n",
      "Starting Round 465\n",
      "Epoch [100/2000], Loss: 0.2880, Val Loss: 0.2880\n",
      "Epoch [200/2000], Loss: 0.2784, Val Loss: 0.2784\n",
      "Epoch [300/2000], Loss: 0.2739, Val Loss: 0.2739\n",
      "Early stopping at epoch 392\n",
      "Training complete.\n",
      "Starting Round 466\n",
      "Epoch [100/2000], Loss: 0.2680, Val Loss: 0.2680\n",
      "Epoch [200/2000], Loss: 0.2635, Val Loss: 0.2635\n",
      "Early stopping at epoch 246\n",
      "Training complete.\n",
      "Starting Round 467\n",
      "Epoch [100/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Epoch [200/2000], Loss: 0.2766, Val Loss: 0.2766\n",
      "Early stopping at epoch 278\n",
      "Training complete.\n",
      "Starting Round 468\n",
      "Epoch [100/2000], Loss: 0.2444, Val Loss: 0.2444\n",
      "Epoch [200/2000], Loss: 0.2469, Val Loss: 0.2469\n",
      "Early stopping at epoch 261\n",
      "Training complete.\n",
      "Starting Round 469\n",
      "Epoch [100/2000], Loss: 0.2294, Val Loss: 0.2294\n",
      "Epoch [200/2000], Loss: 0.2261, Val Loss: 0.2261\n",
      "Epoch [300/2000], Loss: 0.2286, Val Loss: 0.2286\n",
      "Early stopping at epoch 351\n",
      "Training complete.\n",
      "Starting Round 470\n",
      "Epoch [100/2000], Loss: 0.2317, Val Loss: 0.2317\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 471\n",
      "Epoch [100/2000], Loss: 0.3109, Val Loss: 0.3109\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 472\n",
      "Epoch [100/2000], Loss: 0.2756, Val Loss: 0.2756\n",
      "Epoch [200/2000], Loss: 0.2785, Val Loss: 0.2785\n",
      "Early stopping at epoch 234\n",
      "Training complete.\n",
      "Starting Round 473\n",
      "Epoch [100/2000], Loss: 0.2294, Val Loss: 0.2294\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 474\n",
      "Epoch [100/2000], Loss: 0.2546, Val Loss: 0.2546\n",
      "Epoch [200/2000], Loss: 0.2539, Val Loss: 0.2539\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 475\n",
      "Epoch [100/2000], Loss: 0.2822, Val Loss: 0.2822\n",
      "Epoch [200/2000], Loss: 0.2790, Val Loss: 0.2790\n",
      "Early stopping at epoch 213\n",
      "Training complete.\n",
      "Starting Round 476\n",
      "Epoch [100/2000], Loss: 0.2555, Val Loss: 0.2555\n",
      "Epoch [200/2000], Loss: 0.2798, Val Loss: 0.2798\n",
      "Early stopping at epoch 291\n",
      "Training complete.\n",
      "Starting Round 477\n",
      "Epoch [100/2000], Loss: 0.2388, Val Loss: 0.2388\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 478\n",
      "Epoch [100/2000], Loss: 0.2832, Val Loss: 0.2832\n",
      "Early stopping at epoch 143\n",
      "Training complete.\n",
      "Starting Round 479\n",
      "Epoch [100/2000], Loss: 0.2550, Val Loss: 0.2550\n",
      "Early stopping at epoch 162\n",
      "Training complete.\n",
      "Starting Round 480\n",
      "Epoch [100/2000], Loss: 0.2708, Val Loss: 0.2708\n",
      "Early stopping at epoch 175\n",
      "Training complete.\n",
      "Starting Round 481\n",
      "Epoch [100/2000], Loss: 0.2303, Val Loss: 0.2303\n",
      "Early stopping at epoch 182\n",
      "Training complete.\n",
      "Starting Round 482\n",
      "Epoch [100/2000], Loss: 0.2786, Val Loss: 0.2786\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 483\n",
      "Epoch [100/2000], Loss: 0.2658, Val Loss: 0.2658\n",
      "Epoch [200/2000], Loss: 0.2693, Val Loss: 0.2693\n",
      "Early stopping at epoch 286\n",
      "Training complete.\n",
      "Starting Round 484\n",
      "Epoch [100/2000], Loss: 0.2842, Val Loss: 0.2842\n",
      "Epoch [200/2000], Loss: 0.2610, Val Loss: 0.2610\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 485\n",
      "Epoch [100/2000], Loss: 0.2962, Val Loss: 0.2962\n",
      "Epoch [200/2000], Loss: 0.3032, Val Loss: 0.3032\n",
      "Early stopping at epoch 245\n",
      "Training complete.\n",
      "Starting Round 486\n",
      "Epoch [100/2000], Loss: 0.2533, Val Loss: 0.2533\n",
      "Epoch [200/2000], Loss: 0.2490, Val Loss: 0.2490\n",
      "Early stopping at epoch 281\n",
      "Training complete.\n",
      "Starting Round 487\n",
      "Epoch [100/2000], Loss: 0.2879, Val Loss: 0.2879\n",
      "Epoch [200/2000], Loss: 0.2933, Val Loss: 0.2933\n",
      "Epoch [300/2000], Loss: 0.2841, Val Loss: 0.2841\n",
      "Early stopping at epoch 328\n",
      "Training complete.\n",
      "Starting Round 488\n",
      "Epoch [100/2000], Loss: 0.2586, Val Loss: 0.2586\n",
      "Epoch [200/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Early stopping at epoch 248\n",
      "Training complete.\n",
      "Starting Round 489\n",
      "Epoch [100/2000], Loss: 0.2933, Val Loss: 0.2933\n",
      "Early stopping at epoch 160\n",
      "Training complete.\n",
      "Starting Round 490\n",
      "Epoch [100/2000], Loss: 0.2744, Val Loss: 0.2744\n",
      "Epoch [200/2000], Loss: 0.2692, Val Loss: 0.2692\n",
      "Early stopping at epoch 279\n",
      "Training complete.\n",
      "Starting Round 491\n",
      "Epoch [100/2000], Loss: 0.2337, Val Loss: 0.2337\n",
      "Epoch [200/2000], Loss: 0.2320, Val Loss: 0.2320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/2000], Loss: 0.2261, Val Loss: 0.2261\n",
      "Early stopping at epoch 355\n",
      "Training complete.\n",
      "Starting Round 492\n",
      "Epoch [100/2000], Loss: 0.2417, Val Loss: 0.2417\n",
      "Epoch [200/2000], Loss: 0.2387, Val Loss: 0.2387\n",
      "Epoch [300/2000], Loss: 0.2318, Val Loss: 0.2318\n",
      "Early stopping at epoch 307\n",
      "Training complete.\n",
      "Starting Round 493\n",
      "Epoch [100/2000], Loss: 0.2793, Val Loss: 0.2793\n",
      "Epoch [200/2000], Loss: 0.2748, Val Loss: 0.2748\n",
      "Epoch [300/2000], Loss: 0.2716, Val Loss: 0.2716\n",
      "Epoch [400/2000], Loss: 0.2724, Val Loss: 0.2724\n",
      "Early stopping at epoch 409\n",
      "Training complete.\n",
      "Starting Round 494\n",
      "Epoch [100/2000], Loss: 0.2350, Val Loss: 0.2350\n",
      "Epoch [200/2000], Loss: 0.2524, Val Loss: 0.2524\n",
      "Early stopping at epoch 237\n",
      "Training complete.\n",
      "Starting Round 495\n",
      "Epoch [100/2000], Loss: 0.2673, Val Loss: 0.2673\n",
      "Epoch [200/2000], Loss: 0.2446, Val Loss: 0.2446\n",
      "Epoch [300/2000], Loss: 0.2523, Val Loss: 0.2523\n",
      "Epoch [400/2000], Loss: 0.2573, Val Loss: 0.2573\n",
      "Early stopping at epoch 435\n",
      "Training complete.\n",
      "Starting Round 496\n",
      "Epoch [100/2000], Loss: 0.2743, Val Loss: 0.2743\n",
      "Early stopping at epoch 157\n",
      "Training complete.\n",
      "Starting Round 497\n",
      "Epoch [100/2000], Loss: 0.2704, Val Loss: 0.2704\n",
      "Early stopping at epoch 170\n",
      "Training complete.\n",
      "Starting Round 498\n",
      "Epoch [100/2000], Loss: 0.2353, Val Loss: 0.2353\n",
      "Epoch [200/2000], Loss: 0.2323, Val Loss: 0.2323\n",
      "Epoch [300/2000], Loss: 0.2362, Val Loss: 0.2362\n",
      "Early stopping at epoch 324\n",
      "Training complete.\n",
      "Starting Round 499\n",
      "Epoch [100/2000], Loss: 0.2293, Val Loss: 0.2293\n",
      "Epoch [200/2000], Loss: 0.2279, Val Loss: 0.2279\n",
      "Early stopping at epoch 254\n",
      "Training complete.\n",
      "Starting Round 500\n",
      "Epoch [100/2000], Loss: 0.2589, Val Loss: 0.2589\n",
      "Early stopping at epoch 199\n",
      "Training complete.\n",
      "Starting Round 501\n",
      "Epoch [100/2000], Loss: 0.2786, Val Loss: 0.2786\n",
      "Epoch [200/2000], Loss: 0.2532, Val Loss: 0.2532\n",
      "Early stopping at epoch 277\n",
      "Training complete.\n",
      "Starting Round 502\n",
      "Epoch [100/2000], Loss: 0.2393, Val Loss: 0.2393\n",
      "Epoch [200/2000], Loss: 0.2623, Val Loss: 0.2623\n",
      "Epoch [300/2000], Loss: 0.2518, Val Loss: 0.2518\n",
      "Early stopping at epoch 357\n",
      "Training complete.\n",
      "Starting Round 503\n",
      "Epoch [100/2000], Loss: 0.2780, Val Loss: 0.2780\n",
      "Early stopping at epoch 171\n",
      "Training complete.\n",
      "Starting Round 504\n",
      "Epoch [100/2000], Loss: 0.2296, Val Loss: 0.2296\n",
      "Epoch [200/2000], Loss: 0.2383, Val Loss: 0.2383\n",
      "Early stopping at epoch 233\n",
      "Training complete.\n",
      "Starting Round 505\n",
      "Epoch [100/2000], Loss: 0.2358, Val Loss: 0.2358\n",
      "Early stopping at epoch 187\n",
      "Training complete.\n",
      "Starting Round 506\n",
      "Epoch [100/2000], Loss: 0.2605, Val Loss: 0.2605\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 507\n",
      "Epoch [100/2000], Loss: 0.2943, Val Loss: 0.2943\n",
      "Epoch [200/2000], Loss: 0.2723, Val Loss: 0.2723\n",
      "Early stopping at epoch 252\n",
      "Training complete.\n",
      "Starting Round 508\n",
      "Epoch [100/2000], Loss: 0.2892, Val Loss: 0.2892\n",
      "Early stopping at epoch 164\n",
      "Training complete.\n",
      "Starting Round 509\n",
      "Epoch [100/2000], Loss: 0.2487, Val Loss: 0.2487\n",
      "Epoch [200/2000], Loss: 0.2687, Val Loss: 0.2687\n",
      "Early stopping at epoch 282\n",
      "Training complete.\n",
      "Starting Round 510\n",
      "Epoch [100/2000], Loss: 0.2319, Val Loss: 0.2319\n",
      "Epoch [200/2000], Loss: 0.2335, Val Loss: 0.2335\n",
      "Early stopping at epoch 275\n",
      "Training complete.\n",
      "Starting Round 511\n",
      "Epoch [100/2000], Loss: 0.2936, Val Loss: 0.2936\n",
      "Epoch [200/2000], Loss: 0.2949, Val Loss: 0.2949\n",
      "Early stopping at epoch 201\n",
      "Training complete.\n",
      "Starting Round 512\n",
      "Epoch [100/2000], Loss: 0.3182, Val Loss: 0.3182\n",
      "Epoch [200/2000], Loss: 0.3141, Val Loss: 0.3141\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 513\n",
      "Epoch [100/2000], Loss: 0.2146, Val Loss: 0.2146\n",
      "Epoch [200/2000], Loss: 0.2168, Val Loss: 0.2168\n",
      "Epoch [300/2000], Loss: 0.2115, Val Loss: 0.2115\n",
      "Epoch [400/2000], Loss: 0.1970, Val Loss: 0.1970\n",
      "Early stopping at epoch 448\n",
      "Training complete.\n",
      "Starting Round 514\n",
      "Epoch [100/2000], Loss: 0.2635, Val Loss: 0.2635\n",
      "Epoch [200/2000], Loss: 0.2576, Val Loss: 0.2576\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 515\n",
      "Epoch [100/2000], Loss: 0.2684, Val Loss: 0.2684\n",
      "Epoch [200/2000], Loss: 0.2718, Val Loss: 0.2718\n",
      "Early stopping at epoch 268\n",
      "Training complete.\n",
      "Starting Round 516\n",
      "Epoch [100/2000], Loss: 0.2454, Val Loss: 0.2454\n",
      "Epoch [200/2000], Loss: 0.2591, Val Loss: 0.2591\n",
      "Early stopping at epoch 290\n",
      "Training complete.\n",
      "Starting Round 517\n",
      "Epoch [100/2000], Loss: 0.2675, Val Loss: 0.2675\n",
      "Epoch [200/2000], Loss: 0.2534, Val Loss: 0.2534\n",
      "Epoch [300/2000], Loss: 0.2529, Val Loss: 0.2529\n",
      "Early stopping at epoch 326\n",
      "Training complete.\n",
      "Starting Round 518\n",
      "Epoch [100/2000], Loss: 0.2621, Val Loss: 0.2621\n",
      "Epoch [200/2000], Loss: 0.2576, Val Loss: 0.2576\n",
      "Epoch [300/2000], Loss: 0.2368, Val Loss: 0.2368\n",
      "Epoch [400/2000], Loss: 0.2389, Val Loss: 0.2389\n",
      "Epoch [500/2000], Loss: 0.2333, Val Loss: 0.2333\n",
      "Early stopping at epoch 506\n",
      "Training complete.\n",
      "Starting Round 519\n",
      "Epoch [100/2000], Loss: 0.2252, Val Loss: 0.2252\n",
      "Early stopping at epoch 188\n",
      "Training complete.\n",
      "Starting Round 520\n",
      "Epoch [100/2000], Loss: 0.2424, Val Loss: 0.2424\n",
      "Early stopping at epoch 188\n",
      "Training complete.\n",
      "Starting Round 521\n",
      "Epoch [100/2000], Loss: 0.2452, Val Loss: 0.2452\n",
      "Epoch [200/2000], Loss: 0.2836, Val Loss: 0.2836\n",
      "Early stopping at epoch 202\n",
      "Training complete.\n",
      "Starting Round 522\n",
      "Epoch [100/2000], Loss: 0.2410, Val Loss: 0.2410\n",
      "Epoch [200/2000], Loss: 0.2515, Val Loss: 0.2515\n",
      "Early stopping at epoch 245\n",
      "Training complete.\n",
      "Starting Round 523\n",
      "Epoch [100/2000], Loss: 0.2561, Val Loss: 0.2561\n",
      "Epoch [200/2000], Loss: 0.2574, Val Loss: 0.2574\n",
      "Early stopping at epoch 203\n",
      "Training complete.\n",
      "Starting Round 524\n",
      "Epoch [100/2000], Loss: 0.2438, Val Loss: 0.2438\n",
      "Early stopping at epoch 157\n",
      "Training complete.\n",
      "Starting Round 525\n",
      "Epoch [100/2000], Loss: 0.2387, Val Loss: 0.2387\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 526\n",
      "Epoch [100/2000], Loss: 0.2627, Val Loss: 0.2627\n",
      "Epoch [200/2000], Loss: 0.2489, Val Loss: 0.2489\n",
      "Early stopping at epoch 226\n",
      "Training complete.\n",
      "Starting Round 527\n",
      "Epoch [100/2000], Loss: 0.3053, Val Loss: 0.3053\n",
      "Epoch [200/2000], Loss: 0.2810, Val Loss: 0.2810\n",
      "Epoch [300/2000], Loss: 0.2805, Val Loss: 0.2805\n",
      "Epoch [400/2000], Loss: 0.2879, Val Loss: 0.2879\n",
      "Epoch [500/2000], Loss: 0.2775, Val Loss: 0.2775\n",
      "Epoch [600/2000], Loss: 0.2804, Val Loss: 0.2804\n",
      "Early stopping at epoch 608\n",
      "Training complete.\n",
      "Starting Round 528\n",
      "Epoch [100/2000], Loss: 0.2870, Val Loss: 0.2870\n",
      "Epoch [200/2000], Loss: 0.3029, Val Loss: 0.3029\n",
      "Early stopping at epoch 207\n",
      "Training complete.\n",
      "Starting Round 529\n",
      "Epoch [100/2000], Loss: 0.2584, Val Loss: 0.2584\n",
      "Epoch [200/2000], Loss: 0.2525, Val Loss: 0.2525\n",
      "Early stopping at epoch 259\n",
      "Training complete.\n",
      "Starting Round 530\n",
      "Epoch [100/2000], Loss: 0.2682, Val Loss: 0.2682\n",
      "Epoch [200/2000], Loss: 0.2609, Val Loss: 0.2609\n",
      "Epoch [300/2000], Loss: 0.2552, Val Loss: 0.2552\n",
      "Epoch [400/2000], Loss: 0.2674, Val Loss: 0.2674\n",
      "Early stopping at epoch 431\n",
      "Training complete.\n",
      "Starting Round 531\n",
      "Epoch [100/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Epoch [200/2000], Loss: 0.2696, Val Loss: 0.2696\n",
      "Early stopping at epoch 251\n",
      "Training complete.\n",
      "Starting Round 532\n",
      "Epoch [100/2000], Loss: 0.2588, Val Loss: 0.2588\n",
      "Epoch [200/2000], Loss: 0.2575, Val Loss: 0.2575\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 533\n",
      "Epoch [100/2000], Loss: 0.3088, Val Loss: 0.3088\n",
      "Epoch [200/2000], Loss: 0.2921, Val Loss: 0.2921\n",
      "Epoch [300/2000], Loss: 0.3030, Val Loss: 0.3030\n",
      "Early stopping at epoch 304\n",
      "Training complete.\n",
      "Starting Round 534\n",
      "Epoch [100/2000], Loss: 0.2359, Val Loss: 0.2359\n",
      "Epoch [200/2000], Loss: 0.2257, Val Loss: 0.2257\n",
      "Epoch [300/2000], Loss: 0.2206, Val Loss: 0.2206\n",
      "Early stopping at epoch 391\n",
      "Training complete.\n",
      "Starting Round 535\n",
      "Epoch [100/2000], Loss: 0.2844, Val Loss: 0.2844\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 536\n",
      "Epoch [100/2000], Loss: 0.2922, Val Loss: 0.2922\n",
      "Epoch [200/2000], Loss: 0.2883, Val Loss: 0.2883\n",
      "Early stopping at epoch 260\n",
      "Training complete.\n",
      "Starting Round 537\n",
      "Epoch [100/2000], Loss: 0.2844, Val Loss: 0.2844\n",
      "Epoch [200/2000], Loss: 0.2617, Val Loss: 0.2617\n",
      "Early stopping at epoch 272\n",
      "Training complete.\n",
      "Starting Round 538\n",
      "Epoch [100/2000], Loss: 0.2407, Val Loss: 0.2407\n",
      "Epoch [200/2000], Loss: 0.2433, Val Loss: 0.2433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/2000], Loss: 0.2466, Val Loss: 0.2466\n",
      "Early stopping at epoch 336\n",
      "Training complete.\n",
      "Starting Round 539\n",
      "Epoch [100/2000], Loss: 0.2678, Val Loss: 0.2678\n",
      "Early stopping at epoch 198\n",
      "Training complete.\n",
      "Starting Round 540\n",
      "Epoch [100/2000], Loss: 0.2798, Val Loss: 0.2798\n",
      "Epoch [200/2000], Loss: 0.2784, Val Loss: 0.2784\n",
      "Early stopping at epoch 237\n",
      "Training complete.\n",
      "Starting Round 541\n",
      "Epoch [100/2000], Loss: 0.3180, Val Loss: 0.3180\n",
      "Epoch [200/2000], Loss: 0.2858, Val Loss: 0.2858\n",
      "Epoch [300/2000], Loss: 0.2857, Val Loss: 0.2857\n",
      "Epoch [400/2000], Loss: 0.2886, Val Loss: 0.2886\n",
      "Early stopping at epoch 441\n",
      "Training complete.\n",
      "Starting Round 542\n",
      "Epoch [100/2000], Loss: 0.2990, Val Loss: 0.2990\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 543\n",
      "Epoch [100/2000], Loss: 0.2520, Val Loss: 0.2520\n",
      "Epoch [200/2000], Loss: 0.2546, Val Loss: 0.2546\n",
      "Epoch [300/2000], Loss: 0.2569, Val Loss: 0.2569\n",
      "Early stopping at epoch 309\n",
      "Training complete.\n",
      "Starting Round 544\n",
      "Epoch [100/2000], Loss: 0.2720, Val Loss: 0.2720\n",
      "Epoch [200/2000], Loss: 0.2652, Val Loss: 0.2652\n",
      "Epoch [300/2000], Loss: 0.2562, Val Loss: 0.2562\n",
      "Epoch [400/2000], Loss: 0.2538, Val Loss: 0.2538\n",
      "Early stopping at epoch 428\n",
      "Training complete.\n",
      "Starting Round 545\n",
      "Epoch [100/2000], Loss: 0.2341, Val Loss: 0.2341\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 546\n",
      "Epoch [100/2000], Loss: 0.2633, Val Loss: 0.2633\n",
      "Epoch [200/2000], Loss: 0.2559, Val Loss: 0.2559\n",
      "Early stopping at epoch 224\n",
      "Training complete.\n",
      "Starting Round 547\n",
      "Epoch [100/2000], Loss: 0.2670, Val Loss: 0.2670\n",
      "Epoch [200/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Early stopping at epoch 242\n",
      "Training complete.\n",
      "Starting Round 548\n",
      "Epoch [100/2000], Loss: 0.2289, Val Loss: 0.2289\n",
      "Early stopping at epoch 164\n",
      "Training complete.\n",
      "Starting Round 549\n",
      "Epoch [100/2000], Loss: 0.2297, Val Loss: 0.2297\n",
      "Epoch [200/2000], Loss: 0.2245, Val Loss: 0.2245\n",
      "Early stopping at epoch 206\n",
      "Training complete.\n",
      "Starting Round 550\n",
      "Epoch [100/2000], Loss: 0.2691, Val Loss: 0.2691\n",
      "Epoch [200/2000], Loss: 0.2608, Val Loss: 0.2608\n",
      "Epoch 00280: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Early stopping at epoch 281\n",
      "Training complete.\n",
      "Starting Round 551\n",
      "Epoch [100/2000], Loss: 0.2612, Val Loss: 0.2612\n",
      "Epoch [200/2000], Loss: 0.2607, Val Loss: 0.2607\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 552\n",
      "Epoch [100/2000], Loss: 0.2506, Val Loss: 0.2506\n",
      "Early stopping at epoch 189\n",
      "Training complete.\n",
      "Starting Round 553\n",
      "Epoch [100/2000], Loss: 0.2467, Val Loss: 0.2467\n",
      "Epoch [200/2000], Loss: 0.2330, Val Loss: 0.2330\n",
      "Epoch [300/2000], Loss: 0.2264, Val Loss: 0.2264\n",
      "Early stopping at epoch 400\n",
      "Training complete.\n",
      "Starting Round 554\n",
      "Epoch [100/2000], Loss: 0.2775, Val Loss: 0.2775\n",
      "Epoch [200/2000], Loss: 0.2786, Val Loss: 0.2786\n",
      "Epoch [300/2000], Loss: 0.2854, Val Loss: 0.2854\n",
      "Early stopping at epoch 316\n",
      "Training complete.\n",
      "Starting Round 555\n",
      "Epoch [100/2000], Loss: 0.2420, Val Loss: 0.2420\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 556\n",
      "Epoch [100/2000], Loss: 0.2712, Val Loss: 0.2712\n",
      "Early stopping at epoch 158\n",
      "Training complete.\n",
      "Starting Round 557\n",
      "Epoch [100/2000], Loss: 0.3088, Val Loss: 0.3088\n",
      "Epoch [200/2000], Loss: 0.3151, Val Loss: 0.3151\n",
      "Early stopping at epoch 211\n",
      "Training complete.\n",
      "Starting Round 558\n",
      "Epoch [100/2000], Loss: 0.2570, Val Loss: 0.2570\n",
      "Epoch [200/2000], Loss: 0.2558, Val Loss: 0.2558\n",
      "Early stopping at epoch 265\n",
      "Training complete.\n",
      "Starting Round 559\n",
      "Epoch [100/2000], Loss: 0.2836, Val Loss: 0.2836\n",
      "Epoch [200/2000], Loss: 0.2581, Val Loss: 0.2581\n",
      "Early stopping at epoch 232\n",
      "Training complete.\n",
      "Starting Round 560\n",
      "Epoch [100/2000], Loss: 0.2495, Val Loss: 0.2495\n",
      "Epoch [200/2000], Loss: 0.2563, Val Loss: 0.2563\n",
      "Early stopping at epoch 248\n",
      "Training complete.\n",
      "Starting Round 561\n",
      "Epoch [100/2000], Loss: 0.2562, Val Loss: 0.2562\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 562\n",
      "Epoch [100/2000], Loss: 0.2760, Val Loss: 0.2760\n",
      "Early stopping at epoch 180\n",
      "Training complete.\n",
      "Starting Round 563\n",
      "Epoch [100/2000], Loss: 0.2750, Val Loss: 0.2750\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 564\n",
      "Epoch [100/2000], Loss: 0.2676, Val Loss: 0.2676\n",
      "Epoch [200/2000], Loss: 0.2505, Val Loss: 0.2505\n",
      "Epoch [300/2000], Loss: 0.2520, Val Loss: 0.2520\n",
      "Epoch [400/2000], Loss: 0.2503, Val Loss: 0.2503\n",
      "Early stopping at epoch 411\n",
      "Training complete.\n",
      "Starting Round 565\n",
      "Epoch [100/2000], Loss: 0.2295, Val Loss: 0.2295\n",
      "Epoch [200/2000], Loss: 0.2166, Val Loss: 0.2166\n",
      "Epoch [300/2000], Loss: 0.2366, Val Loss: 0.2366\n",
      "Early stopping at epoch 321\n",
      "Training complete.\n",
      "Starting Round 566\n",
      "Epoch [100/2000], Loss: 0.2988, Val Loss: 0.2988\n",
      "Early stopping at epoch 151\n",
      "Training complete.\n",
      "Starting Round 567\n",
      "Epoch [100/2000], Loss: 0.2689, Val Loss: 0.2689\n",
      "Early stopping at epoch 156\n",
      "Training complete.\n",
      "Starting Round 568\n",
      "Epoch [100/2000], Loss: 0.2803, Val Loss: 0.2803\n",
      "Epoch [200/2000], Loss: 0.2999, Val Loss: 0.2999\n",
      "Early stopping at epoch 210\n",
      "Training complete.\n",
      "Starting Round 569\n",
      "Epoch [100/2000], Loss: 0.2732, Val Loss: 0.2732\n",
      "Epoch [200/2000], Loss: 0.2719, Val Loss: 0.2719\n",
      "Early stopping at epoch 210\n",
      "Training complete.\n",
      "Starting Round 570\n",
      "Epoch [100/2000], Loss: 0.2188, Val Loss: 0.2188\n",
      "Epoch [200/2000], Loss: 0.2157, Val Loss: 0.2157\n",
      "Early stopping at epoch 219\n",
      "Training complete.\n",
      "Starting Round 571\n",
      "Epoch [100/2000], Loss: 0.2447, Val Loss: 0.2447\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 572\n",
      "Epoch [100/2000], Loss: 0.2614, Val Loss: 0.2614\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 573\n",
      "Epoch [100/2000], Loss: 0.2651, Val Loss: 0.2651\n",
      "Epoch [200/2000], Loss: 0.2601, Val Loss: 0.2601\n",
      "Epoch [300/2000], Loss: 0.2627, Val Loss: 0.2627\n",
      "Early stopping at epoch 329\n",
      "Training complete.\n",
      "Starting Round 574\n",
      "Epoch [100/2000], Loss: 0.1921, Val Loss: 0.1921\n",
      "Early stopping at epoch 151\n",
      "Training complete.\n",
      "Starting Round 575\n",
      "Epoch [100/2000], Loss: 0.3143, Val Loss: 0.3143\n",
      "Epoch [200/2000], Loss: 0.3168, Val Loss: 0.3168\n",
      "Epoch [300/2000], Loss: 0.3082, Val Loss: 0.3082\n",
      "Early stopping at epoch 366\n",
      "Training complete.\n",
      "Starting Round 576\n",
      "Epoch [100/2000], Loss: 0.2146, Val Loss: 0.2146\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 577\n",
      "Epoch [100/2000], Loss: 0.2434, Val Loss: 0.2434\n",
      "Epoch [200/2000], Loss: 0.2553, Val Loss: 0.2553\n",
      "Early stopping at epoch 254\n",
      "Training complete.\n",
      "Starting Round 578\n",
      "Epoch [100/2000], Loss: 0.2369, Val Loss: 0.2369\n",
      "Epoch [200/2000], Loss: 0.2328, Val Loss: 0.2328\n",
      "Early stopping at epoch 268\n",
      "Training complete.\n",
      "Starting Round 579\n",
      "Epoch [100/2000], Loss: 0.2256, Val Loss: 0.2256\n",
      "Epoch [200/2000], Loss: 0.2347, Val Loss: 0.2347\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 580\n",
      "Epoch [100/2000], Loss: 0.2755, Val Loss: 0.2755\n",
      "Epoch [200/2000], Loss: 0.2677, Val Loss: 0.2677\n",
      "Epoch [300/2000], Loss: 0.2725, Val Loss: 0.2725\n",
      "Early stopping at epoch 362\n",
      "Training complete.\n",
      "Starting Round 581\n",
      "Epoch [100/2000], Loss: 0.3161, Val Loss: 0.3161\n",
      "Epoch [200/2000], Loss: 0.3278, Val Loss: 0.3278\n",
      "Epoch [300/2000], Loss: 0.3055, Val Loss: 0.3055\n",
      "Early stopping at epoch 359\n",
      "Training complete.\n",
      "Starting Round 582\n",
      "Epoch [100/2000], Loss: 0.2270, Val Loss: 0.2270\n",
      "Epoch [200/2000], Loss: 0.2185, Val Loss: 0.2185\n",
      "Epoch [300/2000], Loss: 0.2136, Val Loss: 0.2136\n",
      "Epoch [400/2000], Loss: 0.2222, Val Loss: 0.2222\n",
      "Early stopping at epoch 414\n",
      "Training complete.\n",
      "Starting Round 583\n",
      "Epoch [100/2000], Loss: 0.2825, Val Loss: 0.2825\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 584\n",
      "Epoch [100/2000], Loss: 0.2635, Val Loss: 0.2635\n",
      "Epoch 00181: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Epoch [200/2000], Loss: 0.2657, Val Loss: 0.2657\n",
      "Early stopping at epoch 237\n",
      "Training complete.\n",
      "Starting Round 585\n",
      "Epoch [100/2000], Loss: 0.2785, Val Loss: 0.2785\n",
      "Epoch [200/2000], Loss: 0.2709, Val Loss: 0.2709\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 586\n",
      "Epoch [100/2000], Loss: 0.2415, Val Loss: 0.2415\n",
      "Epoch [200/2000], Loss: 0.2475, Val Loss: 0.2475\n",
      "Early stopping at epoch 216\n",
      "Training complete.\n",
      "Starting Round 587\n",
      "Epoch [100/2000], Loss: 0.3220, Val Loss: 0.3220\n",
      "Early stopping at epoch 173\n",
      "Training complete.\n",
      "Starting Round 588\n",
      "Epoch [100/2000], Loss: 0.2897, Val Loss: 0.2897\n",
      "Epoch [200/2000], Loss: 0.2764, Val Loss: 0.2764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 267\n",
      "Training complete.\n",
      "Starting Round 589\n",
      "Epoch [100/2000], Loss: 0.2977, Val Loss: 0.2977\n",
      "Epoch [200/2000], Loss: 0.2964, Val Loss: 0.2964\n",
      "Early stopping at epoch 244\n",
      "Training complete.\n",
      "Starting Round 590\n",
      "Epoch [100/2000], Loss: 0.3508, Val Loss: 0.3508\n",
      "Epoch [200/2000], Loss: 0.3473, Val Loss: 0.3473\n",
      "Epoch [300/2000], Loss: 0.3322, Val Loss: 0.3322\n",
      "Epoch [400/2000], Loss: 0.3227, Val Loss: 0.3227\n",
      "Early stopping at epoch 437\n",
      "Training complete.\n",
      "Starting Round 591\n",
      "Epoch [100/2000], Loss: 0.2419, Val Loss: 0.2419\n",
      "Epoch [200/2000], Loss: 0.2264, Val Loss: 0.2264\n",
      "Early stopping at epoch 300\n",
      "Training complete.\n",
      "Starting Round 592\n",
      "Epoch [100/2000], Loss: 0.2197, Val Loss: 0.2197\n",
      "Early stopping at epoch 200\n",
      "Training complete.\n",
      "Starting Round 593\n",
      "Epoch [100/2000], Loss: 0.2470, Val Loss: 0.2470\n",
      "Early stopping at epoch 178\n",
      "Training complete.\n",
      "Starting Round 594\n",
      "Epoch [100/2000], Loss: 0.3029, Val Loss: 0.3029\n",
      "Epoch [200/2000], Loss: 0.3004, Val Loss: 0.3004\n",
      "Early stopping at epoch 279\n",
      "Training complete.\n",
      "Starting Round 595\n",
      "Epoch [100/2000], Loss: 0.2997, Val Loss: 0.2997\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 596\n",
      "Epoch [100/2000], Loss: 0.2748, Val Loss: 0.2748\n",
      "Epoch [200/2000], Loss: 0.2620, Val Loss: 0.2620\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 597\n",
      "Epoch [100/2000], Loss: 0.2589, Val Loss: 0.2589\n",
      "Epoch [200/2000], Loss: 0.2379, Val Loss: 0.2379\n",
      "Epoch [300/2000], Loss: 0.2363, Val Loss: 0.2363\n",
      "Epoch [400/2000], Loss: 0.2425, Val Loss: 0.2425\n",
      "Early stopping at epoch 459\n",
      "Training complete.\n",
      "Starting Round 598\n",
      "Epoch [100/2000], Loss: 0.3119, Val Loss: 0.3119\n",
      "Epoch [200/2000], Loss: 0.2971, Val Loss: 0.2971\n",
      "Early stopping at epoch 294\n",
      "Training complete.\n",
      "Starting Round 599\n",
      "Epoch [100/2000], Loss: 0.2971, Val Loss: 0.2971\n",
      "Early stopping at epoch 157\n",
      "Training complete.\n",
      "Starting Round 600\n",
      "Epoch [100/2000], Loss: 0.2908, Val Loss: 0.2908\n",
      "Epoch [200/2000], Loss: 0.2839, Val Loss: 0.2839\n",
      "Epoch [300/2000], Loss: 0.2868, Val Loss: 0.2868\n",
      "Early stopping at epoch 358\n",
      "Training complete.\n",
      "Starting Round 601\n",
      "Epoch [100/2000], Loss: 0.2216, Val Loss: 0.2216\n",
      "Epoch [200/2000], Loss: 0.2185, Val Loss: 0.2185\n",
      "Epoch [300/2000], Loss: 0.2099, Val Loss: 0.2099\n",
      "Epoch [400/2000], Loss: 0.2069, Val Loss: 0.2069\n",
      "Early stopping at epoch 403\n",
      "Training complete.\n",
      "Starting Round 602\n",
      "Epoch [100/2000], Loss: 0.2279, Val Loss: 0.2279\n",
      "Epoch [200/2000], Loss: 0.2339, Val Loss: 0.2339\n",
      "Epoch [300/2000], Loss: 0.2145, Val Loss: 0.2145\n",
      "Epoch [400/2000], Loss: 0.2242, Val Loss: 0.2242\n",
      "Early stopping at epoch 443\n",
      "Training complete.\n",
      "Starting Round 603\n",
      "Epoch [100/2000], Loss: 0.2963, Val Loss: 0.2963\n",
      "Epoch [200/2000], Loss: 0.2878, Val Loss: 0.2878\n",
      "Early stopping at epoch 280\n",
      "Training complete.\n",
      "Starting Round 604\n",
      "Epoch [100/2000], Loss: 0.2771, Val Loss: 0.2771\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 605\n",
      "Epoch [100/2000], Loss: 0.1935, Val Loss: 0.1935\n",
      "Epoch [200/2000], Loss: 0.2031, Val Loss: 0.2031\n",
      "Epoch [300/2000], Loss: 0.1954, Val Loss: 0.1954\n",
      "Epoch [400/2000], Loss: 0.1941, Val Loss: 0.1941\n",
      "Early stopping at epoch 416\n",
      "Training complete.\n",
      "Starting Round 606\n",
      "Epoch [100/2000], Loss: 0.2598, Val Loss: 0.2598\n",
      "Epoch [200/2000], Loss: 0.2555, Val Loss: 0.2555\n",
      "Epoch [300/2000], Loss: 0.2489, Val Loss: 0.2489\n",
      "Epoch [400/2000], Loss: 0.2371, Val Loss: 0.2371\n",
      "Early stopping at epoch 416\n",
      "Training complete.\n",
      "Starting Round 607\n",
      "Epoch [100/2000], Loss: 0.2752, Val Loss: 0.2752\n",
      "Epoch [200/2000], Loss: 0.2795, Val Loss: 0.2795\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 608\n",
      "Epoch [100/2000], Loss: 0.2575, Val Loss: 0.2575\n",
      "Early stopping at epoch 151\n",
      "Training complete.\n",
      "Starting Round 609\n",
      "Epoch [100/2000], Loss: 0.2443, Val Loss: 0.2443\n",
      "Epoch [200/2000], Loss: 0.2460, Val Loss: 0.2460\n",
      "Early stopping at epoch 209\n",
      "Training complete.\n",
      "Starting Round 610\n",
      "Epoch [100/2000], Loss: 0.3211, Val Loss: 0.3211\n",
      "Epoch [200/2000], Loss: 0.3073, Val Loss: 0.3073\n",
      "Early stopping at epoch 274\n",
      "Training complete.\n",
      "Starting Round 611\n",
      "Epoch [100/2000], Loss: 0.2562, Val Loss: 0.2562\n",
      "Epoch [200/2000], Loss: 0.2746, Val Loss: 0.2746\n",
      "Early stopping at epoch 204\n",
      "Training complete.\n",
      "Starting Round 612\n",
      "Epoch [100/2000], Loss: 0.2784, Val Loss: 0.2784\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 613\n",
      "Epoch [100/2000], Loss: 0.3238, Val Loss: 0.3238\n",
      "Early stopping at epoch 169\n",
      "Training complete.\n",
      "Starting Round 614\n",
      "Epoch [100/2000], Loss: 0.2797, Val Loss: 0.2797\n",
      "Epoch [200/2000], Loss: 0.2899, Val Loss: 0.2899\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 615\n",
      "Epoch [100/2000], Loss: 0.2607, Val Loss: 0.2607\n",
      "Epoch [200/2000], Loss: 0.2553, Val Loss: 0.2553\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 616\n",
      "Epoch [100/2000], Loss: 0.2257, Val Loss: 0.2257\n",
      "Epoch [200/2000], Loss: 0.2313, Val Loss: 0.2313\n",
      "Early stopping at epoch 236\n",
      "Training complete.\n",
      "Starting Round 617\n",
      "Epoch [100/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Epoch [200/2000], Loss: 0.2621, Val Loss: 0.2621\n",
      "Early stopping at epoch 227\n",
      "Training complete.\n",
      "Starting Round 618\n",
      "Epoch [100/2000], Loss: 0.2465, Val Loss: 0.2465\n",
      "Epoch [200/2000], Loss: 0.2481, Val Loss: 0.2481\n",
      "Epoch [300/2000], Loss: 0.2274, Val Loss: 0.2274\n",
      "Epoch [400/2000], Loss: 0.2293, Val Loss: 0.2293\n",
      "Epoch [500/2000], Loss: 0.2318, Val Loss: 0.2318\n",
      "Epoch [600/2000], Loss: 0.2290, Val Loss: 0.2290\n",
      "Early stopping at epoch 627\n",
      "Training complete.\n",
      "Starting Round 619\n",
      "Epoch [100/2000], Loss: 0.2372, Val Loss: 0.2372\n",
      "Epoch [200/2000], Loss: 0.2378, Val Loss: 0.2378\n",
      "Early stopping at epoch 262\n",
      "Training complete.\n",
      "Starting Round 620\n",
      "Epoch [100/2000], Loss: 0.2733, Val Loss: 0.2733\n",
      "Epoch [200/2000], Loss: 0.2759, Val Loss: 0.2759\n",
      "Epoch [300/2000], Loss: 0.2661, Val Loss: 0.2661\n",
      "Early stopping at epoch 315\n",
      "Training complete.\n",
      "Starting Round 621\n",
      "Epoch [100/2000], Loss: 0.3286, Val Loss: 0.3286\n",
      "Early stopping at epoch 198\n",
      "Training complete.\n",
      "Starting Round 622\n",
      "Epoch [100/2000], Loss: 0.2584, Val Loss: 0.2584\n",
      "Epoch [200/2000], Loss: 0.2581, Val Loss: 0.2581\n",
      "Early stopping at epoch 289\n",
      "Training complete.\n",
      "Starting Round 623\n",
      "Epoch [100/2000], Loss: 0.2925, Val Loss: 0.2925\n",
      "Early stopping at epoch 171\n",
      "Training complete.\n",
      "Starting Round 624\n",
      "Epoch [100/2000], Loss: 0.2553, Val Loss: 0.2553\n",
      "Epoch [200/2000], Loss: 0.2666, Val Loss: 0.2666\n",
      "Early stopping at epoch 225\n",
      "Training complete.\n",
      "Starting Round 625\n",
      "Epoch [100/2000], Loss: 0.2688, Val Loss: 0.2688\n",
      "Epoch [200/2000], Loss: 0.2508, Val Loss: 0.2508\n",
      "Early stopping at epoch 235\n",
      "Training complete.\n",
      "Starting Round 626\n",
      "Epoch [100/2000], Loss: 0.2663, Val Loss: 0.2663\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 627\n",
      "Epoch [100/2000], Loss: 0.2671, Val Loss: 0.2671\n",
      "Epoch [200/2000], Loss: 0.2545, Val Loss: 0.2545\n",
      "Epoch [300/2000], Loss: 0.2513, Val Loss: 0.2513\n",
      "Early stopping at epoch 357\n",
      "Training complete.\n",
      "Starting Round 628\n",
      "Epoch [100/2000], Loss: 0.2443, Val Loss: 0.2443\n",
      "Epoch [200/2000], Loss: 0.2499, Val Loss: 0.2499\n",
      "Early stopping at epoch 271\n",
      "Training complete.\n",
      "Starting Round 629\n",
      "Epoch [100/2000], Loss: 0.2616, Val Loss: 0.2616\n",
      "Early stopping at epoch 162\n",
      "Training complete.\n",
      "Starting Round 630\n",
      "Epoch [100/2000], Loss: 0.2636, Val Loss: 0.2636\n",
      "Epoch [200/2000], Loss: 0.2551, Val Loss: 0.2551\n",
      "Epoch [300/2000], Loss: 0.2515, Val Loss: 0.2515\n",
      "Early stopping at epoch 343\n",
      "Training complete.\n",
      "Starting Round 631\n",
      "Epoch [100/2000], Loss: 0.2690, Val Loss: 0.2690\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 632\n",
      "Epoch [100/2000], Loss: 0.3089, Val Loss: 0.3089\n",
      "Epoch [200/2000], Loss: 0.2754, Val Loss: 0.2754\n",
      "Early stopping at epoch 267\n",
      "Training complete.\n",
      "Starting Round 633\n",
      "Epoch [100/2000], Loss: 0.2507, Val Loss: 0.2507\n",
      "Epoch [200/2000], Loss: 0.2337, Val Loss: 0.2337\n",
      "Epoch [300/2000], Loss: 0.2305, Val Loss: 0.2305\n",
      "Epoch [400/2000], Loss: 0.2328, Val Loss: 0.2328\n",
      "Early stopping at epoch 467\n",
      "Training complete.\n",
      "Starting Round 634\n",
      "Epoch [100/2000], Loss: 0.2491, Val Loss: 0.2491\n",
      "Epoch [200/2000], Loss: 0.2326, Val Loss: 0.2326\n",
      "Epoch [300/2000], Loss: 0.2406, Val Loss: 0.2406\n",
      "Epoch [400/2000], Loss: 0.2397, Val Loss: 0.2397\n",
      "Early stopping at epoch 452\n",
      "Training complete.\n",
      "Starting Round 635\n",
      "Epoch [100/2000], Loss: 0.2770, Val Loss: 0.2770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 636\n",
      "Epoch [100/2000], Loss: 0.2413, Val Loss: 0.2413\n",
      "Epoch [200/2000], Loss: 0.2363, Val Loss: 0.2363\n",
      "Epoch [300/2000], Loss: 0.2379, Val Loss: 0.2379\n",
      "Early stopping at epoch 319\n",
      "Training complete.\n",
      "Starting Round 637\n",
      "Epoch [100/2000], Loss: 0.2631, Val Loss: 0.2631\n",
      "Epoch [200/2000], Loss: 0.2540, Val Loss: 0.2540\n",
      "Early stopping at epoch 283\n",
      "Training complete.\n",
      "Starting Round 638\n",
      "Epoch [100/2000], Loss: 0.2549, Val Loss: 0.2549\n",
      "Epoch [200/2000], Loss: 0.2435, Val Loss: 0.2435\n",
      "Epoch [300/2000], Loss: 0.2459, Val Loss: 0.2459\n",
      "Early stopping at epoch 382\n",
      "Training complete.\n",
      "Starting Round 639\n",
      "Epoch [100/2000], Loss: 0.2855, Val Loss: 0.2855\n",
      "Epoch [200/2000], Loss: 0.2961, Val Loss: 0.2961\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 640\n",
      "Epoch [100/2000], Loss: 0.2339, Val Loss: 0.2339\n",
      "Early stopping at epoch 197\n",
      "Training complete.\n",
      "Starting Round 641\n",
      "Epoch [100/2000], Loss: 0.2676, Val Loss: 0.2676\n",
      "Epoch [200/2000], Loss: 0.2703, Val Loss: 0.2703\n",
      "Epoch [300/2000], Loss: 0.2894, Val Loss: 0.2894\n",
      "Epoch [400/2000], Loss: 0.2754, Val Loss: 0.2754\n",
      "Early stopping at epoch 458\n",
      "Training complete.\n",
      "Starting Round 642\n",
      "Epoch [100/2000], Loss: 0.2591, Val Loss: 0.2591\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 643\n",
      "Epoch [100/2000], Loss: 0.2410, Val Loss: 0.2410\n",
      "Epoch [200/2000], Loss: 0.2475, Val Loss: 0.2475\n",
      "Early stopping at epoch 252\n",
      "Training complete.\n",
      "Starting Round 644\n",
      "Epoch [100/2000], Loss: 0.2473, Val Loss: 0.2473\n",
      "Early stopping at epoch 178\n",
      "Training complete.\n",
      "Starting Round 645\n",
      "Epoch [100/2000], Loss: 0.2541, Val Loss: 0.2541\n",
      "Epoch [200/2000], Loss: 0.2680, Val Loss: 0.2680\n",
      "Early stopping at epoch 291\n",
      "Training complete.\n",
      "Starting Round 646\n",
      "Epoch [100/2000], Loss: 0.2578, Val Loss: 0.2578\n",
      "Epoch [200/2000], Loss: 0.2514, Val Loss: 0.2514\n",
      "Early stopping at epoch 250\n",
      "Training complete.\n",
      "Starting Round 647\n",
      "Epoch [100/2000], Loss: 0.2765, Val Loss: 0.2765\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 648\n",
      "Epoch [100/2000], Loss: 0.2787, Val Loss: 0.2787\n",
      "Early stopping at epoch 153\n",
      "Training complete.\n",
      "Starting Round 649\n",
      "Epoch [100/2000], Loss: 0.2357, Val Loss: 0.2357\n",
      "Epoch [200/2000], Loss: 0.2426, Val Loss: 0.2426\n",
      "Early stopping at epoch 219\n",
      "Training complete.\n",
      "Starting Round 650\n",
      "Epoch [100/2000], Loss: 0.2959, Val Loss: 0.2959\n",
      "Early stopping at epoch 170\n",
      "Training complete.\n",
      "Starting Round 651\n",
      "Epoch [100/2000], Loss: 0.2575, Val Loss: 0.2575\n",
      "Epoch [200/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Early stopping at epoch 234\n",
      "Training complete.\n",
      "Starting Round 652\n",
      "Epoch [100/2000], Loss: 0.2320, Val Loss: 0.2320\n",
      "Epoch [200/2000], Loss: 0.2202, Val Loss: 0.2202\n",
      "Epoch [300/2000], Loss: 0.2307, Val Loss: 0.2307\n",
      "Epoch [400/2000], Loss: 0.2222, Val Loss: 0.2222\n",
      "Early stopping at epoch 469\n",
      "Training complete.\n",
      "Starting Round 653\n",
      "Epoch [100/2000], Loss: 0.2645, Val Loss: 0.2645\n",
      "Epoch [200/2000], Loss: 0.2730, Val Loss: 0.2730\n",
      "Early stopping at epoch 261\n",
      "Training complete.\n",
      "Starting Round 654\n",
      "Epoch [100/2000], Loss: 0.2511, Val Loss: 0.2511\n",
      "Epoch [200/2000], Loss: 0.2448, Val Loss: 0.2448\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 655\n",
      "Epoch [100/2000], Loss: 0.2200, Val Loss: 0.2200\n",
      "Epoch [200/2000], Loss: 0.2234, Val Loss: 0.2234\n",
      "Early stopping at epoch 294\n",
      "Training complete.\n",
      "Starting Round 656\n",
      "Epoch [100/2000], Loss: 0.2713, Val Loss: 0.2713\n",
      "Epoch [200/2000], Loss: 0.2604, Val Loss: 0.2604\n",
      "Early stopping at epoch 264\n",
      "Training complete.\n",
      "Starting Round 657\n",
      "Epoch [100/2000], Loss: 0.2727, Val Loss: 0.2727\n",
      "Epoch [200/2000], Loss: 0.2621, Val Loss: 0.2621\n",
      "Early stopping at epoch 290\n",
      "Training complete.\n",
      "Starting Round 658\n",
      "Epoch [100/2000], Loss: 0.2619, Val Loss: 0.2619\n",
      "Epoch [200/2000], Loss: 0.2704, Val Loss: 0.2704\n",
      "Early stopping at epoch 248\n",
      "Training complete.\n",
      "Starting Round 659\n",
      "Epoch [100/2000], Loss: 0.2548, Val Loss: 0.2548\n",
      "Epoch [200/2000], Loss: 0.2440, Val Loss: 0.2440\n",
      "Early stopping at epoch 276\n",
      "Training complete.\n",
      "Starting Round 660\n",
      "Epoch [100/2000], Loss: 0.2618, Val Loss: 0.2618\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 661\n",
      "Epoch [100/2000], Loss: 0.2680, Val Loss: 0.2680\n",
      "Epoch [200/2000], Loss: 0.2732, Val Loss: 0.2732\n",
      "Early stopping at epoch 217\n",
      "Training complete.\n",
      "Starting Round 662\n",
      "Epoch [100/2000], Loss: 0.2762, Val Loss: 0.2762\n",
      "Early stopping at epoch 172\n",
      "Training complete.\n",
      "Starting Round 663\n",
      "Epoch [100/2000], Loss: 0.2484, Val Loss: 0.2484\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 664\n",
      "Epoch [100/2000], Loss: 0.2329, Val Loss: 0.2329\n",
      "Early stopping at epoch 199\n",
      "Training complete.\n",
      "Starting Round 665\n",
      "Epoch [100/2000], Loss: 0.2462, Val Loss: 0.2462\n",
      "Early stopping at epoch 166\n",
      "Training complete.\n",
      "Starting Round 666\n",
      "Epoch [100/2000], Loss: 0.3140, Val Loss: 0.3140\n",
      "Epoch [200/2000], Loss: 0.3144, Val Loss: 0.3144\n",
      "Early stopping at epoch 205\n",
      "Training complete.\n",
      "Starting Round 667\n",
      "Epoch [100/2000], Loss: 0.2961, Val Loss: 0.2961\n",
      "Early stopping at epoch 179\n",
      "Training complete.\n",
      "Starting Round 668\n",
      "Epoch [100/2000], Loss: 0.2760, Val Loss: 0.2760\n",
      "Early stopping at epoch 151\n",
      "Training complete.\n",
      "Starting Round 669\n",
      "Epoch [100/2000], Loss: 0.2740, Val Loss: 0.2740\n",
      "Epoch [200/2000], Loss: 0.2757, Val Loss: 0.2757\n",
      "Early stopping at epoch 266\n",
      "Training complete.\n",
      "Starting Round 670\n",
      "Epoch [100/2000], Loss: 0.2355, Val Loss: 0.2355\n",
      "Epoch [200/2000], Loss: 0.2386, Val Loss: 0.2386\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 671\n",
      "Epoch [100/2000], Loss: 0.2401, Val Loss: 0.2401\n",
      "Epoch [200/2000], Loss: 0.2353, Val Loss: 0.2353\n",
      "Early stopping at epoch 225\n",
      "Training complete.\n",
      "Starting Round 672\n",
      "Epoch [100/2000], Loss: 0.2042, Val Loss: 0.2042\n",
      "Early stopping at epoch 194\n",
      "Training complete.\n",
      "Starting Round 673\n",
      "Epoch [100/2000], Loss: 0.2317, Val Loss: 0.2317\n",
      "Epoch [200/2000], Loss: 0.2608, Val Loss: 0.2608\n",
      "Early stopping at epoch 220\n",
      "Training complete.\n",
      "Starting Round 674\n",
      "Epoch [100/2000], Loss: 0.2807, Val Loss: 0.2807\n",
      "Epoch [200/2000], Loss: 0.2728, Val Loss: 0.2728\n",
      "Epoch [300/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Early stopping at epoch 388\n",
      "Training complete.\n",
      "Starting Round 675\n",
      "Epoch [100/2000], Loss: 0.2859, Val Loss: 0.2859\n",
      "Early stopping at epoch 192\n",
      "Training complete.\n",
      "Starting Round 676\n",
      "Epoch [100/2000], Loss: 0.2438, Val Loss: 0.2438\n",
      "Early stopping at epoch 139\n",
      "Training complete.\n",
      "Starting Round 677\n",
      "Epoch [100/2000], Loss: 0.2416, Val Loss: 0.2416\n",
      "Epoch [200/2000], Loss: 0.2410, Val Loss: 0.2410\n",
      "Early stopping at epoch 294\n",
      "Training complete.\n",
      "Starting Round 678\n",
      "Epoch [100/2000], Loss: 0.2715, Val Loss: 0.2715\n",
      "Epoch [200/2000], Loss: 0.2576, Val Loss: 0.2576\n",
      "Epoch [300/2000], Loss: 0.2631, Val Loss: 0.2631\n",
      "Early stopping at epoch 315\n",
      "Training complete.\n",
      "Starting Round 679\n",
      "Epoch [100/2000], Loss: 0.2408, Val Loss: 0.2408\n",
      "Epoch [200/2000], Loss: 0.2242, Val Loss: 0.2242\n",
      "Early stopping at epoch 217\n",
      "Training complete.\n",
      "Starting Round 680\n",
      "Epoch [100/2000], Loss: 0.2533, Val Loss: 0.2533\n",
      "Epoch [200/2000], Loss: 0.2334, Val Loss: 0.2334\n",
      "Epoch [300/2000], Loss: 0.2272, Val Loss: 0.2272\n",
      "Early stopping at epoch 399\n",
      "Training complete.\n",
      "Starting Round 681\n",
      "Epoch [100/2000], Loss: 0.2887, Val Loss: 0.2887\n",
      "Epoch [200/2000], Loss: 0.2854, Val Loss: 0.2854\n",
      "Epoch [300/2000], Loss: 0.2990, Val Loss: 0.2990\n",
      "Early stopping at epoch 331\n",
      "Training complete.\n",
      "Starting Round 682\n",
      "Epoch [100/2000], Loss: 0.2979, Val Loss: 0.2979\n",
      "Epoch [200/2000], Loss: 0.2884, Val Loss: 0.2884\n",
      "Epoch [300/2000], Loss: 0.2835, Val Loss: 0.2835\n",
      "Early stopping at epoch 308\n",
      "Training complete.\n",
      "Starting Round 683\n",
      "Epoch [100/2000], Loss: 0.2661, Val Loss: 0.2661\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 684\n",
      "Epoch [100/2000], Loss: 0.3241, Val Loss: 0.3241\n",
      "Early stopping at epoch 156\n",
      "Training complete.\n",
      "Starting Round 685\n",
      "Epoch [100/2000], Loss: 0.2414, Val Loss: 0.2414\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 686\n",
      "Epoch [100/2000], Loss: 0.2466, Val Loss: 0.2466\n",
      "Early stopping at epoch 175\n",
      "Training complete.\n",
      "Starting Round 687\n",
      "Epoch [100/2000], Loss: 0.2891, Val Loss: 0.2891\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 688\n",
      "Epoch [100/2000], Loss: 0.2621, Val Loss: 0.2621\n",
      "Epoch [200/2000], Loss: 0.2656, Val Loss: 0.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/2000], Loss: 0.2676, Val Loss: 0.2676\n",
      "Early stopping at epoch 317\n",
      "Training complete.\n",
      "Starting Round 689\n",
      "Epoch [100/2000], Loss: 0.2532, Val Loss: 0.2532\n",
      "Epoch [200/2000], Loss: 0.2502, Val Loss: 0.2502\n",
      "Early stopping at epoch 250\n",
      "Training complete.\n",
      "Starting Round 690\n",
      "Epoch [100/2000], Loss: 0.2651, Val Loss: 0.2651\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 691\n",
      "Epoch [100/2000], Loss: 0.2705, Val Loss: 0.2705\n",
      "Epoch [200/2000], Loss: 0.2703, Val Loss: 0.2703\n",
      "Epoch [300/2000], Loss: 0.2542, Val Loss: 0.2542\n",
      "Epoch [400/2000], Loss: 0.2597, Val Loss: 0.2597\n",
      "Early stopping at epoch 419\n",
      "Training complete.\n",
      "Starting Round 692\n",
      "Epoch [100/2000], Loss: 0.3047, Val Loss: 0.3047\n",
      "Early stopping at epoch 188\n",
      "Training complete.\n",
      "Starting Round 693\n",
      "Epoch [100/2000], Loss: 0.2918, Val Loss: 0.2918\n",
      "Early stopping at epoch 178\n",
      "Training complete.\n",
      "Starting Round 694\n",
      "Epoch [100/2000], Loss: 0.2856, Val Loss: 0.2856\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 695\n",
      "Epoch [100/2000], Loss: 0.2418, Val Loss: 0.2418\n",
      "Epoch [200/2000], Loss: 0.2428, Val Loss: 0.2428\n",
      "Epoch [300/2000], Loss: 0.2596, Val Loss: 0.2596\n",
      "Early stopping at epoch 380\n",
      "Training complete.\n",
      "Starting Round 696\n",
      "Epoch [100/2000], Loss: 0.2730, Val Loss: 0.2730\n",
      "Epoch [200/2000], Loss: 0.2720, Val Loss: 0.2720\n",
      "Epoch [300/2000], Loss: 0.2795, Val Loss: 0.2795\n",
      "Epoch [400/2000], Loss: 0.2775, Val Loss: 0.2775\n",
      "Early stopping at epoch 442\n",
      "Training complete.\n",
      "Starting Round 697\n",
      "Epoch [100/2000], Loss: 0.2864, Val Loss: 0.2864\n",
      "Epoch [200/2000], Loss: 0.2897, Val Loss: 0.2897\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 698\n",
      "Epoch [100/2000], Loss: 0.2768, Val Loss: 0.2768\n",
      "Epoch [200/2000], Loss: 0.2725, Val Loss: 0.2725\n",
      "Early stopping at epoch 238\n",
      "Training complete.\n",
      "Starting Round 699\n",
      "Epoch [100/2000], Loss: 0.2605, Val Loss: 0.2605\n",
      "Epoch [200/2000], Loss: 0.2852, Val Loss: 0.2852\n",
      "Early stopping at epoch 209\n",
      "Training complete.\n",
      "Starting Round 700\n",
      "Epoch [100/2000], Loss: 0.2781, Val Loss: 0.2781\n",
      "Epoch [200/2000], Loss: 0.2606, Val Loss: 0.2606\n",
      "Early stopping at epoch 279\n",
      "Training complete.\n",
      "Starting Round 701\n",
      "Epoch [100/2000], Loss: 0.2573, Val Loss: 0.2573\n",
      "Early stopping at epoch 168\n",
      "Training complete.\n",
      "Starting Round 702\n",
      "Epoch [100/2000], Loss: 0.2523, Val Loss: 0.2523\n",
      "Epoch [200/2000], Loss: 0.2510, Val Loss: 0.2510\n",
      "Early stopping at epoch 259\n",
      "Training complete.\n",
      "Starting Round 703\n",
      "Epoch [100/2000], Loss: 0.2505, Val Loss: 0.2505\n",
      "Epoch [200/2000], Loss: 0.2597, Val Loss: 0.2597\n",
      "Early stopping at epoch 247\n",
      "Training complete.\n",
      "Starting Round 704\n",
      "Epoch [100/2000], Loss: 0.2791, Val Loss: 0.2791\n",
      "Epoch [200/2000], Loss: 0.2709, Val Loss: 0.2709\n",
      "Early stopping at epoch 243\n",
      "Training complete.\n",
      "Starting Round 705\n",
      "Epoch [100/2000], Loss: 0.2643, Val Loss: 0.2643\n",
      "Epoch [200/2000], Loss: 0.2698, Val Loss: 0.2698\n",
      "Epoch [300/2000], Loss: 0.2704, Val Loss: 0.2704\n",
      "Epoch [400/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Early stopping at epoch 426\n",
      "Training complete.\n",
      "Starting Round 706\n",
      "Epoch [100/2000], Loss: 0.2309, Val Loss: 0.2309\n",
      "Epoch [200/2000], Loss: 0.2233, Val Loss: 0.2233\n",
      "Epoch [300/2000], Loss: 0.2367, Val Loss: 0.2367\n",
      "Early stopping at epoch 313\n",
      "Training complete.\n",
      "Starting Round 707\n",
      "Epoch [100/2000], Loss: 0.2722, Val Loss: 0.2722\n",
      "Epoch [200/2000], Loss: 0.2855, Val Loss: 0.2855\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 708\n",
      "Epoch [100/2000], Loss: 0.2557, Val Loss: 0.2557\n",
      "Epoch [200/2000], Loss: 0.2584, Val Loss: 0.2584\n",
      "Early stopping at epoch 274\n",
      "Training complete.\n",
      "Starting Round 709\n",
      "Epoch [100/2000], Loss: 0.2533, Val Loss: 0.2533\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 710\n",
      "Epoch [100/2000], Loss: 0.2351, Val Loss: 0.2351\n",
      "Epoch [200/2000], Loss: 0.2308, Val Loss: 0.2308\n",
      "Early stopping at epoch 210\n",
      "Training complete.\n",
      "Starting Round 711\n",
      "Epoch [100/2000], Loss: 0.2276, Val Loss: 0.2276\n",
      "Epoch [200/2000], Loss: 0.2283, Val Loss: 0.2283\n",
      "Early stopping at epoch 262\n",
      "Training complete.\n",
      "Starting Round 712\n",
      "Epoch [100/2000], Loss: 0.2735, Val Loss: 0.2735\n",
      "Epoch [200/2000], Loss: 0.2705, Val Loss: 0.2705\n",
      "Epoch [300/2000], Loss: 0.2600, Val Loss: 0.2600\n",
      "Epoch [400/2000], Loss: 0.2595, Val Loss: 0.2595\n",
      "Epoch [500/2000], Loss: 0.2442, Val Loss: 0.2442\n",
      "Early stopping at epoch 525\n",
      "Training complete.\n",
      "Starting Round 713\n",
      "Epoch [100/2000], Loss: 0.2647, Val Loss: 0.2647\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 714\n",
      "Epoch [100/2000], Loss: 0.2799, Val Loss: 0.2799\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 715\n",
      "Epoch [100/2000], Loss: 0.2650, Val Loss: 0.2650\n",
      "Epoch [200/2000], Loss: 0.2586, Val Loss: 0.2586\n",
      "Early stopping at epoch 227\n",
      "Training complete.\n",
      "Starting Round 716\n",
      "Epoch [100/2000], Loss: 0.2540, Val Loss: 0.2540\n",
      "Epoch [200/2000], Loss: 0.2519, Val Loss: 0.2519\n",
      "Early stopping at epoch 251\n",
      "Training complete.\n",
      "Starting Round 717\n",
      "Epoch [100/2000], Loss: 0.2500, Val Loss: 0.2500\n",
      "Epoch [200/2000], Loss: 0.2424, Val Loss: 0.2424\n",
      "Early stopping at epoch 220\n",
      "Training complete.\n",
      "Starting Round 718\n",
      "Epoch [100/2000], Loss: 0.2640, Val Loss: 0.2640\n",
      "Epoch [200/2000], Loss: 0.2573, Val Loss: 0.2573\n",
      "Epoch [300/2000], Loss: 0.2462, Val Loss: 0.2462\n",
      "Early stopping at epoch 319\n",
      "Training complete.\n",
      "Starting Round 719\n",
      "Epoch [100/2000], Loss: 0.2668, Val Loss: 0.2668\n",
      "Epoch [200/2000], Loss: 0.2738, Val Loss: 0.2738\n",
      "Early stopping at epoch 216\n",
      "Training complete.\n",
      "Starting Round 720\n",
      "Epoch [100/2000], Loss: 0.2419, Val Loss: 0.2419\n",
      "Epoch [200/2000], Loss: 0.2414, Val Loss: 0.2414\n",
      "Epoch [300/2000], Loss: 0.2378, Val Loss: 0.2378\n",
      "Early stopping at epoch 376\n",
      "Training complete.\n",
      "Starting Round 721\n",
      "Epoch [100/2000], Loss: 0.3249, Val Loss: 0.3249\n",
      "Epoch [200/2000], Loss: 0.3267, Val Loss: 0.3267\n",
      "Early stopping at epoch 206\n",
      "Training complete.\n",
      "Starting Round 722\n",
      "Epoch [100/2000], Loss: 0.2533, Val Loss: 0.2533\n",
      "Early stopping at epoch 186\n",
      "Training complete.\n",
      "Starting Round 723\n",
      "Epoch [100/2000], Loss: 0.2730, Val Loss: 0.2730\n",
      "Epoch [200/2000], Loss: 0.2618, Val Loss: 0.2618\n",
      "Early stopping at epoch 264\n",
      "Training complete.\n",
      "Starting Round 724\n",
      "Epoch [100/2000], Loss: 0.2442, Val Loss: 0.2442\n",
      "Epoch [200/2000], Loss: 0.2448, Val Loss: 0.2448\n",
      "Epoch [300/2000], Loss: 0.2397, Val Loss: 0.2397\n",
      "Early stopping at epoch 325\n",
      "Training complete.\n",
      "Starting Round 725\n",
      "Epoch [100/2000], Loss: 0.2537, Val Loss: 0.2537\n",
      "Epoch [200/2000], Loss: 0.2523, Val Loss: 0.2523\n",
      "Early stopping at epoch 227\n",
      "Training complete.\n",
      "Starting Round 726\n",
      "Epoch [100/2000], Loss: 0.2426, Val Loss: 0.2426\n",
      "Epoch [200/2000], Loss: 0.2364, Val Loss: 0.2364\n",
      "Early stopping at epoch 262\n",
      "Training complete.\n",
      "Starting Round 727\n",
      "Epoch [100/2000], Loss: 0.3034, Val Loss: 0.3034\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 728\n",
      "Epoch [100/2000], Loss: 0.2571, Val Loss: 0.2571\n",
      "Epoch [200/2000], Loss: 0.2656, Val Loss: 0.2656\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 729\n",
      "Epoch [100/2000], Loss: 0.2799, Val Loss: 0.2799\n",
      "Epoch [200/2000], Loss: 0.2764, Val Loss: 0.2764\n",
      "Early stopping at epoch 229\n",
      "Training complete.\n",
      "Starting Round 730\n",
      "Epoch [100/2000], Loss: 0.2348, Val Loss: 0.2348\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 731\n",
      "Epoch [100/2000], Loss: 0.2579, Val Loss: 0.2579\n",
      "Epoch [200/2000], Loss: 0.2558, Val Loss: 0.2558\n",
      "Epoch [300/2000], Loss: 0.2501, Val Loss: 0.2501\n",
      "Early stopping at epoch 376\n",
      "Training complete.\n",
      "Starting Round 732\n",
      "Epoch [100/2000], Loss: 0.2957, Val Loss: 0.2957\n",
      "Early stopping at epoch 156\n",
      "Training complete.\n",
      "Starting Round 733\n",
      "Epoch [100/2000], Loss: 0.2814, Val Loss: 0.2814\n",
      "Early stopping at epoch 162\n",
      "Training complete.\n",
      "Starting Round 734\n",
      "Epoch [100/2000], Loss: 0.2906, Val Loss: 0.2906\n",
      "Epoch [200/2000], Loss: 0.3170, Val Loss: 0.3170\n",
      "Early stopping at epoch 267\n",
      "Training complete.\n",
      "Starting Round 735\n",
      "Epoch [100/2000], Loss: 0.2278, Val Loss: 0.2278\n",
      "Epoch [200/2000], Loss: 0.2272, Val Loss: 0.2272\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 736\n",
      "Epoch [100/2000], Loss: 0.2556, Val Loss: 0.2556\n",
      "Epoch [200/2000], Loss: 0.2541, Val Loss: 0.2541\n",
      "Epoch [300/2000], Loss: 0.2493, Val Loss: 0.2493\n",
      "Early stopping at epoch 355\n",
      "Training complete.\n",
      "Starting Round 737\n",
      "Epoch [100/2000], Loss: 0.2503, Val Loss: 0.2503\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.2584, Val Loss: 0.2584\n",
      "Epoch [200/2000], Loss: 0.2499, Val Loss: 0.2499\n",
      "Early stopping at epoch 276\n",
      "Training complete.\n",
      "Starting Round 739\n",
      "Epoch [100/2000], Loss: 0.2365, Val Loss: 0.2365\n",
      "Epoch [200/2000], Loss: 0.2271, Val Loss: 0.2271\n",
      "Early stopping at epoch 231\n",
      "Training complete.\n",
      "Starting Round 740\n",
      "Epoch [100/2000], Loss: 0.2246, Val Loss: 0.2246\n",
      "Epoch [200/2000], Loss: 0.2236, Val Loss: 0.2236\n",
      "Early stopping at epoch 256\n",
      "Training complete.\n",
      "Starting Round 741\n",
      "Epoch [100/2000], Loss: 0.2728, Val Loss: 0.2728\n",
      "Epoch [200/2000], Loss: 0.2719, Val Loss: 0.2719\n",
      "Early stopping at epoch 209\n",
      "Training complete.\n",
      "Starting Round 742\n",
      "Epoch [100/2000], Loss: 0.2760, Val Loss: 0.2760\n",
      "Epoch [200/2000], Loss: 0.2712, Val Loss: 0.2712\n",
      "Early stopping at epoch 218\n",
      "Training complete.\n",
      "Starting Round 743\n",
      "Epoch [100/2000], Loss: 0.2854, Val Loss: 0.2854\n",
      "Epoch [200/2000], Loss: 0.2862, Val Loss: 0.2862\n",
      "Early stopping at epoch 299\n",
      "Training complete.\n",
      "Starting Round 744\n",
      "Epoch [100/2000], Loss: 0.2340, Val Loss: 0.2340\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 745\n",
      "Epoch [100/2000], Loss: 0.2759, Val Loss: 0.2759\n",
      "Epoch [200/2000], Loss: 0.2874, Val Loss: 0.2874\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 746\n",
      "Epoch [100/2000], Loss: 0.2130, Val Loss: 0.2130\n",
      "Early stopping at epoch 150\n",
      "Training complete.\n",
      "Starting Round 747\n",
      "Epoch [100/2000], Loss: 0.2373, Val Loss: 0.2373\n",
      "Epoch [200/2000], Loss: 0.2271, Val Loss: 0.2271\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 748\n",
      "Epoch [100/2000], Loss: 0.2904, Val Loss: 0.2904\n",
      "Epoch [200/2000], Loss: 0.2845, Val Loss: 0.2845\n",
      "Early stopping at epoch 231\n",
      "Training complete.\n",
      "Starting Round 749\n",
      "Epoch [100/2000], Loss: 0.2809, Val Loss: 0.2809\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 750\n",
      "Epoch [100/2000], Loss: 0.2220, Val Loss: 0.2220\n",
      "Epoch [200/2000], Loss: 0.2331, Val Loss: 0.2331\n",
      "Early stopping at epoch 240\n",
      "Training complete.\n",
      "Starting Round 751\n",
      "Epoch [100/2000], Loss: 0.2365, Val Loss: 0.2365\n",
      "Epoch [200/2000], Loss: 0.2492, Val Loss: 0.2492\n",
      "Early stopping at epoch 206\n",
      "Training complete.\n",
      "Starting Round 752\n",
      "Epoch [100/2000], Loss: 0.3223, Val Loss: 0.3223\n",
      "Epoch [200/2000], Loss: 0.2902, Val Loss: 0.2902\n",
      "Early stopping at epoch 253\n",
      "Training complete.\n",
      "Starting Round 753\n",
      "Epoch [100/2000], Loss: 0.2509, Val Loss: 0.2509\n",
      "Epoch [200/2000], Loss: 0.2430, Val Loss: 0.2430\n",
      "Early stopping at epoch 294\n",
      "Training complete.\n",
      "Starting Round 754\n",
      "Epoch [100/2000], Loss: 0.2514, Val Loss: 0.2514\n",
      "Epoch [200/2000], Loss: 0.2682, Val Loss: 0.2682\n",
      "Early stopping at epoch 241\n",
      "Training complete.\n",
      "Starting Round 755\n",
      "Epoch [100/2000], Loss: 0.2625, Val Loss: 0.2625\n",
      "Epoch [200/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Early stopping at epoch 253\n",
      "Training complete.\n",
      "Starting Round 756\n",
      "Epoch [100/2000], Loss: 0.2193, Val Loss: 0.2193\n",
      "Epoch [200/2000], Loss: 0.2167, Val Loss: 0.2167\n",
      "Early stopping at epoch 236\n",
      "Training complete.\n",
      "Starting Round 757\n",
      "Epoch [100/2000], Loss: 0.2850, Val Loss: 0.2850\n",
      "Epoch [200/2000], Loss: 0.2963, Val Loss: 0.2963\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 758\n",
      "Epoch [100/2000], Loss: 0.2595, Val Loss: 0.2595\n",
      "Early stopping at epoch 152\n",
      "Training complete.\n",
      "Starting Round 759\n",
      "Epoch [100/2000], Loss: 0.3007, Val Loss: 0.3007\n",
      "Epoch [200/2000], Loss: 0.3067, Val Loss: 0.3067\n",
      "Early stopping at epoch 252\n",
      "Training complete.\n",
      "Starting Round 760\n",
      "Epoch [100/2000], Loss: 0.2619, Val Loss: 0.2619\n",
      "Epoch [200/2000], Loss: 0.2522, Val Loss: 0.2522\n",
      "Early stopping at epoch 214\n",
      "Training complete.\n",
      "Starting Round 761\n",
      "Epoch [100/2000], Loss: 0.2999, Val Loss: 0.2999\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 762\n",
      "Epoch [100/2000], Loss: 0.2694, Val Loss: 0.2694\n",
      "Early stopping at epoch 162\n",
      "Training complete.\n",
      "Starting Round 763\n",
      "Epoch [100/2000], Loss: 0.2726, Val Loss: 0.2726\n",
      "Early stopping at epoch 160\n",
      "Training complete.\n",
      "Starting Round 764\n",
      "Epoch [100/2000], Loss: 0.2578, Val Loss: 0.2578\n",
      "Epoch [200/2000], Loss: 0.2546, Val Loss: 0.2546\n",
      "Epoch [300/2000], Loss: 0.2624, Val Loss: 0.2624\n",
      "Early stopping at epoch 323\n",
      "Training complete.\n",
      "Starting Round 765\n",
      "Epoch [100/2000], Loss: 0.2576, Val Loss: 0.2576\n",
      "Epoch [200/2000], Loss: 0.2577, Val Loss: 0.2577\n",
      "Epoch [300/2000], Loss: 0.2430, Val Loss: 0.2430\n",
      "Early stopping at epoch 400\n",
      "Training complete.\n",
      "Starting Round 766\n",
      "Epoch [100/2000], Loss: 0.2301, Val Loss: 0.2301\n",
      "Early stopping at epoch 161\n",
      "Training complete.\n",
      "Starting Round 767\n",
      "Epoch [100/2000], Loss: 0.2531, Val Loss: 0.2531\n",
      "Epoch [200/2000], Loss: 0.2539, Val Loss: 0.2539\n",
      "Epoch 00267: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Epoch [300/2000], Loss: 0.2499, Val Loss: 0.2499\n",
      "Early stopping at epoch 376\n",
      "Training complete.\n",
      "Starting Round 768\n",
      "Epoch [100/2000], Loss: 0.2316, Val Loss: 0.2316\n",
      "Epoch [200/2000], Loss: 0.2257, Val Loss: 0.2257\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 769\n",
      "Epoch [100/2000], Loss: 0.2820, Val Loss: 0.2820\n",
      "Epoch [200/2000], Loss: 0.2796, Val Loss: 0.2796\n",
      "Early stopping at epoch 231\n",
      "Training complete.\n",
      "Starting Round 770\n",
      "Epoch [100/2000], Loss: 0.2643, Val Loss: 0.2643\n",
      "Epoch [200/2000], Loss: 0.2643, Val Loss: 0.2643\n",
      "Early stopping at epoch 248\n",
      "Training complete.\n",
      "Starting Round 771\n",
      "Epoch [100/2000], Loss: 0.2399, Val Loss: 0.2399\n",
      "Epoch [200/2000], Loss: 0.2186, Val Loss: 0.2186\n",
      "Early stopping at epoch 284\n",
      "Training complete.\n",
      "Starting Round 772\n",
      "Epoch [100/2000], Loss: 0.2369, Val Loss: 0.2369\n",
      "Early stopping at epoch 175\n",
      "Training complete.\n",
      "Starting Round 773\n",
      "Epoch [100/2000], Loss: 0.2732, Val Loss: 0.2732\n",
      "Early stopping at epoch 172\n",
      "Training complete.\n",
      "Starting Round 774\n",
      "Epoch [100/2000], Loss: 0.2465, Val Loss: 0.2465\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 775\n",
      "Epoch [100/2000], Loss: 0.2591, Val Loss: 0.2591\n",
      "Epoch [200/2000], Loss: 0.2423, Val Loss: 0.2423\n",
      "Epoch [300/2000], Loss: 0.2579, Val Loss: 0.2579\n",
      "Early stopping at epoch 306\n",
      "Training complete.\n",
      "Starting Round 776\n",
      "Epoch [100/2000], Loss: 0.2679, Val Loss: 0.2679\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 777\n",
      "Epoch [100/2000], Loss: 0.2633, Val Loss: 0.2633\n",
      "Epoch [200/2000], Loss: 0.2629, Val Loss: 0.2629\n",
      "Epoch [300/2000], Loss: 0.2750, Val Loss: 0.2750\n",
      "Early stopping at epoch 331\n",
      "Training complete.\n",
      "Starting Round 778\n",
      "Epoch [100/2000], Loss: 0.2790, Val Loss: 0.2790\n",
      "Early stopping at epoch 188\n",
      "Training complete.\n",
      "Starting Round 779\n",
      "Epoch [100/2000], Loss: 0.2761, Val Loss: 0.2761\n",
      "Epoch [200/2000], Loss: 0.2780, Val Loss: 0.2780\n",
      "Epoch [300/2000], Loss: 0.2778, Val Loss: 0.2778\n",
      "Early stopping at epoch 309\n",
      "Training complete.\n",
      "Starting Round 780\n",
      "Epoch [100/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Epoch [200/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Epoch [300/2000], Loss: 0.2667, Val Loss: 0.2667\n",
      "Epoch [400/2000], Loss: 0.2533, Val Loss: 0.2533\n",
      "Early stopping at epoch 476\n",
      "Training complete.\n",
      "Starting Round 781\n",
      "Epoch [100/2000], Loss: 0.2295, Val Loss: 0.2295\n",
      "Epoch [200/2000], Loss: 0.2167, Val Loss: 0.2167\n",
      "Epoch [300/2000], Loss: 0.2206, Val Loss: 0.2206\n",
      "Early stopping at epoch 309\n",
      "Training complete.\n",
      "Starting Round 782\n",
      "Epoch [100/2000], Loss: 0.2330, Val Loss: 0.2330\n",
      "Epoch [200/2000], Loss: 0.2418, Val Loss: 0.2418\n",
      "Early stopping at epoch 272\n",
      "Training complete.\n",
      "Starting Round 783\n",
      "Epoch [100/2000], Loss: 0.2332, Val Loss: 0.2332\n",
      "Epoch [200/2000], Loss: 0.2327, Val Loss: 0.2327\n",
      "Epoch [300/2000], Loss: 0.2302, Val Loss: 0.2302\n",
      "Epoch [400/2000], Loss: 0.2171, Val Loss: 0.2171\n",
      "Epoch [500/2000], Loss: 0.2163, Val Loss: 0.2163\n",
      "Epoch [600/2000], Loss: 0.2155, Val Loss: 0.2155\n",
      "Early stopping at epoch 672\n",
      "Training complete.\n",
      "Starting Round 784\n",
      "Epoch [100/2000], Loss: 0.2715, Val Loss: 0.2715\n",
      "Epoch [200/2000], Loss: 0.2603, Val Loss: 0.2603\n",
      "Early stopping at epoch 295\n",
      "Training complete.\n",
      "Starting Round 785\n",
      "Epoch [100/2000], Loss: 0.2500, Val Loss: 0.2500\n",
      "Epoch [200/2000], Loss: 0.2542, Val Loss: 0.2542\n",
      "Early stopping at epoch 233\n",
      "Training complete.\n",
      "Starting Round 786\n",
      "Epoch [100/2000], Loss: 0.2463, Val Loss: 0.2463\n",
      "Early stopping at epoch 173\n",
      "Training complete.\n",
      "Starting Round 787\n",
      "Epoch [100/2000], Loss: 0.2574, Val Loss: 0.2574\n",
      "Epoch [200/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Early stopping at epoch 285\n",
      "Training complete.\n",
      "Starting Round 788\n",
      "Epoch [100/2000], Loss: 0.2829, Val Loss: 0.2829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/2000], Loss: 0.2816, Val Loss: 0.2816\n",
      "Epoch [300/2000], Loss: 0.2657, Val Loss: 0.2657\n",
      "Epoch [400/2000], Loss: 0.2562, Val Loss: 0.2562\n",
      "Early stopping at epoch 424\n",
      "Training complete.\n",
      "Starting Round 789\n",
      "Epoch [100/2000], Loss: 0.2807, Val Loss: 0.2807\n",
      "Epoch [200/2000], Loss: 0.2652, Val Loss: 0.2652\n",
      "Early stopping at epoch 278\n",
      "Training complete.\n",
      "Starting Round 790\n",
      "Epoch [100/2000], Loss: 0.2357, Val Loss: 0.2357\n",
      "Early stopping at epoch 148\n",
      "Training complete.\n",
      "Starting Round 791\n",
      "Epoch [100/2000], Loss: 0.2824, Val Loss: 0.2824\n",
      "Epoch [200/2000], Loss: 0.2810, Val Loss: 0.2810\n",
      "Epoch [300/2000], Loss: 0.2761, Val Loss: 0.2761\n",
      "Epoch [400/2000], Loss: 0.2835, Val Loss: 0.2835\n",
      "Early stopping at epoch 458\n",
      "Training complete.\n",
      "Starting Round 792\n",
      "Epoch [100/2000], Loss: 0.2707, Val Loss: 0.2707\n",
      "Epoch [200/2000], Loss: 0.2703, Val Loss: 0.2703\n",
      "Early stopping at epoch 250\n",
      "Training complete.\n",
      "Starting Round 793\n",
      "Epoch [100/2000], Loss: 0.2767, Val Loss: 0.2767\n",
      "Epoch [200/2000], Loss: 0.2603, Val Loss: 0.2603\n",
      "Early stopping at epoch 242\n",
      "Training complete.\n",
      "Starting Round 794\n",
      "Epoch [100/2000], Loss: 0.2393, Val Loss: 0.2393\n",
      "Early stopping at epoch 182\n",
      "Training complete.\n",
      "Starting Round 795\n",
      "Epoch [100/2000], Loss: 0.2713, Val Loss: 0.2713\n",
      "Epoch [200/2000], Loss: 0.2655, Val Loss: 0.2655\n",
      "Epoch [300/2000], Loss: 0.2668, Val Loss: 0.2668\n",
      "Epoch [400/2000], Loss: 0.2732, Val Loss: 0.2732\n",
      "Early stopping at epoch 410\n",
      "Training complete.\n",
      "Starting Round 796\n",
      "Epoch [100/2000], Loss: 0.2831, Val Loss: 0.2831\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 797\n",
      "Epoch [100/2000], Loss: 0.3069, Val Loss: 0.3069\n",
      "Epoch [200/2000], Loss: 0.2931, Val Loss: 0.2931\n",
      "Early stopping at epoch 204\n",
      "Training complete.\n",
      "Starting Round 798\n",
      "Epoch [100/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Epoch [200/2000], Loss: 0.2281, Val Loss: 0.2281\n",
      "Early stopping at epoch 265\n",
      "Training complete.\n",
      "Starting Round 799\n",
      "Epoch [100/2000], Loss: 0.2686, Val Loss: 0.2686\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 800\n",
      "Epoch [100/2000], Loss: 0.2582, Val Loss: 0.2582\n",
      "Epoch [200/2000], Loss: 0.2516, Val Loss: 0.2516\n",
      "Epoch [300/2000], Loss: 0.2486, Val Loss: 0.2486\n",
      "Epoch [400/2000], Loss: 0.2485, Val Loss: 0.2485\n",
      "Early stopping at epoch 401\n",
      "Training complete.\n",
      "Starting Round 801\n",
      "Epoch [100/2000], Loss: 0.2796, Val Loss: 0.2796\n",
      "Epoch [200/2000], Loss: 0.2723, Val Loss: 0.2723\n",
      "Early stopping at epoch 261\n",
      "Training complete.\n",
      "Starting Round 802\n",
      "Epoch [100/2000], Loss: 0.2394, Val Loss: 0.2394\n",
      "Early stopping at epoch 142\n",
      "Training complete.\n",
      "Starting Round 803\n",
      "Epoch [100/2000], Loss: 0.2264, Val Loss: 0.2264\n",
      "Epoch [200/2000], Loss: 0.2332, Val Loss: 0.2332\n",
      "Epoch [300/2000], Loss: 0.2312, Val Loss: 0.2312\n",
      "Epoch [400/2000], Loss: 0.2287, Val Loss: 0.2287\n",
      "Early stopping at epoch 408\n",
      "Training complete.\n",
      "Starting Round 804\n",
      "Epoch [100/2000], Loss: 0.2714, Val Loss: 0.2714\n",
      "Epoch [200/2000], Loss: 0.2780, Val Loss: 0.2780\n",
      "Early stopping at epoch 254\n",
      "Training complete.\n",
      "Starting Round 805\n",
      "Epoch [100/2000], Loss: 0.2697, Val Loss: 0.2697\n",
      "Epoch [200/2000], Loss: 0.2584, Val Loss: 0.2584\n",
      "Early stopping at epoch 241\n",
      "Training complete.\n",
      "Starting Round 806\n",
      "Epoch [100/2000], Loss: 0.2848, Val Loss: 0.2848\n",
      "Epoch [200/2000], Loss: 0.2758, Val Loss: 0.2758\n",
      "Early stopping at epoch 259\n",
      "Training complete.\n",
      "Starting Round 807\n",
      "Epoch [100/2000], Loss: 0.2329, Val Loss: 0.2329\n",
      "Epoch [200/2000], Loss: 0.2311, Val Loss: 0.2311\n",
      "Epoch [300/2000], Loss: 0.2258, Val Loss: 0.2258\n",
      "Epoch [400/2000], Loss: 0.2203, Val Loss: 0.2203\n",
      "Epoch [500/2000], Loss: 0.2362, Val Loss: 0.2362\n",
      "Early stopping at epoch 578\n",
      "Training complete.\n",
      "Starting Round 808\n",
      "Epoch [100/2000], Loss: 0.3344, Val Loss: 0.3344\n",
      "Epoch [200/2000], Loss: 0.3315, Val Loss: 0.3315\n",
      "Epoch [300/2000], Loss: 0.3176, Val Loss: 0.3176\n",
      "Early stopping at epoch 383\n",
      "Training complete.\n",
      "Starting Round 809\n",
      "Epoch [100/2000], Loss: 0.2842, Val Loss: 0.2842\n",
      "Epoch [200/2000], Loss: 0.2774, Val Loss: 0.2774\n",
      "Epoch [300/2000], Loss: 0.2806, Val Loss: 0.2806\n",
      "Early stopping at epoch 355\n",
      "Training complete.\n",
      "Starting Round 810\n",
      "Epoch [100/2000], Loss: 0.2930, Val Loss: 0.2930\n",
      "Epoch [200/2000], Loss: 0.2785, Val Loss: 0.2785\n",
      "Early stopping at epoch 276\n",
      "Training complete.\n",
      "Starting Round 811\n",
      "Epoch [100/2000], Loss: 0.2708, Val Loss: 0.2708\n",
      "Epoch [200/2000], Loss: 0.2888, Val Loss: 0.2888\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 812\n",
      "Epoch [100/2000], Loss: 0.2675, Val Loss: 0.2675\n",
      "Epoch [200/2000], Loss: 0.2593, Val Loss: 0.2593\n",
      "Early stopping at epoch 223\n",
      "Training complete.\n",
      "Starting Round 813\n",
      "Epoch [100/2000], Loss: 0.2507, Val Loss: 0.2507\n",
      "Epoch [200/2000], Loss: 0.2566, Val Loss: 0.2566\n",
      "Early stopping at epoch 222\n",
      "Training complete.\n",
      "Starting Round 814\n",
      "Epoch [100/2000], Loss: 0.2722, Val Loss: 0.2722\n",
      "Epoch [200/2000], Loss: 0.2627, Val Loss: 0.2627\n",
      "Epoch [300/2000], Loss: 0.2570, Val Loss: 0.2570\n",
      "Early stopping at epoch 321\n",
      "Training complete.\n",
      "Starting Round 815\n",
      "Epoch [100/2000], Loss: 0.2419, Val Loss: 0.2419\n",
      "Early stopping at epoch 158\n",
      "Training complete.\n",
      "Starting Round 816\n",
      "Epoch [100/2000], Loss: 0.1974, Val Loss: 0.1974\n",
      "Early stopping at epoch 196\n",
      "Training complete.\n",
      "Starting Round 817\n",
      "Epoch [100/2000], Loss: 0.2443, Val Loss: 0.2443\n",
      "Epoch [200/2000], Loss: 0.2626, Val Loss: 0.2626\n",
      "Early stopping at epoch 272\n",
      "Training complete.\n",
      "Starting Round 818\n",
      "Epoch [100/2000], Loss: 0.2546, Val Loss: 0.2546\n",
      "Epoch [200/2000], Loss: 0.2558, Val Loss: 0.2558\n",
      "Early stopping at epoch 212\n",
      "Training complete.\n",
      "Starting Round 819\n",
      "Epoch [100/2000], Loss: 0.2449, Val Loss: 0.2449\n",
      "Epoch [200/2000], Loss: 0.2508, Val Loss: 0.2508\n",
      "Early stopping at epoch 277\n",
      "Training complete.\n",
      "Starting Round 820\n",
      "Epoch [100/2000], Loss: 0.2542, Val Loss: 0.2542\n",
      "Epoch [200/2000], Loss: 0.2489, Val Loss: 0.2489\n",
      "Epoch [300/2000], Loss: 0.2503, Val Loss: 0.2503\n",
      "Epoch [400/2000], Loss: 0.2534, Val Loss: 0.2534\n",
      "Early stopping at epoch 408\n",
      "Training complete.\n",
      "Starting Round 821\n",
      "Epoch [100/2000], Loss: 0.2266, Val Loss: 0.2266\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 822\n",
      "Epoch [100/2000], Loss: 0.2747, Val Loss: 0.2747\n",
      "Early stopping at epoch 189\n",
      "Training complete.\n",
      "Starting Round 823\n",
      "Epoch [100/2000], Loss: 0.2914, Val Loss: 0.2914\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 824\n",
      "Epoch [100/2000], Loss: 0.2362, Val Loss: 0.2362\n",
      "Epoch [200/2000], Loss: 0.2379, Val Loss: 0.2379\n",
      "Early stopping at epoch 250\n",
      "Training complete.\n",
      "Starting Round 825\n",
      "Epoch [100/2000], Loss: 0.2639, Val Loss: 0.2639\n",
      "Early stopping at epoch 187\n",
      "Training complete.\n",
      "Starting Round 826\n",
      "Epoch [100/2000], Loss: 0.2743, Val Loss: 0.2743\n",
      "Epoch [200/2000], Loss: 0.2688, Val Loss: 0.2688\n",
      "Early stopping at epoch 241\n",
      "Training complete.\n",
      "Starting Round 827\n",
      "Epoch [100/2000], Loss: 0.3369, Val Loss: 0.3369\n",
      "Epoch [200/2000], Loss: 0.3112, Val Loss: 0.3112\n",
      "Epoch [300/2000], Loss: 0.3262, Val Loss: 0.3262\n",
      "Early stopping at epoch 343\n",
      "Training complete.\n",
      "Starting Round 828\n",
      "Epoch [100/2000], Loss: 0.2776, Val Loss: 0.2776\n",
      "Early stopping at epoch 165\n",
      "Training complete.\n",
      "Starting Round 829\n",
      "Epoch [100/2000], Loss: 0.2663, Val Loss: 0.2663\n",
      "Early stopping at epoch 144\n",
      "Training complete.\n",
      "Starting Round 830\n",
      "Epoch [100/2000], Loss: 0.2668, Val Loss: 0.2668\n",
      "Epoch [200/2000], Loss: 0.2739, Val Loss: 0.2739\n",
      "Early stopping at epoch 262\n",
      "Training complete.\n",
      "Starting Round 831\n",
      "Epoch [100/2000], Loss: 0.3069, Val Loss: 0.3069\n",
      "Early stopping at epoch 148\n",
      "Training complete.\n",
      "Starting Round 832\n",
      "Epoch [100/2000], Loss: 0.2706, Val Loss: 0.2706\n",
      "Early stopping at epoch 191\n",
      "Training complete.\n",
      "Starting Round 833\n",
      "Epoch [100/2000], Loss: 0.2580, Val Loss: 0.2580\n",
      "Early stopping at epoch 164\n",
      "Training complete.\n",
      "Starting Round 834\n",
      "Epoch [100/2000], Loss: 0.2668, Val Loss: 0.2668\n",
      "Epoch [200/2000], Loss: 0.2505, Val Loss: 0.2505\n",
      "Epoch [300/2000], Loss: 0.2426, Val Loss: 0.2426\n",
      "Epoch [400/2000], Loss: 0.2430, Val Loss: 0.2430\n",
      "Early stopping at epoch 429\n",
      "Training complete.\n",
      "Starting Round 835\n",
      "Epoch [100/2000], Loss: 0.2349, Val Loss: 0.2349\n",
      "Epoch [200/2000], Loss: 0.2111, Val Loss: 0.2111\n",
      "Epoch [300/2000], Loss: 0.2180, Val Loss: 0.2180\n",
      "Early stopping at epoch 347\n",
      "Training complete.\n",
      "Starting Round 836\n",
      "Epoch [100/2000], Loss: 0.2480, Val Loss: 0.2480\n",
      "Epoch [200/2000], Loss: 0.2412, Val Loss: 0.2412\n",
      "Early stopping at epoch 297\n",
      "Training complete.\n",
      "Starting Round 837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.2906, Val Loss: 0.2906\n",
      "Early stopping at epoch 155\n",
      "Training complete.\n",
      "Starting Round 838\n",
      "Epoch [100/2000], Loss: 0.2613, Val Loss: 0.2613\n",
      "Epoch [200/2000], Loss: 0.2564, Val Loss: 0.2564\n",
      "Epoch [300/2000], Loss: 0.2564, Val Loss: 0.2564\n",
      "Early stopping at epoch 325\n",
      "Training complete.\n",
      "Starting Round 839\n",
      "Epoch [100/2000], Loss: 0.2233, Val Loss: 0.2233\n",
      "Early stopping at epoch 194\n",
      "Training complete.\n",
      "Starting Round 840\n",
      "Epoch [100/2000], Loss: 0.2104, Val Loss: 0.2104\n",
      "Epoch [200/2000], Loss: 0.2110, Val Loss: 0.2110\n",
      "Epoch [300/2000], Loss: 0.2015, Val Loss: 0.2015\n",
      "Early stopping at epoch 351\n",
      "Training complete.\n",
      "Starting Round 841\n",
      "Epoch [100/2000], Loss: 0.2632, Val Loss: 0.2632\n",
      "Epoch [200/2000], Loss: 0.2573, Val Loss: 0.2573\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 842\n",
      "Epoch [100/2000], Loss: 0.3124, Val Loss: 0.3124\n",
      "Epoch [200/2000], Loss: 0.3105, Val Loss: 0.3105\n",
      "Epoch [300/2000], Loss: 0.3083, Val Loss: 0.3083\n",
      "Early stopping at epoch 340\n",
      "Training complete.\n",
      "Starting Round 843\n",
      "Epoch [100/2000], Loss: 0.2526, Val Loss: 0.2526\n",
      "Epoch [200/2000], Loss: 0.2458, Val Loss: 0.2458\n",
      "Epoch [300/2000], Loss: 0.2358, Val Loss: 0.2358\n",
      "Epoch [400/2000], Loss: 0.2377, Val Loss: 0.2377\n",
      "Early stopping at epoch 412\n",
      "Training complete.\n",
      "Starting Round 844\n",
      "Epoch [100/2000], Loss: 0.2773, Val Loss: 0.2773\n",
      "Early stopping at epoch 159\n",
      "Training complete.\n",
      "Starting Round 845\n",
      "Epoch [100/2000], Loss: 0.2807, Val Loss: 0.2807\n",
      "Epoch [200/2000], Loss: 0.2699, Val Loss: 0.2699\n",
      "Early stopping at epoch 296\n",
      "Training complete.\n",
      "Starting Round 846\n",
      "Epoch [100/2000], Loss: 0.3011, Val Loss: 0.3011\n",
      "Epoch [200/2000], Loss: 0.2719, Val Loss: 0.2719\n",
      "Epoch [300/2000], Loss: 0.2743, Val Loss: 0.2743\n",
      "Early stopping at epoch 353\n",
      "Training complete.\n",
      "Starting Round 847\n",
      "Epoch [100/2000], Loss: 0.2529, Val Loss: 0.2529\n",
      "Epoch [200/2000], Loss: 0.2464, Val Loss: 0.2464\n",
      "Epoch [300/2000], Loss: 0.2491, Val Loss: 0.2491\n",
      "Epoch [400/2000], Loss: 0.2478, Val Loss: 0.2478\n",
      "Early stopping at epoch 403\n",
      "Training complete.\n",
      "Starting Round 848\n",
      "Epoch [100/2000], Loss: 0.2517, Val Loss: 0.2517\n",
      "Epoch [200/2000], Loss: 0.2394, Val Loss: 0.2394\n",
      "Epoch [300/2000], Loss: 0.2367, Val Loss: 0.2367\n",
      "Early stopping at epoch 372\n",
      "Training complete.\n",
      "Starting Round 849\n",
      "Epoch [100/2000], Loss: 0.2380, Val Loss: 0.2380\n",
      "Epoch [200/2000], Loss: 0.2313, Val Loss: 0.2313\n",
      "Epoch [300/2000], Loss: 0.2294, Val Loss: 0.2294\n",
      "Early stopping at epoch 370\n",
      "Training complete.\n",
      "Starting Round 850\n",
      "Epoch [100/2000], Loss: 0.2955, Val Loss: 0.2955\n",
      "Early stopping at epoch 195\n",
      "Training complete.\n",
      "Starting Round 851\n",
      "Epoch [100/2000], Loss: 0.2628, Val Loss: 0.2628\n",
      "Early stopping at epoch 139\n",
      "Training complete.\n",
      "Starting Round 852\n",
      "Epoch [100/2000], Loss: 0.2601, Val Loss: 0.2601\n",
      "Early stopping at epoch 183\n",
      "Training complete.\n",
      "Starting Round 853\n",
      "Epoch [100/2000], Loss: 0.2369, Val Loss: 0.2369\n",
      "Epoch [200/2000], Loss: 0.2478, Val Loss: 0.2478\n",
      "Epoch [300/2000], Loss: 0.2303, Val Loss: 0.2303\n",
      "Early stopping at epoch 341\n",
      "Training complete.\n",
      "Starting Round 854\n",
      "Epoch [100/2000], Loss: 0.2650, Val Loss: 0.2650\n",
      "Epoch [200/2000], Loss: 0.2451, Val Loss: 0.2451\n",
      "Epoch [300/2000], Loss: 0.2365, Val Loss: 0.2365\n",
      "Early stopping at epoch 315\n",
      "Training complete.\n",
      "Starting Round 855\n",
      "Epoch [100/2000], Loss: 0.2468, Val Loss: 0.2468\n",
      "Early stopping at epoch 179\n",
      "Training complete.\n",
      "Starting Round 856\n",
      "Epoch [100/2000], Loss: 0.2498, Val Loss: 0.2498\n",
      "Epoch [200/2000], Loss: 0.2485, Val Loss: 0.2485\n",
      "Early stopping at epoch 295\n",
      "Training complete.\n",
      "Starting Round 857\n",
      "Epoch [100/2000], Loss: 0.2601, Val Loss: 0.2601\n",
      "Epoch [200/2000], Loss: 0.2680, Val Loss: 0.2680\n",
      "Epoch [300/2000], Loss: 0.2508, Val Loss: 0.2508\n",
      "Early stopping at epoch 333\n",
      "Training complete.\n",
      "Starting Round 858\n",
      "Epoch [100/2000], Loss: 0.2278, Val Loss: 0.2278\n",
      "Early stopping at epoch 182\n",
      "Training complete.\n",
      "Starting Round 859\n",
      "Epoch [100/2000], Loss: 0.2702, Val Loss: 0.2702\n",
      "Early stopping at epoch 152\n",
      "Training complete.\n",
      "Starting Round 860\n",
      "Epoch [100/2000], Loss: 0.2293, Val Loss: 0.2293\n",
      "Epoch [200/2000], Loss: 0.2245, Val Loss: 0.2245\n",
      "Epoch [300/2000], Loss: 0.2202, Val Loss: 0.2202\n",
      "Epoch [400/2000], Loss: 0.2210, Val Loss: 0.2210\n",
      "Epoch [500/2000], Loss: 0.2207, Val Loss: 0.2207\n",
      "Early stopping at epoch 537\n",
      "Training complete.\n",
      "Starting Round 861\n",
      "Epoch [100/2000], Loss: 0.3036, Val Loss: 0.3036\n",
      "Epoch [200/2000], Loss: 0.2888, Val Loss: 0.2888\n",
      "Epoch [300/2000], Loss: 0.2846, Val Loss: 0.2846\n",
      "Early stopping at epoch 349\n",
      "Training complete.\n",
      "Starting Round 862\n",
      "Epoch [100/2000], Loss: 0.2212, Val Loss: 0.2212\n",
      "Epoch [200/2000], Loss: 0.2229, Val Loss: 0.2229\n",
      "Early stopping at epoch 228\n",
      "Training complete.\n",
      "Starting Round 863\n",
      "Epoch [100/2000], Loss: 0.2535, Val Loss: 0.2535\n",
      "Epoch [200/2000], Loss: 0.2436, Val Loss: 0.2436\n",
      "Epoch [300/2000], Loss: 0.2595, Val Loss: 0.2595\n",
      "Epoch [400/2000], Loss: 0.2492, Val Loss: 0.2492\n",
      "Early stopping at epoch 445\n",
      "Training complete.\n",
      "Starting Round 864\n",
      "Epoch [100/2000], Loss: 0.2604, Val Loss: 0.2604\n",
      "Epoch [200/2000], Loss: 0.2551, Val Loss: 0.2551\n",
      "Early stopping at epoch 283\n",
      "Training complete.\n",
      "Starting Round 865\n",
      "Epoch [100/2000], Loss: 0.3031, Val Loss: 0.3031\n",
      "Epoch [200/2000], Loss: 0.2932, Val Loss: 0.2932\n",
      "Early stopping at epoch 241\n",
      "Training complete.\n",
      "Starting Round 866\n",
      "Epoch [100/2000], Loss: 0.2605, Val Loss: 0.2605\n",
      "Early stopping at epoch 178\n",
      "Training complete.\n",
      "Starting Round 867\n",
      "Epoch [100/2000], Loss: 0.2468, Val Loss: 0.2468\n",
      "Early stopping at epoch 160\n",
      "Training complete.\n",
      "Starting Round 868\n",
      "Epoch [100/2000], Loss: 0.2662, Val Loss: 0.2662\n",
      "Epoch [200/2000], Loss: 0.2635, Val Loss: 0.2635\n",
      "Epoch [300/2000], Loss: 0.2481, Val Loss: 0.2481\n",
      "Early stopping at epoch 325\n",
      "Training complete.\n",
      "Starting Round 869\n",
      "Epoch [100/2000], Loss: 0.2369, Val Loss: 0.2369\n",
      "Epoch [200/2000], Loss: 0.1981, Val Loss: 0.1981\n",
      "Epoch [300/2000], Loss: 0.2012, Val Loss: 0.2012\n",
      "Early stopping at epoch 315\n",
      "Training complete.\n",
      "Starting Round 870\n",
      "Epoch [100/2000], Loss: 0.2313, Val Loss: 0.2313\n",
      "Epoch [200/2000], Loss: 0.2317, Val Loss: 0.2317\n",
      "Epoch [300/2000], Loss: 0.2150, Val Loss: 0.2150\n",
      "Early stopping at epoch 400\n",
      "Training complete.\n",
      "Starting Round 871\n",
      "Epoch [100/2000], Loss: 0.2777, Val Loss: 0.2777\n",
      "Epoch [200/2000], Loss: 0.2869, Val Loss: 0.2869\n",
      "Epoch [300/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Epoch [400/2000], Loss: 0.2685, Val Loss: 0.2685\n",
      "Epoch [500/2000], Loss: 0.2532, Val Loss: 0.2532\n",
      "Early stopping at epoch 502\n",
      "Training complete.\n",
      "Starting Round 872\n",
      "Epoch [100/2000], Loss: 0.2778, Val Loss: 0.2778\n",
      "Epoch [200/2000], Loss: 0.2549, Val Loss: 0.2549\n",
      "Early stopping at epoch 268\n",
      "Training complete.\n",
      "Starting Round 873\n",
      "Epoch [100/2000], Loss: 0.2513, Val Loss: 0.2513\n",
      "Epoch [200/2000], Loss: 0.2473, Val Loss: 0.2473\n",
      "Early stopping at epoch 242\n",
      "Training complete.\n",
      "Starting Round 874\n",
      "Epoch [100/2000], Loss: 0.2646, Val Loss: 0.2646\n",
      "Epoch [200/2000], Loss: 0.2579, Val Loss: 0.2579\n",
      "Early stopping at epoch 246\n",
      "Training complete.\n",
      "Starting Round 875\n",
      "Epoch [100/2000], Loss: 0.2927, Val Loss: 0.2927\n",
      "Epoch [200/2000], Loss: 0.2948, Val Loss: 0.2948\n",
      "Early stopping at epoch 217\n",
      "Training complete.\n",
      "Starting Round 876\n",
      "Epoch [100/2000], Loss: 0.2597, Val Loss: 0.2597\n",
      "Epoch [200/2000], Loss: 0.2428, Val Loss: 0.2428\n",
      "Epoch [300/2000], Loss: 0.2452, Val Loss: 0.2452\n",
      "Early stopping at epoch 337\n",
      "Training complete.\n",
      "Starting Round 877\n",
      "Epoch [100/2000], Loss: 0.2388, Val Loss: 0.2388\n",
      "Early stopping at epoch 159\n",
      "Training complete.\n",
      "Starting Round 878\n",
      "Epoch [100/2000], Loss: 0.2234, Val Loss: 0.2234\n",
      "Early stopping at epoch 200\n",
      "Training complete.\n",
      "Starting Round 879\n",
      "Epoch [100/2000], Loss: 0.2512, Val Loss: 0.2512\n",
      "Epoch [200/2000], Loss: 0.2189, Val Loss: 0.2189\n",
      "Epoch [300/2000], Loss: 0.2268, Val Loss: 0.2268\n",
      "Early stopping at epoch 325\n",
      "Training complete.\n",
      "Starting Round 880\n",
      "Epoch [100/2000], Loss: 0.2435, Val Loss: 0.2435\n",
      "Epoch [200/2000], Loss: 0.2567, Val Loss: 0.2567\n",
      "Early stopping at epoch 207\n",
      "Training complete.\n",
      "Starting Round 881\n",
      "Epoch [100/2000], Loss: 0.2921, Val Loss: 0.2921\n",
      "Epoch [200/2000], Loss: 0.2751, Val Loss: 0.2751\n",
      "Early stopping at epoch 255\n",
      "Training complete.\n",
      "Starting Round 882\n",
      "Epoch [100/2000], Loss: 0.2376, Val Loss: 0.2376\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 883\n",
      "Epoch [100/2000], Loss: 0.2653, Val Loss: 0.2653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/2000], Loss: 0.2496, Val Loss: 0.2496\n",
      "Early stopping at epoch 240\n",
      "Training complete.\n",
      "Starting Round 884\n",
      "Epoch [100/2000], Loss: 0.3578, Val Loss: 0.3578\n",
      "Early stopping at epoch 163\n",
      "Training complete.\n",
      "Starting Round 885\n",
      "Epoch [100/2000], Loss: 0.2732, Val Loss: 0.2732\n",
      "Early stopping at epoch 166\n",
      "Training complete.\n",
      "Starting Round 886\n",
      "Epoch [100/2000], Loss: 0.2237, Val Loss: 0.2237\n",
      "Epoch [200/2000], Loss: 0.2130, Val Loss: 0.2130\n",
      "Epoch [300/2000], Loss: 0.2156, Val Loss: 0.2156\n",
      "Early stopping at epoch 341\n",
      "Training complete.\n",
      "Starting Round 887\n",
      "Epoch [100/2000], Loss: 0.2745, Val Loss: 0.2745\n",
      "Early stopping at epoch 177\n",
      "Training complete.\n",
      "Starting Round 888\n",
      "Epoch [100/2000], Loss: 0.2279, Val Loss: 0.2279\n",
      "Epoch [200/2000], Loss: 0.2254, Val Loss: 0.2254\n",
      "Early stopping at epoch 224\n",
      "Training complete.\n",
      "Starting Round 889\n",
      "Epoch [100/2000], Loss: 0.2785, Val Loss: 0.2785\n",
      "Early stopping at epoch 170\n",
      "Training complete.\n",
      "Starting Round 890\n",
      "Epoch [100/2000], Loss: 0.2937, Val Loss: 0.2937\n",
      "Early stopping at epoch 181\n",
      "Training complete.\n",
      "Starting Round 891\n",
      "Epoch [100/2000], Loss: 0.2841, Val Loss: 0.2841\n",
      "Epoch [200/2000], Loss: 0.2612, Val Loss: 0.2612\n",
      "Epoch [300/2000], Loss: 0.2712, Val Loss: 0.2712\n",
      "Early stopping at epoch 324\n",
      "Training complete.\n",
      "Starting Round 892\n",
      "Epoch [100/2000], Loss: 0.2429, Val Loss: 0.2429\n",
      "Epoch [200/2000], Loss: 0.2368, Val Loss: 0.2368\n",
      "Epoch [300/2000], Loss: 0.2318, Val Loss: 0.2318\n",
      "Early stopping at epoch 318\n",
      "Training complete.\n",
      "Starting Round 893\n",
      "Epoch [100/2000], Loss: 0.2920, Val Loss: 0.2920\n",
      "Epoch [200/2000], Loss: 0.2864, Val Loss: 0.2864\n",
      "Early stopping at epoch 253\n",
      "Training complete.\n",
      "Starting Round 894\n",
      "Epoch [100/2000], Loss: 0.2761, Val Loss: 0.2761\n",
      "Epoch [200/2000], Loss: 0.2746, Val Loss: 0.2746\n",
      "Early stopping at epoch 258\n",
      "Training complete.\n",
      "Starting Round 895\n",
      "Epoch [100/2000], Loss: 0.2731, Val Loss: 0.2731\n",
      "Epoch [200/2000], Loss: 0.2702, Val Loss: 0.2702\n",
      "Early stopping at epoch 276\n",
      "Training complete.\n",
      "Starting Round 896\n",
      "Epoch [100/2000], Loss: 0.2959, Val Loss: 0.2959\n",
      "Epoch [200/2000], Loss: 0.2939, Val Loss: 0.2939\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 897\n",
      "Epoch [100/2000], Loss: 0.2415, Val Loss: 0.2415\n",
      "Epoch [200/2000], Loss: 0.2382, Val Loss: 0.2382\n",
      "Epoch [300/2000], Loss: 0.2502, Val Loss: 0.2502\n",
      "Early stopping at epoch 303\n",
      "Training complete.\n",
      "Starting Round 898\n",
      "Epoch [100/2000], Loss: 0.2608, Val Loss: 0.2608\n",
      "Epoch [200/2000], Loss: 0.2607, Val Loss: 0.2607\n",
      "Early stopping at epoch 262\n",
      "Training complete.\n",
      "Starting Round 899\n",
      "Epoch [100/2000], Loss: 0.2573, Val Loss: 0.2573\n",
      "Epoch [200/2000], Loss: 0.2500, Val Loss: 0.2500\n",
      "Epoch [300/2000], Loss: 0.2412, Val Loss: 0.2412\n",
      "Early stopping at epoch 328\n",
      "Training complete.\n",
      "Starting Round 900\n",
      "Epoch [100/2000], Loss: 0.2892, Val Loss: 0.2892\n",
      "Epoch [200/2000], Loss: 0.2951, Val Loss: 0.2951\n",
      "Epoch [300/2000], Loss: 0.2903, Val Loss: 0.2903\n",
      "Early stopping at epoch 336\n",
      "Training complete.\n",
      "Starting Round 901\n",
      "Epoch [100/2000], Loss: 0.2564, Val Loss: 0.2564\n",
      "Epoch [200/2000], Loss: 0.2438, Val Loss: 0.2438\n",
      "Epoch [300/2000], Loss: 0.2534, Val Loss: 0.2534\n",
      "Early stopping at epoch 391\n",
      "Training complete.\n",
      "Starting Round 902\n",
      "Epoch [100/2000], Loss: 0.2478, Val Loss: 0.2478\n",
      "Epoch [200/2000], Loss: 0.2390, Val Loss: 0.2390\n",
      "Early stopping at epoch 244\n",
      "Training complete.\n",
      "Starting Round 903\n",
      "Epoch [100/2000], Loss: 0.2795, Val Loss: 0.2795\n",
      "Epoch [200/2000], Loss: 0.2744, Val Loss: 0.2744\n",
      "Early stopping at epoch 257\n",
      "Training complete.\n",
      "Starting Round 904\n",
      "Epoch [100/2000], Loss: 0.2856, Val Loss: 0.2856\n",
      "Epoch [200/2000], Loss: 0.2839, Val Loss: 0.2839\n",
      "Epoch [300/2000], Loss: 0.2754, Val Loss: 0.2754\n",
      "Early stopping at epoch 336\n",
      "Training complete.\n",
      "Starting Round 905\n",
      "Epoch [100/2000], Loss: 0.2127, Val Loss: 0.2127\n",
      "Epoch [200/2000], Loss: 0.2085, Val Loss: 0.2085\n",
      "Epoch [300/2000], Loss: 0.2096, Val Loss: 0.2096\n",
      "Early stopping at epoch 303\n",
      "Training complete.\n",
      "Starting Round 906\n",
      "Epoch [100/2000], Loss: 0.2387, Val Loss: 0.2387\n",
      "Epoch [200/2000], Loss: 0.2308, Val Loss: 0.2308\n",
      "Epoch [300/2000], Loss: 0.2249, Val Loss: 0.2249\n",
      "Early stopping at epoch 342\n",
      "Training complete.\n",
      "Starting Round 907\n",
      "Epoch [100/2000], Loss: 0.2883, Val Loss: 0.2883\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 908\n",
      "Epoch [100/2000], Loss: 0.2710, Val Loss: 0.2710\n",
      "Epoch [200/2000], Loss: 0.2837, Val Loss: 0.2837\n",
      "Early stopping at epoch 251\n",
      "Training complete.\n",
      "Starting Round 909\n",
      "Epoch [100/2000], Loss: 0.2698, Val Loss: 0.2698\n",
      "Epoch [200/2000], Loss: 0.2695, Val Loss: 0.2695\n",
      "Early stopping at epoch 294\n",
      "Training complete.\n",
      "Starting Round 910\n",
      "Epoch [100/2000], Loss: 0.2667, Val Loss: 0.2667\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 911\n",
      "Epoch [100/2000], Loss: 0.2549, Val Loss: 0.2549\n",
      "Epoch [200/2000], Loss: 0.2711, Val Loss: 0.2711\n",
      "Early stopping at epoch 252\n",
      "Training complete.\n",
      "Starting Round 912\n",
      "Epoch [100/2000], Loss: 0.2873, Val Loss: 0.2873\n",
      "Epoch [200/2000], Loss: 0.2855, Val Loss: 0.2855\n",
      "Early stopping at epoch 214\n",
      "Training complete.\n",
      "Starting Round 913\n",
      "Epoch [100/2000], Loss: 0.2593, Val Loss: 0.2593\n",
      "Epoch [200/2000], Loss: 0.2478, Val Loss: 0.2478\n",
      "Early stopping at epoch 272\n",
      "Training complete.\n",
      "Starting Round 914\n",
      "Epoch [100/2000], Loss: 0.2532, Val Loss: 0.2532\n",
      "Epoch [200/2000], Loss: 0.2399, Val Loss: 0.2399\n",
      "Early stopping at epoch 231\n",
      "Training complete.\n",
      "Starting Round 915\n",
      "Epoch [100/2000], Loss: 0.2680, Val Loss: 0.2680\n",
      "Epoch [200/2000], Loss: 0.2596, Val Loss: 0.2596\n",
      "Early stopping at epoch 275\n",
      "Training complete.\n",
      "Starting Round 916\n",
      "Epoch [100/2000], Loss: 0.2184, Val Loss: 0.2184\n",
      "Early stopping at epoch 179\n",
      "Training complete.\n",
      "Starting Round 917\n",
      "Epoch [100/2000], Loss: 0.2821, Val Loss: 0.2821\n",
      "Epoch [200/2000], Loss: 0.2606, Val Loss: 0.2606\n",
      "Epoch [300/2000], Loss: 0.2725, Val Loss: 0.2725\n",
      "Early stopping at epoch 338\n",
      "Training complete.\n",
      "Starting Round 918\n",
      "Epoch [100/2000], Loss: 0.2959, Val Loss: 0.2959\n",
      "Epoch [200/2000], Loss: 0.2959, Val Loss: 0.2959\n",
      "Early stopping at epoch 224\n",
      "Training complete.\n",
      "Starting Round 919\n",
      "Epoch [100/2000], Loss: 0.2527, Val Loss: 0.2527\n",
      "Epoch [200/2000], Loss: 0.2464, Val Loss: 0.2464\n",
      "Epoch [300/2000], Loss: 0.2510, Val Loss: 0.2510\n",
      "Early stopping at epoch 317\n",
      "Training complete.\n",
      "Starting Round 920\n",
      "Epoch [100/2000], Loss: 0.2810, Val Loss: 0.2810\n",
      "Epoch [200/2000], Loss: 0.2936, Val Loss: 0.2936\n",
      "Early stopping at epoch 230\n",
      "Training complete.\n",
      "Starting Round 921\n",
      "Epoch [100/2000], Loss: 0.2653, Val Loss: 0.2653\n",
      "Epoch [200/2000], Loss: 0.2550, Val Loss: 0.2550\n",
      "Early stopping at epoch 267\n",
      "Training complete.\n",
      "Starting Round 922\n",
      "Epoch [100/2000], Loss: 0.2527, Val Loss: 0.2527\n",
      "Early stopping at epoch 148\n",
      "Training complete.\n",
      "Starting Round 923\n",
      "Epoch [100/2000], Loss: 0.2012, Val Loss: 0.2012\n",
      "Epoch [200/2000], Loss: 0.1972, Val Loss: 0.1972\n",
      "Epoch [300/2000], Loss: 0.2015, Val Loss: 0.2015\n",
      "Early stopping at epoch 332\n",
      "Training complete.\n",
      "Starting Round 924\n",
      "Epoch [100/2000], Loss: 0.2871, Val Loss: 0.2871\n",
      "Early stopping at epoch 193\n",
      "Training complete.\n",
      "Starting Round 925\n",
      "Epoch [100/2000], Loss: 0.2723, Val Loss: 0.2723\n",
      "Epoch [200/2000], Loss: 0.2767, Val Loss: 0.2767\n",
      "Early stopping at epoch 211\n",
      "Training complete.\n",
      "Starting Round 926\n",
      "Epoch [100/2000], Loss: 0.2936, Val Loss: 0.2936\n",
      "Early stopping at epoch 174\n",
      "Training complete.\n",
      "Starting Round 927\n",
      "Epoch [100/2000], Loss: 0.2608, Val Loss: 0.2608\n",
      "Epoch [200/2000], Loss: 0.2667, Val Loss: 0.2667\n",
      "Epoch [300/2000], Loss: 0.2605, Val Loss: 0.2605\n",
      "Early stopping at epoch 321\n",
      "Training complete.\n",
      "Starting Round 928\n",
      "Epoch [100/2000], Loss: 0.2462, Val Loss: 0.2462\n",
      "Epoch [200/2000], Loss: 0.2347, Val Loss: 0.2347\n",
      "Epoch [300/2000], Loss: 0.2326, Val Loss: 0.2326\n",
      "Epoch [400/2000], Loss: 0.2398, Val Loss: 0.2398\n",
      "Early stopping at epoch 466\n",
      "Training complete.\n",
      "Starting Round 929\n",
      "Epoch [100/2000], Loss: 0.2577, Val Loss: 0.2577\n",
      "Epoch [200/2000], Loss: 0.2406, Val Loss: 0.2406\n",
      "Early stopping at epoch 278\n",
      "Training complete.\n",
      "Starting Round 930\n",
      "Epoch [100/2000], Loss: 0.2661, Val Loss: 0.2661\n",
      "Early stopping at epoch 194\n",
      "Training complete.\n",
      "Starting Round 931\n",
      "Epoch [100/2000], Loss: 0.2502, Val Loss: 0.2502\n",
      "Early stopping at epoch 151\n",
      "Training complete.\n",
      "Starting Round 932\n",
      "Epoch [100/2000], Loss: 0.2396, Val Loss: 0.2396\n",
      "Epoch [200/2000], Loss: 0.2307, Val Loss: 0.2307\n",
      "Epoch [300/2000], Loss: 0.2381, Val Loss: 0.2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 388\n",
      "Training complete.\n",
      "Starting Round 933\n",
      "Epoch [100/2000], Loss: 0.2860, Val Loss: 0.2860\n",
      "Epoch [200/2000], Loss: 0.2766, Val Loss: 0.2766\n",
      "Early stopping at epoch 221\n",
      "Training complete.\n",
      "Starting Round 934\n",
      "Epoch [100/2000], Loss: 0.2790, Val Loss: 0.2790\n",
      "Epoch [200/2000], Loss: 0.2893, Val Loss: 0.2893\n",
      "Early stopping at epoch 203\n",
      "Training complete.\n",
      "Starting Round 935\n",
      "Epoch [100/2000], Loss: 0.2740, Val Loss: 0.2740\n",
      "Epoch [200/2000], Loss: 0.2741, Val Loss: 0.2741\n",
      "Epoch [300/2000], Loss: 0.2579, Val Loss: 0.2579\n",
      "Early stopping at epoch 392\n",
      "Training complete.\n",
      "Starting Round 936\n",
      "Epoch [100/2000], Loss: 0.2737, Val Loss: 0.2737\n",
      "Early stopping at epoch 194\n",
      "Training complete.\n",
      "Starting Round 937\n",
      "Epoch [100/2000], Loss: 0.2313, Val Loss: 0.2313\n",
      "Epoch [200/2000], Loss: 0.2267, Val Loss: 0.2267\n",
      "Early stopping at epoch 270\n",
      "Training complete.\n",
      "Starting Round 938\n",
      "Epoch [100/2000], Loss: 0.2953, Val Loss: 0.2953\n",
      "Early stopping at epoch 178\n",
      "Training complete.\n",
      "Starting Round 939\n",
      "Epoch [100/2000], Loss: 0.2634, Val Loss: 0.2634\n",
      "Epoch [200/2000], Loss: 0.2451, Val Loss: 0.2451\n",
      "Epoch [300/2000], Loss: 0.2450, Val Loss: 0.2450\n",
      "Early stopping at epoch 348\n",
      "Training complete.\n",
      "Starting Round 940\n",
      "Epoch [100/2000], Loss: 0.2886, Val Loss: 0.2886\n",
      "Epoch [200/2000], Loss: 0.2986, Val Loss: 0.2986\n",
      "Epoch [300/2000], Loss: 0.2859, Val Loss: 0.2859\n",
      "Epoch [400/2000], Loss: 0.2867, Val Loss: 0.2867\n",
      "Early stopping at epoch 412\n",
      "Training complete.\n",
      "Starting Round 941\n",
      "Epoch [100/2000], Loss: 0.2440, Val Loss: 0.2440\n",
      "Epoch [200/2000], Loss: 0.2419, Val Loss: 0.2419\n",
      "Early stopping at epoch 265\n",
      "Training complete.\n",
      "Starting Round 942\n",
      "Epoch [100/2000], Loss: 0.2661, Val Loss: 0.2661\n",
      "Epoch [200/2000], Loss: 0.2585, Val Loss: 0.2585\n",
      "Epoch [300/2000], Loss: 0.2728, Val Loss: 0.2728\n",
      "Epoch [400/2000], Loss: 0.2594, Val Loss: 0.2594\n",
      "Early stopping at epoch 484\n",
      "Training complete.\n",
      "Starting Round 943\n",
      "Epoch [100/2000], Loss: 0.2654, Val Loss: 0.2654\n",
      "Epoch [200/2000], Loss: 0.2768, Val Loss: 0.2768\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 944\n",
      "Epoch [100/2000], Loss: 0.2560, Val Loss: 0.2560\n",
      "Early stopping at epoch 192\n",
      "Training complete.\n",
      "Starting Round 945\n",
      "Epoch [100/2000], Loss: 0.2523, Val Loss: 0.2523\n",
      "Epoch [200/2000], Loss: 0.2400, Val Loss: 0.2400\n",
      "Early stopping at epoch 204\n",
      "Training complete.\n",
      "Starting Round 946\n",
      "Epoch [100/2000], Loss: 0.2248, Val Loss: 0.2248\n",
      "Epoch [200/2000], Loss: 0.2062, Val Loss: 0.2062\n",
      "Epoch [300/2000], Loss: 0.2048, Val Loss: 0.2048\n",
      "Early stopping at epoch 319\n",
      "Training complete.\n",
      "Starting Round 947\n",
      "Epoch [100/2000], Loss: 0.2569, Val Loss: 0.2569\n",
      "Epoch [200/2000], Loss: 0.2401, Val Loss: 0.2401\n",
      "Early stopping at epoch 265\n",
      "Training complete.\n",
      "Starting Round 948\n",
      "Epoch [100/2000], Loss: 0.2955, Val Loss: 0.2955\n",
      "Epoch [200/2000], Loss: 0.2950, Val Loss: 0.2950\n",
      "Early stopping at epoch 288\n",
      "Training complete.\n",
      "Starting Round 949\n",
      "Epoch [100/2000], Loss: 0.2415, Val Loss: 0.2415\n",
      "Early stopping at epoch 179\n",
      "Training complete.\n",
      "Starting Round 950\n",
      "Epoch [100/2000], Loss: 0.2564, Val Loss: 0.2564\n",
      "Epoch [200/2000], Loss: 0.2595, Val Loss: 0.2595\n",
      "Early stopping at epoch 215\n",
      "Training complete.\n",
      "Starting Round 951\n",
      "Epoch [100/2000], Loss: 0.2756, Val Loss: 0.2756\n",
      "Epoch [200/2000], Loss: 0.2788, Val Loss: 0.2788\n",
      "Early stopping at epoch 266\n",
      "Training complete.\n",
      "Starting Round 952\n",
      "Epoch [100/2000], Loss: 0.2613, Val Loss: 0.2613\n",
      "Early stopping at epoch 176\n",
      "Training complete.\n",
      "Starting Round 953\n",
      "Epoch [100/2000], Loss: 0.2836, Val Loss: 0.2836\n",
      "Epoch [200/2000], Loss: 0.2981, Val Loss: 0.2981\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 954\n",
      "Epoch [100/2000], Loss: 0.2733, Val Loss: 0.2733\n",
      "Early stopping at epoch 172\n",
      "Training complete.\n",
      "Starting Round 955\n",
      "Epoch [100/2000], Loss: 0.2610, Val Loss: 0.2610\n",
      "Epoch [200/2000], Loss: 0.2533, Val Loss: 0.2533\n",
      "Epoch [300/2000], Loss: 0.2536, Val Loss: 0.2536\n",
      "Early stopping at epoch 351\n",
      "Training complete.\n",
      "Starting Round 956\n",
      "Epoch [100/2000], Loss: 0.2702, Val Loss: 0.2702\n",
      "Epoch [200/2000], Loss: 0.2541, Val Loss: 0.2541\n",
      "Early stopping at epoch 276\n",
      "Training complete.\n",
      "Starting Round 957\n",
      "Epoch [100/2000], Loss: 0.2268, Val Loss: 0.2268\n",
      "Early stopping at epoch 184\n",
      "Training complete.\n",
      "Starting Round 958\n",
      "Epoch [100/2000], Loss: 0.2592, Val Loss: 0.2592\n",
      "Epoch [200/2000], Loss: 0.2468, Val Loss: 0.2468\n",
      "Early stopping at epoch 250\n",
      "Training complete.\n",
      "Starting Round 959\n",
      "Epoch [100/2000], Loss: 0.2797, Val Loss: 0.2797\n",
      "Epoch [200/2000], Loss: 0.2728, Val Loss: 0.2728\n",
      "Early stopping at epoch 238\n",
      "Training complete.\n",
      "Starting Round 960\n",
      "Epoch [100/2000], Loss: 0.2601, Val Loss: 0.2601\n",
      "Early stopping at epoch 167\n",
      "Training complete.\n",
      "Starting Round 961\n",
      "Epoch [100/2000], Loss: 0.2444, Val Loss: 0.2444\n",
      "Epoch [200/2000], Loss: 0.2422, Val Loss: 0.2422\n",
      "Early stopping at epoch 270\n",
      "Training complete.\n",
      "Starting Round 962\n",
      "Epoch [100/2000], Loss: 0.2523, Val Loss: 0.2523\n",
      "Epoch [200/2000], Loss: 0.2511, Val Loss: 0.2511\n",
      "Epoch [300/2000], Loss: 0.2469, Val Loss: 0.2469\n",
      "Early stopping at epoch 362\n",
      "Training complete.\n",
      "Starting Round 963\n",
      "Epoch [100/2000], Loss: 0.2676, Val Loss: 0.2676\n",
      "Early stopping at epoch 185\n",
      "Training complete.\n",
      "Starting Round 964\n",
      "Epoch [100/2000], Loss: 0.2539, Val Loss: 0.2539\n",
      "Epoch [200/2000], Loss: 0.2640, Val Loss: 0.2640\n",
      "Early stopping at epoch 231\n",
      "Training complete.\n",
      "Starting Round 965\n",
      "Epoch [100/2000], Loss: 0.2509, Val Loss: 0.2509\n",
      "Early stopping at epoch 176\n",
      "Training complete.\n",
      "Starting Round 966\n",
      "Epoch [100/2000], Loss: 0.2713, Val Loss: 0.2713\n",
      "Epoch [200/2000], Loss: 0.2606, Val Loss: 0.2606\n",
      "Epoch [300/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Epoch [400/2000], Loss: 0.2575, Val Loss: 0.2575\n",
      "Epoch [500/2000], Loss: 0.2628, Val Loss: 0.2628\n",
      "Early stopping at epoch 540\n",
      "Training complete.\n",
      "Starting Round 967\n",
      "Epoch [100/2000], Loss: 0.2615, Val Loss: 0.2615\n",
      "Epoch [200/2000], Loss: 0.2665, Val Loss: 0.2665\n",
      "Epoch [300/2000], Loss: 0.2515, Val Loss: 0.2515\n",
      "Epoch [400/2000], Loss: 0.2514, Val Loss: 0.2514\n",
      "Early stopping at epoch 452\n",
      "Training complete.\n",
      "Starting Round 968\n",
      "Epoch [100/2000], Loss: 0.2562, Val Loss: 0.2562\n",
      "Epoch [200/2000], Loss: 0.2486, Val Loss: 0.2486\n",
      "Early stopping at epoch 211\n",
      "Training complete.\n",
      "Starting Round 969\n",
      "Epoch [100/2000], Loss: 0.2390, Val Loss: 0.2390\n",
      "Epoch [200/2000], Loss: 0.2364, Val Loss: 0.2364\n",
      "Epoch [300/2000], Loss: 0.2473, Val Loss: 0.2473\n",
      "Early stopping at epoch 324\n",
      "Training complete.\n",
      "Starting Round 970\n",
      "Epoch [100/2000], Loss: 0.2763, Val Loss: 0.2763\n",
      "Epoch [200/2000], Loss: 0.2847, Val Loss: 0.2847\n",
      "Early stopping at epoch 242\n",
      "Training complete.\n",
      "Starting Round 971\n",
      "Epoch [100/2000], Loss: 0.2533, Val Loss: 0.2533\n",
      "Epoch [200/2000], Loss: 0.2564, Val Loss: 0.2564\n",
      "Epoch [300/2000], Loss: 0.2382, Val Loss: 0.2382\n",
      "Epoch [400/2000], Loss: 0.2542, Val Loss: 0.2542\n",
      "Early stopping at epoch 495\n",
      "Training complete.\n",
      "Starting Round 972\n",
      "Epoch [100/2000], Loss: 0.2672, Val Loss: 0.2672\n",
      "Epoch [200/2000], Loss: 0.2707, Val Loss: 0.2707\n",
      "Early stopping at epoch 204\n",
      "Training complete.\n",
      "Starting Round 973\n",
      "Epoch [100/2000], Loss: 0.2445, Val Loss: 0.2445\n",
      "Epoch [200/2000], Loss: 0.2521, Val Loss: 0.2521\n",
      "Early stopping at epoch 227\n",
      "Training complete.\n",
      "Starting Round 974\n",
      "Epoch [100/2000], Loss: 0.2553, Val Loss: 0.2553\n",
      "Epoch [200/2000], Loss: 0.2594, Val Loss: 0.2594\n",
      "Early stopping at epoch 243\n",
      "Training complete.\n",
      "Starting Round 975\n",
      "Epoch [100/2000], Loss: 0.2465, Val Loss: 0.2465\n",
      "Epoch [200/2000], Loss: 0.2359, Val Loss: 0.2359\n",
      "Early stopping at epoch 269\n",
      "Training complete.\n",
      "Starting Round 976\n",
      "Epoch [100/2000], Loss: 0.2791, Val Loss: 0.2791\n",
      "Epoch [200/2000], Loss: 0.2759, Val Loss: 0.2759\n",
      "Early stopping at epoch 210\n",
      "Training complete.\n",
      "Starting Round 977\n",
      "Epoch [100/2000], Loss: 0.2283, Val Loss: 0.2283\n",
      "Epoch [200/2000], Loss: 0.2330, Val Loss: 0.2330\n",
      "Early stopping at epoch 221\n",
      "Training complete.\n",
      "Starting Round 978\n",
      "Epoch [100/2000], Loss: 0.2826, Val Loss: 0.2826\n",
      "Epoch [200/2000], Loss: 0.2813, Val Loss: 0.2813\n",
      "Epoch [300/2000], Loss: 0.2852, Val Loss: 0.2852\n",
      "Early stopping at epoch 397\n",
      "Training complete.\n",
      "Starting Round 979\n",
      "Epoch [100/2000], Loss: 0.2460, Val Loss: 0.2460\n",
      "Epoch [200/2000], Loss: 0.2361, Val Loss: 0.2361\n",
      "Early stopping at epoch 209\n",
      "Training complete.\n",
      "Starting Round 980\n",
      "Epoch [100/2000], Loss: 0.2392, Val Loss: 0.2392\n",
      "Early stopping at epoch 189\n",
      "Training complete.\n",
      "Starting Round 981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.3088, Val Loss: 0.3088\n",
      "Epoch [200/2000], Loss: 0.3009, Val Loss: 0.3009\n",
      "Early stopping at epoch 253\n",
      "Training complete.\n",
      "Starting Round 982\n",
      "Epoch [100/2000], Loss: 0.2880, Val Loss: 0.2880\n",
      "Early stopping at epoch 182\n",
      "Training complete.\n",
      "Starting Round 983\n",
      "Epoch [100/2000], Loss: 0.2421, Val Loss: 0.2421\n",
      "Epoch [200/2000], Loss: 0.2226, Val Loss: 0.2226\n",
      "Epoch [300/2000], Loss: 0.2267, Val Loss: 0.2267\n",
      "Epoch [400/2000], Loss: 0.2166, Val Loss: 0.2166\n",
      "Epoch [500/2000], Loss: 0.2122, Val Loss: 0.2122\n",
      "Early stopping at epoch 595\n",
      "Training complete.\n",
      "Starting Round 984\n",
      "Epoch [100/2000], Loss: 0.2846, Val Loss: 0.2846\n",
      "Early stopping at epoch 198\n",
      "Training complete.\n",
      "Starting Round 985\n",
      "Epoch [100/2000], Loss: 0.2603, Val Loss: 0.2603\n",
      "Epoch [200/2000], Loss: 0.2541, Val Loss: 0.2541\n",
      "Early stopping at epoch 265\n",
      "Training complete.\n",
      "Starting Round 986\n",
      "Epoch [100/2000], Loss: 0.3303, Val Loss: 0.3303\n",
      "Epoch [200/2000], Loss: 0.3345, Val Loss: 0.3345\n",
      "Early stopping at epoch 263\n",
      "Training complete.\n",
      "Starting Round 987\n",
      "Epoch [100/2000], Loss: 0.2204, Val Loss: 0.2204\n",
      "Early stopping at epoch 190\n",
      "Training complete.\n",
      "Starting Round 988\n",
      "Epoch [100/2000], Loss: 0.2636, Val Loss: 0.2636\n",
      "Early stopping at epoch 169\n",
      "Training complete.\n",
      "Starting Round 989\n",
      "Epoch [100/2000], Loss: 0.2688, Val Loss: 0.2688\n",
      "Epoch [200/2000], Loss: 0.2521, Val Loss: 0.2521\n",
      "Epoch [300/2000], Loss: 0.2497, Val Loss: 0.2497\n",
      "Early stopping at epoch 355\n",
      "Training complete.\n",
      "Starting Round 990\n",
      "Epoch [100/2000], Loss: 0.2840, Val Loss: 0.2840\n",
      "Epoch [200/2000], Loss: 0.2822, Val Loss: 0.2822\n",
      "Early stopping at epoch 230\n",
      "Training complete.\n",
      "Starting Round 991\n",
      "Epoch [100/2000], Loss: 0.2798, Val Loss: 0.2798\n",
      "Early stopping at epoch 160\n",
      "Training complete.\n",
      "Starting Round 992\n",
      "Epoch [100/2000], Loss: 0.2704, Val Loss: 0.2704\n",
      "Epoch [200/2000], Loss: 0.2681, Val Loss: 0.2681\n",
      "Early stopping at epoch 227\n",
      "Training complete.\n",
      "Starting Round 993\n",
      "Epoch [100/2000], Loss: 0.2727, Val Loss: 0.2727\n",
      "Epoch [200/2000], Loss: 0.2684, Val Loss: 0.2684\n",
      "Early stopping at epoch 290\n",
      "Training complete.\n",
      "Starting Round 994\n",
      "Epoch [100/2000], Loss: 0.2508, Val Loss: 0.2508\n",
      "Epoch [200/2000], Loss: 0.2585, Val Loss: 0.2585\n",
      "Early stopping at epoch 281\n",
      "Training complete.\n",
      "Starting Round 995\n",
      "Epoch [100/2000], Loss: 0.2537, Val Loss: 0.2537\n",
      "Early stopping at epoch 154\n",
      "Training complete.\n",
      "Starting Round 996\n",
      "Epoch [100/2000], Loss: 0.2283, Val Loss: 0.2283\n",
      "Epoch [200/2000], Loss: 0.2237, Val Loss: 0.2237\n",
      "Epoch [300/2000], Loss: 0.2176, Val Loss: 0.2176\n",
      "Epoch [400/2000], Loss: 0.2109, Val Loss: 0.2109\n",
      "Epoch [500/2000], Loss: 0.2132, Val Loss: 0.2132\n",
      "Early stopping at epoch 501\n",
      "Training complete.\n",
      "Starting Round 997\n",
      "Epoch [100/2000], Loss: 0.2835, Val Loss: 0.2835\n",
      "Epoch [200/2000], Loss: 0.2835, Val Loss: 0.2835\n",
      "Epoch [300/2000], Loss: 0.2939, Val Loss: 0.2939\n",
      "Early stopping at epoch 342\n",
      "Training complete.\n",
      "Starting Round 998\n",
      "Epoch [100/2000], Loss: 0.2776, Val Loss: 0.2776\n",
      "Epoch [200/2000], Loss: 0.2678, Val Loss: 0.2678\n",
      "Epoch [300/2000], Loss: 0.2787, Val Loss: 0.2787\n",
      "Early stopping at epoch 360\n",
      "Training complete.\n",
      "Starting Round 999\n",
      "Epoch [100/2000], Loss: 0.2650, Val Loss: 0.2650\n",
      "Epoch [200/2000], Loss: 0.2605, Val Loss: 0.2605\n",
      "Epoch [300/2000], Loss: 0.2500, Val Loss: 0.2500\n",
      "Early stopping at epoch 333\n",
      "Training complete.\n",
      "8.576108705997466 mins\n"
     ]
    }
   ],
   "source": [
    "target_variables = ['B', 'V', 'Cr', 'Mn', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Be',\n",
    "                    'As', 'Rb', 'Sr', 'Y', 'Mo', 'Cd', 'Sb', 'Cs', 'Ba', 'Pb'] # to be predicted\n",
    "input_features = ['Li', 'Na', 'Ca', 'SO-', 'Cl-', 'Br-', 'Al', 'Si', 'pH', 'F-', 'Fe', 'Mg']\n",
    "import time\n",
    "start = time.time()\n",
    "results = []\n",
    "### Making an ensemble of 1000 models\n",
    "for i in range(1000):\n",
    "    print(f'Starting Round {i}')\n",
    "    r_values, test_y, predicted_y, train_y, predicted_y_train, l_tr, l_te = pytorch_NN(all_data, input_features, target_variables)\n",
    "    results.append({\n",
    "        'r_values': r_values,\n",
    "        'test_y': test_y,\n",
    "        'predicted_y': predicted_y,\n",
    "        'train_y': train_y,\n",
    "        'predicted_y_train': predicted_y_train,\n",
    "        'l_tr': l_tr,\n",
    "        'l_te': l_te,\n",
    "    })\n",
    "end = time.time()\n",
    "print(f'{(end - start)/60} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f45d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_te = [[r for r in result['l_te']] for result in results]\n",
    "l_tr = [[r for r in result['l_tr']] for result in results]\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "for i in l_tr:\n",
    "    ax.plot(i, c='b', lw=0.5, label='Train')\n",
    "    ax.set_yscale('log')\n",
    "for i in l_te:\n",
    "    ax.plot(i, c='r', lw=0.5, label='Test')\n",
    "    ax.set_yscale('log')\n",
    "ax.set_xlabel('Epochs', fontsize=10, family='Arial')\n",
    "ax.set_ylabel('MAE', fontsize=10, family='Arial')\n",
    "plt.yticks(fontname = \"Arial\", fontsize=10)\n",
    "plt.xticks(fontname = \"Arial\", fontsize=10)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(), fontsize='small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edef33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separating the R2 score of each model\n",
    "r_squared_values = [[r**2 for r in result['r_values']] for result in results]\n",
    "df = pd.DataFrame(r_squared_values, columns=target_variables)\n",
    "df_melted = df.melt(var_name='Element', value_name='R_squared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d966f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Making a plot to have a view on the R2 score for each predicted element\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,3))\n",
    "sns.boxplot(data=df_melted, x='Element', y='R_squared')\n",
    "plt.xlabel('Elements', fontname = \"Arial\", fontsize=10)\n",
    "plt.ylabel('R$^2$', fontname = \"Arial\", fontsize=10)\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7aca35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
